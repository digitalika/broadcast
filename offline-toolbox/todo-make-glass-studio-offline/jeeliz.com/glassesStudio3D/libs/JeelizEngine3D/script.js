"use strict";var SharedShaders=(function(){let _shadersProvider=null;function a(){if(_shadersProvider!==null){return}else{if(typeof(Shaders)!=="undefined"){_shadersProvider=Shaders}else{if(typeof(JEShaders)!=="undefined"){_shadersProvider=JEShaders}}}}a();return{set_shadersProvider:function(b){if(_shadersProvider===b){return}if(_shadersProvider){_shadersProvider.unset()}_shadersProvider=b},is_initialized:function(){return _shadersProvider.is_initialized()},set_vertexPointersQuad:function(){return _shadersProvider.set_vertexPointersQuad()},set_vertexPointersQuadGL:function(b){return _shadersProvider.set_vertexPointersQuadGL(b)},set_vertexPointers:function(){return _shadersProvider.set_vertexPointers()},unset:function(){return _shadersProvider.unset()},set:function(b){return _shadersProvider.set(b)},set_shpCopyGL:function(b){a();return _shadersProvider.set_shpCopyGL(b)},set_shpHalfGL:function(b){a();return _shadersProvider.set_shpHalfGL(b)},destroy:function(){return _shadersProvider.destroy()}}})();var SharedTexture=(function(){let __sampler=0,__samplers=null,__indexCount=0,__texturesBoundIndices=null;let __predefinedTextures=null,__rttTexture=null;let __precisions=null;let __pixelFormats=null,__internalPixelFormats=null;let __isInitalized=false;const l=[];const u={isFloat:false,isPot:true,isLinear:false,isMipmap:false,isAnisotropicFiltering:false,isMirrorX:false,isMirrorY:false,isSrgb:false,isKeepArray:false,isFlipY:null,width:0,height:0,url:null,array:null,data:null,domElement:null,glTexture:null,isForceFloat:false,isHalfFloat:false,callback:null,nChannels:4,maxMipmapLevel:0};const v={initialized:false,element:null,ctx:null};const f=[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]];let __isJEContext=false,__isSharedContext=false;let __debugTexture;function n(x,B){const z=Array.prototype.slice.call(x);z.sort(function(E,D){return E-D});const C=z.length;const A=Math.round(C*B/2);return[z[A],z[C-1-A]]}function d(x){GL.bindTexture(GL.TEXTURE_2D,x)}const q=new Float32Array(1);const t=new Int32Array(q.buffer);function p(B){q[0]=B;const z=t[0];let bits=(z>>16)&32768;let m=(z>>12)&2047;const A=(z>>23)&255;if(A<103){return bits}if(A>142){bits|=31744;bits|=((A==255)?0:1)&&(z&8388607);return bits}if(A<113){m|=2048;bits|=(m>>(114-A))+((m>>(113-A))&1);return bits}bits|=((A-112)<<10)|(m>>1);bits+=m&1;return bits}function a(x){const z=new Uint16Array(x.length);x.forEach(function(B,A){z[A]=p(B)});return z}function r(){if(__predefinedTextures){return}console.log("INFO in SharedTexture: build random texture");const x=64;const z=x*x*4;const A=new Float32Array(z);for(let i=0;i<z;++i){A[i]=2*Math.random()-1}__predefinedTextures={random:e.instance({isFloat:true,isPot:true,array:A,width:x}),transparent:e.instance({isFloat:false,isPot:true,width:1,array:new Uint8Array([0,0,0,0])})}}const g={initHalfFloatTextureFromArray:null,initUnsignedIntTextureFromArray:null};function c(){if(g.initHalfFloatTextureFromArray!==null){return g.initHalfFloatTextureFromArray}const x=b(a([1,1,1,1]));if(x===null){console.log("ERROR: Invalid capacity in SharedTexture.can_initFromHalfFloatArray()");;return true}g.initHalfFloatTextureFromArray=x;return x}function o(){if(g.initUnsignedIntTextureFromArray!==null){return g.initUnsignedIntTextureFromArray}const x=b(new Uint8Array([255,255,255,255]));if(x===null){console.log("ERROR: Invalid capacity in SharedTexture.can_initFromUnsignedIntArray()");;return true}g.initUnsignedIntTextureFromArray=x;return x}function b(z){if(!SharedShaders.is_initialized()||!__isInitalized){console.log("WARNING in SharedTexture: can_initFromArray() is called too soon");return null}let textureTest=null;try{let glErr=GL.getError();if(glErr==="FUCKING_BIG_ERROR"){return false}textureTest=e.instance({isFloat:false,isHalfFloat:true,array:z,width:1});glErr=GL.getError();if(glErr!==GL.NO_ERROR){return false}}catch(B){return false}SharedFBO.unbind();GL.viewport(0,0,1,1);GL.clearColor(0,0,0,0);GL.clear(GL.COLOR_BUFFER_BIT);SharedShaders.set("shp_copy");textureTest.bindForce_toSampler(0);SharedVBO.draw_quad(true,true);const A=new Uint8Array(4);GL.readPixels(0,0,1,1,GL.RGBA,GL.UNSIGNED_BYTE,A);const x=(A[0]>0.9);textureTest.remove();SharedFBO.bind_default();return x}const e={init:function(){if(__isInitalized){return}console.log("INFO in SharedTexture: init()");__pixelFormats=[GL.RGB,null,GL.RGB,GL.RGBA];__internalPixelFormats=[GL.RGB,null,GL.RGB,GL.RGBA];__samplers=[GL.TEXTURE0,GL.TEXTURE1,GL.TEXTURE2,GL.TEXTURE3,GL.TEXTURE4,GL.TEXTURE5,GL.TEXTURE6,GL.TEXTURE7];__isJEContext=(typeof(JEContext)!=="undefined");__isSharedContext=(typeof(SharedContext)!=="undefined");if(__isJEContext&&JEContext.is_useManySamplers()){__samplers.push(GL.TEXTURE8,GL.TEXTURE9)}__texturesBoundIndices=[-1,-1,-1,-1,-1,-1,-1,-1];__precisions=[GL.UNSIGNED_BYTE,GL.FLOAT,GL.FLOAT];__isInitalized=true;let basePath=false;if(typeof(JESETTINGS)!=="undefined"){basePath=(typeof(SETTINGS)==="undefined")?JESETTINGS.basePath:SETTINGS.basePath}if(basePath){__debugTexture=e.instance({url:basePath+"images/debug/debugTexture.jpg"})}},init_afterLoad:function(){r();e.update_halfFloat()},get_transparentTexture:function(){return __predefinedTextures.transparent},get_debugTexture:function(){return __debugTexture},get_debugInfos:function(){return{textureCanInitFromArray:b(),textureCanInitFromHalfFloatArray:c(),"textureCanInitFromUnsignedArray()":o()}},update_halfFloat:function(){__precisions[1]=SharedContext.get_glHalfFloatType(GL)},set_onlyRTTRGBA:function(){__pixelFormats=[GL.RGBA,GL.RGBA,GL.RGBA,GL.RGBA];__internalPixelFormats=__pixelFormats},read_texture:function(B,z){Shaders.set("shp_copyLow");SharedFBO.unbind();const A=B.get_width(),x=B.get_height();GL.viewport(0,0,A,x);B.bind_toSampler(0);SharedVBO.draw_quad(false,false);GL.readPixels(0,0,A,x,GL.RGBA,GL.UNSIGNED_BYTE,z)},fill_halfFloatUsingFloat:function(C,D,x,H,E,G,z){C.activeTexture(C.TEXTURE0);const A=C.createTexture();C.bindTexture(C.TEXTURE_2D,A);const B=(E instanceof (Float32Array))?E:new Float32Array(E);const F=lib_maths.ln2(B.length);if(F%1!==0){C.texParameteri(C.TEXTURE_2D,C.TEXTURE_WRAP_S,C.CLAMP_TO_EDGE);C.texParameteri(C.TEXTURE_2D,C.TEXTURE_WRAP_T,C.CLAMP_TO_EDGE)}C.texParameteri(C.TEXTURE_2D,C.TEXTURE_MAG_FILTER,C.NEAREST);C.texParameteri(C.TEXTURE_2D,C.TEXTURE_MIN_FILTER,C.NEAREST);C.pixelStorei(C.UNPACK_FLIP_Y_WEBGL,G);C.texImage2D(C.TEXTURE_2D,0,C.RGBA,x,H,0,C.RGBA,C.FLOAT,B);C.bindTexture(C.TEXTURE_2D,null);C.pixelStorei(C.UNPACK_FLIP_Y_WEBGL,false);if(z){SharedFBO.bind_default();Shaders.set("shp_copy")}C.viewport(0,0,x,H);C.framebufferTexture2D(C.FRAMEBUFFER,C.COLOR_ATTACHMENT0,C.TEXTURE_2D,D,0);C.bindTexture(C.TEXTURE_2D,A);if(z){SharedVBO.draw_quad(true,true)}else{VBO.fill_viewportForTest(C)}C.deleteTexture(A);if(__isInitalized){__texturesBoundIndices[0]=-1;__rttTexture=null;__sampler=0}},activate_sampler:function(x){if(x!==__sampler){GL.activeTexture(__samplers[x]);__sampler=x}},instance:function(N){const K=Object.assign({},u,N);const M=__indexCount++;if(K.isFlipY===null){K.isFlipY=(K.url||K.array)?true:false}if(K.data){if(typeof(K.data)==="string"){K.array=QuantizaterDecoder_decodeFloatArray(K.data)}else{if(K.isFloat){K.array=new Float32Array(K.data)}else{K.array=new Uint8Array(K.data)}}K.isFlipY=false}let _precisionIndex=0;const B=(K.domElement)?true:false;const z={cv:null,ctx:null,isInitialized:false,iData:null};K.isHalfFloat=K.isHalfFloat||K.isFloat;if(K.isHalfFloat){_precisionIndex=1}if(!K.isForceFloat&&!SharedContext.is_webgl2()&&K.isFloat&&__isSharedContext&&!SharedContext.can_floatRTT()){K.isFloat=false}if(K.isFloat){_precisionIndex=2}if(K.isAnisotropicFiltering&&__isJEContext&&!JEContext.is_anisotropicFiltering()){K.isAnisotropicFiltering=false}const I=K.glTexture||GL.createTexture();let _image=null,_array=false,_width=0,_height=0,_isLoaded=false,_isDeleted=false;let _isBufferReady=false,_buffersFloat=null,_buffersByte=null,_bufferByte4=null,_bufferFloat4=null;let _internalPixelFormat=null,_pixelFormat=null,_pixelType=null;let _isFlipY=K.isFlipY;const J=(K.isHalfFloat&&K.isMipmap);const H=(J&&TextureFilteringTester.can_mipmapFloat());const E=(J&&H)?true:false;let _fakeMipmaps=null,_maxMipmapLevel=-1;let _isMipMapGenerated=false;const G={isReady:false,byteBuf:null,floatBuf:null};if(K.width){_width=K.width;_height=(K.height)?K.height:_width}function D(){d(I);GL.texImage2D(GL.TEXTURE_2D,0,GL.RGBA,1,1,0,GL.RGBA,GL.UNSIGNED_BYTE,null)}function x(P){try{const R=GL.getError();if(R==="FUCKING_BIG_ERROR"){return false}if(R!==GL.NO_ERROR){console.log("GLERR in SharedTexture:",R)}GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,P);if(GL.getError()!==GL.NO_ERROR){console.log("WARNING in SharedTexture - fill_textureFromArray(): invalid texImage2D params with array =",_internalPixelFormat,_pixelFormat,_pixelType);GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,null);if(GL.getError()!==GL.NO_ERROR){console.log("WARNING in SharedTexture - fill_textureFromArray(): invalid texImage2D params with null =",_internalPixelFormat,_pixelFormat,_pixelType);GL.texImage2D(GL.TEXTURE_2D,0,GL.RGBA,_width,_height,0,GL.RGBA,GL.UNSIGNED_BYTE,null)}}}catch(Q){GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,null)}return true}function L(){let glErr=GL.getError();if(glErr==="FUCKING_BIG_ERROR"){return false}GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,null);glErr=GL.getError();if(glErr!==GL.NO_ERROR){GL.finish();GLDebugger.log_glEnums("DEBUG in SharedTexture.fill_emptyTexture() - GL.texImage2D params:",{glErr:glErr,internalFormat:_internalPixelFormat,pixelFormat:_pixelFormat,pixelType:_pixelType});_pixelFormat=GL.RGBA;if(K.isHalfFloat&&_pixelType!==GL.FLOAT){_pixelType=GL.FLOAT;GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,null)}}return true}function O(P){let glErr=GL.getError();if(glErr==="FUCKING_BIG_ERROR"){return false}GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_pixelFormat,_pixelType,P);glErr=GL.getError();if(glErr!==GL.NO_ERROR){GL.finish();GLDebugger.log_glEnums("[DEBUG] in SharedTexture.fill_textureFromDomElement() - GL.texImage2D params:",{glErr:glErr,internalFormat:_internalPixelFormat,pixelFormat:_pixelFormat,pixelType:_pixelType});if(_pixelFormat!==GL.RGBA){_pixelFormat=GL.RGBA;GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_pixelFormat,_pixelType,P)}}return true}function C(){const U=Math.min(_width,_height);const S=Math.log2(U);_fakeMipmaps=new Array(1+S);_fakeMipmaps[0]=I;for(let level=1;level<=S;++level){const R=Math.pow(2,level);const Q=_width/R;const T=_height/R;const P=GL.createTexture();d(P);GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_MIN_FILTER,GL.NEAREST);GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_MAG_FILTER,GL.NEAREST);GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,Q,T,0,_pixelFormat,_pixelType,null);d(null);_fakeMipmaps[level]=P}_isMipMapGenerated=true}function F(){if(_isDeleted){return}d(I);if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,_isFlipY)}if(K.isPot){GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_WRAP_S,(K.isMirrorX)?GL.MIRRORED_REPEAT:GL.REPEAT);GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_WRAP_T,(K.isMirrorY)?GL.MIRRORED_REPEAT:GL.REPEAT)}else{GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_WRAP_S,GL.CLAMP_TO_EDGE);GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_WRAP_T,GL.CLAMP_TO_EDGE)}if(K.isAnisotropicFiltering&&typeof(JESETTINGS)!=="undefined"){GL.texParameterf(GL.TEXTURE_2D,JEContext.get_extTextureAnisotropic().TEXTURE_MAX_ANISOTROPY_EXT,JESETTINGS.anisotropicFilteringLevel)}GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_MAG_FILTER,(K.isLinear)?GL.LINEAR:GL.NEAREST);if(K.isLinear){GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_MIN_FILTER,(K.isMipmap&&!E)?GL.NEAREST_MIPMAP_LINEAR:GL.LINEAR)}else{GL.texParameteri(GL.TEXTURE_2D,GL.TEXTURE_MIN_FILTER,(K.isMipmap&&!E)?GL.NEAREST_MIPMAP_NEAREST:GL.NEAREST)}_pixelFormat=__pixelFormats[K.nChannels-1];_internalPixelFormat=__internalPixelFormats[K.nChannels-1];_pixelType=__precisions[_precisionIndex];if(SharedContext.is_webgl2()){const Q=GL.RGBA32F;if(_pixelFormat===GL.RGBA&&_pixelType===GL.FLOAT){if(K.isMipmap||K.isLinear){_internalPixelFormat=TextureFilteringTester.get_glInternalPixelFormat(GL)}else{if(!SharedContext.can_floatRTT()){_internalPixelFormat=GL.RGBA16F||GL.RGBA}else{if(Q){_internalPixelFormat=Q}}}}else{if(_pixelFormat===GL.RGB&&_pixelType===GL.FLOAT&&Q){_internalPixelFormat=Q;_pixelFormat=GL.RGBA}}}if((K.isHalfFloat&&!K.isFloat)||(K.isFloat&&K.isMipmap&&TextureFilteringTester.is_float16())){const P=GL.RGBA16F;if(P){_internalPixelFormat=P}_pixelType=SharedContext.get_glHalfFloatType(GL)}if(K.maxMipmapLevel){_maxMipmapLevel=K.maxMipmapLevel}if(K.isSrgb&&K.nChannels===4){_pixelFormat=JEContext.get_srgbFormat()}if((K.domElement||K.url)&&_pixelType!==GL.UNSIGNED_BYTE){console.log("WARNING in SharedTexture - load(): an url or domElement texture is floating point",K.domElement,K.url)}if(K.domElement){O(K.domElement)}else{if(K.url){O(_image)}else{if(_array){x(_array);if(!K.isKeepArray){_array=null}}else{L()}}}if(K.isMipmap){if(!E&&that){that.generate_mipmap();_isMipMapGenerated=true}else{if(E){C()}}}d(null);__texturesBoundIndices[__sampler]=-1;if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,false)}_isLoaded=true;if(K.callback&&that){K.callback(that);K.callback=null}}let that={get:function(){return I},get_width:function(){return _width},get_height:function(){return _height},get_url:function(){return K.url},is_float:function(){return K.isFloat},is_halfFloat:function(){return K.isHalfFloat},is_linear:function(){return K.isLinear},generate_mipmap:function(){GL.generateMipmap(GL.TEXTURE_2D)},bind_mipmapLevelToSampler:function(Q,P){if(E){if(!Q){Q=that.get_maxMipmapLevel()}e.activate_sampler(P);d(_fakeMipmaps[Q]);__texturesBoundIndices[P]=-1}else{that.bind_toSampler(P)}},get_maxMipmapLevel:function(){if(_maxMipmapLevel===-1){_maxMipmapLevel=Math.log(_width)/Math.log(2)}return _maxMipmapLevel},generate_mipmapToLevel:function(P){if(!E){that.generate_mipmap();return}if(!P){P=that.get_maxMipmapLevel()}Shaders.set("shp_fakeMipmap");e.activate_sampler(0);let w=_width,h=_height;for(let genLevel=1;genLevel<=P;++genLevel){w/=2;h/=2;Shaders.set_uniformDynamic2f("uun_dxy",0.25/w,0.25/h);GL.viewport(0,0,w,h);d(_fakeMipmaps[genLevel-1]);GL.framebufferTexture2D(SharedFBO.get_glTarget(),GL.COLOR_ATTACHMENT0,GL.TEXTURE_2D,_fakeMipmaps[genLevel],0);SharedVBO.draw_quad(false,genLevel===1)}__texturesBoundIndices[0]=-1},bind_toSampler:function(P){if(!_isLoaded){return false}e.activate_sampler(P);if(__texturesBoundIndices[P]===M){return false}d(I);__texturesBoundIndices[P]=M;return true},bindForce_toSampler:function(P){GL.activeTexture(__samplers[P]);__sampler=P;d(I);__texturesBoundIndices[P]=M},set_rtt:function(){__rttTexture=that;GL.framebufferTexture2D(SharedFBO.get_glTarget(),GL.COLOR_ATTACHMENT0,GL.TEXTURE_2D,I,0)},set_rttVp:function(){__rttTexture=that;GL.viewport(0,0,_width,_height);GL.framebufferTexture2D(SharedFBO.get_glTarget(),GL.COLOR_ATTACHMENT0,GL.TEXTURE_2D,I,0)},unset_rtt:e.unset_rtt,resize:function(Q,P){_width=Q,_height=P;F()},clone:function(Q){const P=e.instance({width:_width,height:_height,isHalfFloat:K.isHalfFloat,isFloat:K.isFloat,isLinear:K.isLinear,isMirrorY:K.isMirrorY,isFlipY:(Q)?!_isFlipY:_isFlipY,isPot:K.isPot});SharedShaders.set("shp_copy");SharedFBO.bind_default();P.set_rtt();GL.viewport(0,0,_width,_height);that.bind_toSampler(0);SharedVBO.draw_quad(true,true);return P},set_vp:function(){GL.viewport(0,0,_width,_height)},debug:function(){GL.depthMask(true);SharedFBO.unbind_andClear();that.bind_toSampler(0);SharedVBO.draw_quad(true,true)},draw_FS:function(){SharedFBO.unbind_andClear();Shaders.set("shp_debug");that.bind_toSampler(0);SharedVBO.draw_quad(false,true)},draw_debugRange:function(P){SharedFBO.unbind_andClear();Shaders.set("shp_debugRange");Shaders.set_uniformDynamic2fv("uun_range",P);that.bind_toSampler(0);SharedVBO.draw_quad(false,true);FBO.bind_default()},get_debugInfos:function(){return JSON.stringify({_internalPixelFormat:_internalPixelFormat,_width:_width,_height:_height,_pixelFormat:_pixelFormat,_pixelType:_pixelType})},get_debugFakeMipmaps:function(){return _fakeMipmaps},remove:function(){GL.deleteTexture(I);_isDeleted=true;l.splice(l.indexOf(that),1);that=null},refresh:function(){that.bindForce_toSampler(0);if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,true)}if(B){GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_pixelFormat,GL.UNSIGNED_BYTE,K.domElement)}else{GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,_array)}if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,false)}},create_buffersFloat:function(){const P=_width*_height*4;_buffersByte=[new Uint8Array(P),new Uint8Array(P),new Uint8Array(P),new Uint8Array(P)];_buffersFloat=[new Float32Array(_buffersByte[0].buffer),new Float32Array(_buffersByte[1].buffer),new Float32Array(_buffersByte[2].buffer),new Float32Array(_buffersByte[3].buffer)];_bufferByte4=new Uint8Array(P*4);_bufferFloat4=new Float32Array(_bufferByte4.buffer);_isBufferReady=true},read_allFloat:function(){if(!_isBufferReady){that.create_buffersFloat()}GL.readPixels(0,0,_width,_height*4,GL.RGBA,GL.UNSIGNED_BYTE,_bufferByte4);const P=_width*_height;const Q=P,S=2*P,R=3*P;for(let i=0;i<P;++i){_buffersFloat[0][i]=_bufferFloat4[i];_buffersFloat[1][i]=_bufferFloat4[i+Q];_buffersFloat[2][i]=_bufferFloat4[i+S];_buffersFloat[3][i]=_bufferFloat4[i+R]}return _buffersFloat},read_meanFloat:function(){if(!G.isReady){const P=_width*_height*4;G.byteBuf=new Uint8Array(P);G.floatBuf=new Float32Array(G.buffer);G.isReady=true}GL.readPixels(0,0,_width,_height,GL.RGBA,GL.UNSIGNED_BYTE,G.byteBuf);return G.floatBuf},draw_float:function(P){SharedFBO.unbind();Shaders.set("shp_floatChannel");that.bind_toSampler(0);if(P){GL.viewport(0,0,_width,_height);Shaders.set_uniformDynamic4fv("uun_channel",0.25,0.25,0.25,0.25);SharedVBO.draw_quad(false,true)}else{for(let colorIndex=0;colorIndex<4;++colorIndex){GL.viewport(0,_height*colorIndex,_width,_height);Shaders.set_uniformDynamic4fv("uun_channel",f[colorIndex]);SharedVBO.draw_quad(false,colorIndex===0)}}},update_fromArray:function(P){if(isNaN(P[0])){console.log("WARNING in SharedTexture - update_fromArray(): NaN value !")}const Q=(_pixelType===__precisions[0]&&!o());d(I);if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,true)}if(Q){if(!z.isInitialized){z.cv=document.createElement("canvas");z.cv.width=_width,z.cv.height=_height;z.ctx=z.cv.getContext("2d");z.iData=z.ctx.createImageData(_width,_height);z.isInitialized=true;DebugUtils.append_canvas(z.cv)}z.iData.data.set(P);z.ctx.putImageData(z.iData,0,0);GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_pixelFormat,_pixelType,z.cv)}else{GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_width,_height,0,_pixelFormat,_pixelType,P)}__texturesBoundIndices[__sampler]=M;if(_isFlipY){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,false)}},update_fromDOM:function(Q,P){d(I);if(P){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,true)}GL.texImage2D(GL.TEXTURE_2D,0,_internalPixelFormat,_pixelFormat,_pixelType,Q);__texturesBoundIndices[__sampler]=M;if(P){GL.pixelStorei(GL.UNPACK_FLIP_Y_WEBGL,false)}},serialize:function(T,P){const U=_width*_height;const S=U*4;let format="undefined";if(K.isHalfFloat){format=(T)?"RGBE":"JSON"}else{format="RGBA"}if(P){format=P}const R=SharedContext.is_webgl2()&&false;let shaderId=null;switch(format){case"RGBE":shaderId="shp_RGBtoRGBE";break;case"JSON":shaderId=(R)?"shp_copy":"shp_floatChannel";break;case"RGBA":case"RGBAARRAY":shaderId="shp_copyInvy";break}if(!_isBufferReady){if(format==="RGBA"||format==="RGBE"||format==="RGBAARRAY"){_buffersByte=new Uint8Array(S);_isBufferReady=true}else{if(format==="JSON"&&!R){that.create_buffersFloat()}}}SharedFBO.unbind();Shaders.set(shaderId);that.bind_toSampler(0);let data=null;if(format==="RGBA"||format==="RGBE"||format==="RGBAARRAY"){GL.viewport(0,0,_width,_height);SharedVBO.draw_quad(true,true);GL.readPixels(0,0,_width,_height,GL.RGBA,GL.UNSIGNED_BYTE,_buffersByte);if(format==="RGBAARRAY"){return{data:_buffersByte}}if(!v.initialized){v.element=document.createElement("canvas");v.ctx=v.element.getContext("2d");v.initialized=true}v.element.width=_width;v.element.height=_height;const Q=v.ctx.createImageData(_width,_height);Q.data.set(_buffersByte);v.ctx.putImageData(Q,0,0);data=v.element.toDataURL("image/png")}else{if(format==="JSON"){if(R){data=new Float32Array(U);GL.viewport(0,0,_width,_height);SharedVBO.draw_quad(true,true);GL.readPixels(0,0,_width,_height,GL.RGBA,GL.FLOAT,data)}else{for(let colorIndex=0;colorIndex<4;++colorIndex){GL.viewport(0,_height*colorIndex,_width,_height);Shaders.set_uniformDynamic4fv("uun_channel",f[colorIndex]);SharedVBO.draw_quad(!colorIndex,!colorIndex)}that.read_allFloat();data=new Array(U);for(let i=0;i<U;++i){data[4*i]=_buffersFloat[0][i];data[4*i+1]=_buffersFloat[1][i];data[4*i+2]=_buffersFloat[2][i];data[4*i+3]=_buffersFloat[3][i]}}}}return{format:format,data:data,width:_width,height:_height,isMirrorY:K.isMirrorY,isFlipY:(format==="RGBA")?K.isFlipY:!K.isFlipY}}};if(K.isMipmap&&!E&&_isLoaded&&!_isMipMapGenerated){that.generate_mipmap();_isMipMapGenerated=true}if(K.url){D();_image=new Image();_image.crossorigin="Anonymous";_image.crossOrigin="Anonymous";_image.src=K.url;_image.onload=function(){_width=_image.width;_height=_image.height;F()}}else{if(K.domElement){const A=function(){_width=("videoWidth" in K.domElement)?K.domElement.videoWidth:K.domElement.width;_height=("videoHeight" in K.domElement)?K.domElement.videoHeight:K.domElement.height;if(!_width){console.log("WARNING in SharedTexture - instance(): DOM element provided but width is invalid. retry loading later...");setTimeout(A,1)}else{F()}};A()}else{if(K.array){if(K.isHalfFloat&&!K.isFloat){if(K.array instanceof (Uint16Array)){_array=K.array;F()}else{if(c()){_array=a(K.array);F()}else{F();e.fill_halfFloatUsingFloat(GL,I,that.get_width(),that.get_height(),K.array,_isFlipY,true)}}}else{if(K.isFloat){_array=(K.array instanceof (Float32Array))?K.array:new Float32Array(K.array);F()}else{_array=(K.array instanceof (Uint8Array))?K.array:new Uint8Array(K.array);F()}}if(!K.isKeepArray){if(_array&&_array!==K.array){_array=null}delete (K.array)}}else{if(K.glTexture){_isLoaded=true}else{F()}}}}if(!that){}that.get_size=that.get_width;if(K.callback&&_isLoaded){K.callback(that);K.callback=null}l.push(that);return that},unbind:function(x){if(x!==__sampler){GL.activeTexture(__samplers[x]);__sampler=x}__texturesBoundIndices[x]=-1;d(null)},bind_random:function(x){__predefinedTextures.random.bind_toSampler(x)},unset_rtt:function(){__rttTexture=null;GL.framebufferTexture2D(SharedFBO.get_glTarget(),GL.COLOR_ATTACHMENT0,GL.TEXTURE_2D,null,0)},reset:function(){for(let i=0;i<__samplers.length;++i){__texturesBoundIndices[i]=-1}__sampler=-1},reset_sampler:function(){__sampler=-1},unbind_all:function(){for(let i=0;i<__samplers.length;++i){e.unbind(i)}},free_memory:function(){if(__predefinedTextures){__predefinedTextures.random.remove();__predefinedTextures.transparent.remove()}},unserialize:function(z,A){if(z.format==="RGBA"||z.format==="RGBE"){const x=new Image();x.src=z.data;x.onload=function(){const B=e.instance({isMirrorY:z.isMirrorY,isFlipY:z.isFlipY,isFloat:false,domElement:x,callback:function(D){if(z.format==="RGBA"){A(D);return}const C=z.width,F=z.height;const E=e.instance({isMirrorY:z.isMirrorY,isFloat:true,width:C,height:F,isFlipY:z.isFlipY});SharedFBO.bind_default();GL.viewport(0,0,C,F);Shaders.set("shp_RGBEtoRGB");E.set_rtt();D.bind_toSampler(0);SharedVBO.draw_quad(true,true);e.unbind(0);A(E);GL.flush();setTimeout(D.remove,50)}})}}else{if(z.format==="JSON"){A(e.instance({isFloat:true,isFlipY:z.isFlipY,width:z.width,height:z.height,array:new Float32Array(z.data)}))}else{console.log("ERROR in SharedTexture.unserialize(): incorrect serialized texture format");A(false)}}},destroy:function(){if(__rttTexture){FBO.bind_default();e.unset_rtt();FBO.unbind()}e.unbind_all();l.slice(0).forEach(function(x){x.remove()});l.splice(0);__isInitalized=false;__indexCount=0;if(typeof(TextureFilteringTester)!=="undefined"){TextureFilteringTester.destroy()}__predefinedTextures=null}};return e})();const SharedTexturePair=(function(){return{instance:function(a){const b=[SharedTexture.instance(a),SharedTexture.instance(a)];const d=[b[1],b[0]];let _textures=d;const c={set_rttAndBind:function(e){_textures[1].set_rtt();_textures[0].bind_toSampler(e);c.swap()},set_rttVpAndBind:function(e){_textures[1].set_rttVp();_textures[0].bind_toSampler(e);c.swap()},swap:function(){_textures=(_textures===b)?d:b},refresh:function(){_textures[0].refresh();_textures[1].refresh()},bind_toSampler:function(e){_textures[0].bind_toSampler(e)},bind_previousToSampler:function(e){_textures[1].bind_toSampler(e)},get_last:function(){return _textures[0]},remove:function(){_textures[0].remove(),_textures[1].remove();_textures=null}};return c}}})();var SharedVBO=(function(){let __defaultFillViewportVBOs=null,__bufferCount=0,__isInitialized=false;const c=[];const b={vertices:-2,indices:-2};function d(n){const l={vertices:null,indices:null};const g=[-1,-1,3,-1,-1,3];l.vertices=n.createBuffer();n.bindBuffer(n.ARRAY_BUFFER,l.vertices);n.bufferData(n.ARRAY_BUFFER,new Float32Array(g),n.STATIC_DRAW);const f=[0,1,2];l.indices=n.createBuffer();n.bindBuffer(n.ELEMENT_ARRAY_BUFFER,l.indices);n.bufferData(n.ELEMENT_ARRAY_BUFFER,new Uint16Array(f),n.STATIC_DRAW);return l}function e(g,f){g.deleteBuffer(f.vertices);g.deleteBuffer(f.indices)}const a={reset:function(){b.vertices=-2,b.indices=-2},init:function(){if(__isInitialized){return}console.log("INFO in SharedVBO : init()");__defaultFillViewportVBOs=d(GL);a.bind_quad();__isInitialized=true},instance:function(l){const p=__bufferCount++;const o=(l.indices)?l.indices.length:0;const n=(typeof(l.mode)==="undefined")?GL.STATIC_DRAW:l.mode;const g=GL.createBuffer();GL.bindBuffer(GL.ARRAY_BUFFER,g);GL.bufferData(GL.ARRAY_BUFFER,(l.vertices instanceof Float32Array)?l.vertices:new Float32Array(l.vertices),n);b.vertices=p;let _bufferIndices=null,_typeIndice=null,_sizePerIndice=null;if(l.indices){_bufferIndices=GL.createBuffer();GL.bindBuffer(GL.ELEMENT_ARRAY_BUFFER,_bufferIndices);let typeArray=null;if(l.indices.length<65536){typeArray=Uint16Array;_typeIndice=GL.UNSIGNED_SHORT;_sizePerIndice=2}else{typeArray=Uint32Array;_typeIndice=GL.UNSIGNED_INT;_sizePerIndice=4}const f=(l.indices instanceof typeArray)?l.indices:new typeArray(l.indices);GL.bufferData(GL.ELEMENT_ARRAY_BUFFER,f,n);b.indices=p}let that={bind_vertices:function(q){if(b.vertices!==p){GL.bindBuffer(GL.ARRAY_BUFFER,g);b.vertices=p}if(q){SharedShaders.set_vertexPointers()}},bind_indices:function(){if(b.indices===p){return}GL.bindBuffer(GL.ELEMENT_ARRAY_BUFFER,_bufferIndices);b.indices=p},bind:function(q){that.bind_vertices(q);that.bind_indices()},draw:function(){GL.drawElements(GL.TRIANGLES,o,_typeIndice,0);if(GLDebugger.catch_GLError()){console.log("ERROR in SharedVBO.draw(): No VBO bound to enabled attributes")}},draw_part:function(r,q){GL.drawElements(GL.TRIANGLES,r,_typeIndice,q*_sizePerIndice)},remove:function(){GL.deleteBuffer(g);if(l.indices){GL.deleteBuffer(_bufferIndices)}that=null}};c.push(that);return that},bind_quad:function(){if(b.vertices!==-1){GL.bindBuffer(GL.ARRAY_BUFFER,__defaultFillViewportVBOs.vertices);b.vertices=-1}if(b.indices!==-1){GL.bindBuffer(GL.ELEMENT_ARRAY_BUFFER,__defaultFillViewportVBOs.indices);b.indices=-1}},draw_quad:function(f,g){if(f){SharedVBO.bind_quad()}if(g){SharedShaders.set_vertexPointersQuad()}GL.drawElements(GL.TRIANGLES,3,GL.UNSIGNED_SHORT,0)},fill_viewportForTest:function(f){const l=f||GL;const g=d(l);l.bindBuffer(l.ARRAY_BUFFER,g.vertices);l.bindBuffer(l.ELEMENT_ARRAY_BUFFER,g.indices);SharedShaders.set_vertexPointersQuadGL(l);l.drawElements(l.TRIANGLES,3,l.UNSIGNED_SHORT,0);e(l,g);a.reset();if(__isInitialized){a.bind_quad();SharedShaders.set_vertexPointersQuad()}},free_memory:function(){e(GL,__defaultFillViewportVBOs)},destroy:function(){a.free_memory();c.forEach(function(f){f.remove()});GL.bindBuffer(GL.ARRAY_BUFFER,null);GL.bindBuffer(GL.ELEMENT_ARRAY_BUFFER,null);a.reset();__isInitialized=false;c.splice(0);__bufferCount=0}};return a})();var SharedFBO=(function(){let __fbo=null,__glDrawTarget=null,__glReadTarget=null,__isInitialized=false;const c=[];const b={fboBindedIndex:-2,fboCounter:1};const a={is_initialized:function(){return __isInitialized},init:function(){if(__isInitialized){return}__fbo=GL.createFramebuffer();const d=SharedContext.is_webgl2();__glDrawTarget=(d&&GL.DRAW_FRAMEBUFFER)?GL.DRAW_FRAMEBUFFER:GL.FRAMEBUFFER;__glReadTarget=(d&&GL.READ_FRAMEBUFFER)?GL.READ_FRAMEBUFFER:GL.FRAMEBUFFER;__isInitialized=true},get_glDrawTarget:function(){if(!__glDrawTarget){throw new Error("ERROR in SharedFBO - get_glDrawTarget(): __glDrawTarget is unset")}return __glDrawTarget},get_glReadTarget:function(){if(!__glDrawTarget){throw new Error("ERROR in SharedFBO - get_glReadTarget(): __glReadTarget is unset")}return __glReadTarget},get_glTarget:function(){return GL.FRAMEBUFFER},get_shared:function(){return b},get_FBO:function(){return __fbo},instance:function(d){if(!("isDepth" in d)){d.isDepth=false}let _texture=(d.texture)?d.texture:null;let _width=d.width;let _height=("height" in d)?d.height:d.width;let _fbo=__fbo;let _rbo=null;let _isSeparated=false,_isDeleted=false;let _fboIndex=0;if(_texture){_width=(_width)?_width:_texture.get_width();_height=(_height)?_height:_texture.get_height()}const e={separate:function(){if(_isSeparated){return}_fbo=GL.createFramebuffer();_isSeparated=true;_fboIndex=b.fboCounter++},add_depth:function(){e.separate();e.set_rtt();_rbo=GL.createRenderbuffer();GL.bindRenderbuffer(GL.RENDERBUFFER,_rbo);GL.renderbufferStorage(GL.RENDERBUFFER,GL.DEPTH_COMPONENT16,_width,_height);GL.framebufferRenderbuffer(__glDrawTarget,GL.DEPTH_ATTACHMENT,GL.RENDERBUFFER,_rbo);GL.clearDepth(1)},bind:function(f,g){if(_fboIndex!==b.fboBindedIndex){GL.bindFramebuffer(__glDrawTarget,_fbo);b.fboBindedIndex=_fboIndex}if(_texture){_texture.set_rtt()}if(g){GL.viewport(0,0,_width,_height)}if(f){GL.clear(GL.COLOR_BUFFER_BIT|GL.DEPTH_BUFFER_BIT)}},bind_only:function(){if(_fboIndex!==b.fboBindedIndex){GL.bindFramebuffer(__glDrawTarget,_fbo);b.fboBindedIndex=_fboIndex}},clear:function(){GL.clear(GL.COLOR_BUFFER_BIT|GL.DEPTH_BUFFER_BIT)},clear_color:function(){GL.clear(GL.COLOR_BUFFER_BIT)},clear_depth:function(){GL.clear(GL.DEPTH_BUFFER_BIT)},set_vp:function(){GL.viewport(0,0,_width,_height)},set_rtt:function(){if(_fboIndex!==b.fboBindedIndex){GL.bindFramebuffer(__glDrawTarget,_fbo);b.fboBindedIndex=_fboIndex}},rtt:function(f){_texture=f;if(b.fboBindedIndex!==_fboIndex){GL.bindFramebuffer(GL.FRAMEBUFFER,_fbo);b.fboBindedIndex=_fboIndex}f.set_rtt()},unbind:function(){GL.bindFramebuffer(__glDrawTarget,null);b.fboBindedIndex=-1},resize:function(g,f){_width=g;_height=f;if(_rbo){GL.bindRenderbuffer(GL.RENDERBUFFER,_rbo);GL.renderbufferStorage(GL.RENDERBUFFER,GL.DEPTH_COMPONENT16,_width,_height)}},remove:function(){if(_fbo!==__fbo&&!_isDeleted){GL.bindFramebuffer(__glDrawTarget,_fbo);GL.framebufferTexture2D(__glDrawTarget,GL.COLOR_ATTACHMENT0,GL.TEXTURE_2D,null,0);if(_rbo){GL.framebufferRenderbuffer(__glDrawTarget,GL.DEPTH_ATTACHMENT,GL.RENDERBUFFER,null)}GL.bindFramebuffer(__glDrawTarget,null);GL.deleteFramebuffer(_fbo);if(_rbo){GL.deleteRenderbuffer(_rbo)}}_isDeleted=true}};if(d.isDepth){e.add_depth()}c.push(e);return e},unbind:function(){GL.bindFramebuffer(__glDrawTarget,null);b.fboBindedIndex=-1},unbind_andClear:function(){GL.bindFramebuffer(__glDrawTarget,null);GL.clear(GL.COLOR_BUFFER_BIT|GL.DEPTH_BUFFER_BIT);GL.viewport(0,0,SharedContext.get_width(),SharedContext.get_height());b.fboBindedIndex=-1},reset:function(){b.fboBindedIndex=-2},bind_default:function(){if(b.fboBindedIndex!==0){GL.bindFramebuffer(__glDrawTarget,__fbo);b.fboBindedIndex=0}},clear:function(){GL.viewport(0,0,SharedContext.get_width(),SharedContext.get_height());GL.clear(GL.COLOR_BUFFER_BIT)},destroy:function(){a.unbind();c.forEach(function(d){d.remove()});GL.deleteFramebuffer(__fbo);a.reset();__isInitialized=false;c.splice(0);b.fboBindedIndex=-2;b.fboCounter=1}};return a})();const SharedContext=(function(){let _contextProvider=null,_isInitialized=false;const a={isFloatEnabled:false,textureFloat:null,textureFloatLinear:null,isTextureFloat:false,isTextureFloatLinear:false,textureHalfFloat:null,isTextureHalfFloat:false,textureHalfFloatLinear:null,isHalfFloatEnabled:false,colorBufferFloat:null,isColorBufferFloat:false,colorBufferHalfFloat:null,isColorBufferHalfFloat:false};let _extensions=null;const l={floatRTT:true,halfFloatRTT:true,floatRTT4channels:true};let _capabilities=null;let _global=(typeof(window)==="undefined")?{}:window;function f(){if(!_isInitialized){n()}}function n(){_contextProvider=(typeof(Context)==="undefined")?JEContext:Context;_isInitialized=true}function o(q,t){for(let i=0;i<q.length;++i){const r=t.getExtension(q[i]);if(r){return r}}return null}function p(q){b(q);d(q);c(q);g(q)}function c(q){_extensions.colorBufferFloat=e.enable_colorBufferFloatExtension(q);_extensions.isColorBufferFloat=(_extensions.colorBufferFloat)?true:false;_global.GL_EXT_COLORBUFFERFLOAT=_extensions.colorBufferFloat}function g(q){_extensions.colorBufferHalfFloat=e.enable_colorBufferHalfFloatExtension(q);_extensions.isColorBufferHalfFloat=(_extensions.colorBufferHalfFloat)?true:false;_global.GL_EXT_COLORBUFFERHALFFLOAT=_extensions.colorBufferHalfFloat}function b(q){if(_extensions.isFloatEnabled){return}console.log("INFO in SharedContext: enable_floatExtensions()");_extensions.textureFloat=e.enable_textureFloatExtensions(q);_global.GL_EXT_FLOAT=_extensions.textureFloat;_extensions.isTextureFloat=(_extensions.textureFloat)?true:false;if(_extensions.isTextureFloat||e.is_webgl2()){_extensions.textureFloatLinear=e.enable_textureFloatLinearExtensions(q);_extensions.isTextureFloatLinear=(_extensions.textureFloatLinear)?true:false;_global.GL_EXT_FLOATLINEAR=_extensions.textureFloatLinear}_extensions.isFloatEnabled=true}function d(q){if(_extensions.isHalfFloatEnabled){return}console.log("INFO in SharedContext: enable_halfFloatExtensions()");_extensions.textureHalfFloat=e.enable_textureHalfFloatExtensions(q);if(_extensions.textureHalfFloat){_extensions.isTextureHalfFloat=true;_global.GL_EXT_HALFFLOAT=_extensions.textureHalfFloat}else{console.log("WARNING in SharedContext.enable_halfFloatExtensions(): OES_texture_half_float not found")}if(_extensions.isTextureHalfFloat||e.is_webgl2()){_extensions.textureHalfFloatLinear=e.enable_textureHalfFloatLinearExtensions(q);_global.GL_EXT_HALFFLOATLINEAR=_extensions.textureHalfFloatLinear}if(!_extensions.textureHalfFloatLinear){console.log("WARNING in SharedContext.enable_halfFloatExtensions(): OES_texture_half_float_linear not found")}_extensions.isTextureHalfFloatLinear=(_extensions.textureHalfFloatLinear)?true:false;_extensions.isHalfFloatEnabled=true}const e={init:function(){if(_isInitialized){return true}_extensions=Object.assign({},a);_capabilities=Object.assign({},l);f();p(GL);SharedFBO.init();SharedTexture.init();const q=e.determine_capabilities();if(!q){return false}SharedVBO.init();SharedTexture.init_afterLoad();return true},get_width:function(){f();return _contextProvider.get_width()},get_height:function(){f();return _contextProvider.get_height()},is_webgl2:function(){f();return _contextProvider.is_webgl2()},enable_allExtensions:function(q){e.enable_colorBufferFloatExtension(q);e.enable_colorBufferHalfFloatExtension(q);e.enable_textureFloatExtensions(q);e.enable_textureFloatLinearExtensions(q);e.enable_textureHalfFloatExtensions(q);e.enable_textureHalfFloatLinearExtensions(q)},enable_colorBufferFloatExtension:o.bind(null,["EXT_color_buffer_float","WEBGL_color_buffer_float","OES_color_buffer_float"]),enable_colorBufferHalfFloatExtension:o.bind(null,["EXT_color_buffer_half_float","WEBGL_color_buffer_half_float","OES_color_buffer_half_float"]),enable_textureFloatExtensions:o.bind(null,["OES_texture_float","MOZ_OES_texture_float","WEBKIT_OES_texture_float"]),enable_textureFloatLinearExtensions:o.bind(null,["OES_texture_float_linear","MOZ_OES_texture_float_linear","WEBKIT_OES_texture_float_linear"]),enable_textureHalfFloatExtensions:o.bind(null,["OES_texture_half_float","MOZ_OES_texture_half_float","WEBKIT_OES_texture_half_float"]),enable_textureHalfFloatLinearExtensions:o.bind(null,["OES_texture_half_float_linear","MOZ_OES_texture_half_float_linear","WEBKIT_OES_texture_half_float_linear"]),get_glHalfFloatType:function(r){const q=e.enable_textureHalfFloatExtensions(r);if(q&&q.HALF_FLOAT_OES){return q.HALF_FLOAT_OES}return(r.HALF_FLOAT||r.FLOAT)},get_capabilities:function(){return _capabilities},can_floatRTT:function(){return _capabilities.floatRTT},can_halfFloatRTT:function(){return _capabilities.halfFloatRTT},can_RTT4Channels:function(){return _capabilities.floatRTT4channels},test_RTT:function(u,B,A){const q=u.FRAMEBUFFER;const x=u.NEAREST;console.log("INFO in SharedContext.test_RTT(): test RTT with glInternalPixelFormat = "+GLDebugger.get_GLEnum(B,u)+", glPixelType = "+GLDebugger.get_GLEnum(A,u));const v=u.createFramebuffer();u.bindFramebuffer(q,v);const t=u.createTexture();u.bindTexture(u.TEXTURE_2D,t);u.pixelStorei(u.UNPACK_FLIP_Y_WEBGL,false);u.texParameteri(u.TEXTURE_2D,u.TEXTURE_MAG_FILTER,x);u.texParameteri(u.TEXTURE_2D,u.TEXTURE_MIN_FILTER,x);const z=function(){u.bindTexture(u.TEXTURE_2D,null);u.bindFramebuffer(q,null);u.deleteTexture(t);u.deleteFramebuffer(v)};u.texImage2D(u.TEXTURE_2D,0,B,1,1,0,u.RGBA,A,null);u.framebufferTexture2D(u.FRAMEBUFFER,u.COLOR_ATTACHMENT0,u.TEXTURE_2D,t,0);const C=u.READ_FRAMEBUFFER||u.FRAMEBUFFER;let glStatus=u.checkFramebufferStatus(C);if(glStatus!==u.FRAMEBUFFER_COMPLETE){GLDebugger.log_GLEnum("WARNING in SharedContext.test_RTT(): cannot do RTT. glStatus =",glStatus,u);z();return false}SharedShaders.set_shpHalfGL(u);u.clearColor(0,0,0,0);u.viewport(0,0,1,1);u.disable(u.DEPTH_TEST);u.clear(u.COLOR_BUFFER_BIT);SharedVBO.fill_viewportForTest(u);u.bindFramebuffer(q,null);SharedShaders.set_shpCopyGL(u);u.activeTexture(u.TEXTURE0);u.bindTexture(u.TEXTURE_2D,t);SharedVBO.fill_viewportForTest(u);const r=new Uint8Array(4);u.readPixels(0,0,1,1,u.RGBA,u.UNSIGNED_BYTE,r);z();if(Math.abs(r[0]-127)>3){console.log("WARNING in SharedContext.test_RTT(): readBufferPixel = ",r.toString(),"(should be [127,127,127,127])");return false}console.log("  RTT success!");return true},determine_floatRTTCapability:function(t){console.log("============ BEGIN SharedContext determine_floatRTTCapability() ============");const q={floatRTT:false,halfFloatRTT:false};t.disable(t.BLEND);t.clearColor(0,0,0,0);t.clear(t.COLOR_BUFFER_BIT);if(t.RGBA32F&&e.test_RTT(t,t.RGBA32F,t.FLOAT)){q.floatRTT=true}if(!q.floatRTT&&e.test_RTT(t,t.RGBA,t.FLOAT)){q.floatRTT=true}const r=e.get_glHalfFloatType(t);if(t.RGBA16F&&e.test_RTT(t,t.RGBA16F,r)){q.halfFloatRTT=true}if(!q.halfFloatRTT&&e.test_RTT(t,t.RGBA,r)){q.halfFloatRTT=true}console.log("============ END SharedContext determine_floatRTTCapability() ============");return q},determine_floatRTT4ChannelsCapability:function(){const r=SharedFBO.instance({width:1});r.separate();const t=SharedTexture.instance({width:1,isFloat:true,nChannels:3});r.set_rtt();t.set_rtt();GL.flush();const q=GL.checkFramebufferStatus(SharedFBO.get_glReadTarget());if(q!==GL.FRAMEBUFFER_COMPLETE){console.log("INFO in SharedContext - determine_floatRTT4ChannelsCapability(): cannot do RTT in 3 channels RGB texture.");SharedTexture.set_onlyRTTRGBA();_capabilities.floatRTT4channels=false}else{_capabilities.floatRTT4channels=true}r.remove();t.remove()},determine_capabilities:function(){const q=e.determine_floatRTTCapability(GL);Object.assign(_capabilities,q);if(!_capabilities.floatRTT&&!_capabilities.halfFloatRTT){console.log("ERROR in SharedContext - determine_capabilities(): cannot do RTT on float and half float textures");return false}e.determine_floatRTT4ChannelsCapability();return true},destroy:function(){SharedTexture.destroy();SharedShaders.destroy();SharedFBO.destroy();SharedVBO.destroy();_isInitialized=false},get_debugInfos:function(){return{capabilityFloatRTT:_capabilities.floatRTT,capabilityHalfFloatRTT:_capabilities.halfFloatRTT,capabilityFloatRTT4channels:_capabilities.floatRTT4channels}}};return e})();var GLDebugger=(function(){const a={get_jsType:function(b){let tp=Object.prototype.toString.call(b);tp=tp.replace("[object ","[");tp=tp.replace("[","");tp=tp.replace("]","");return tp},get_GLEnum:function(c,b){if(!c){return c}const d=b||GL;let keyFound=null;for(let key in d){if(d[key]===c){keyFound=key;break}}if(keyFound){return("gl."+keyFound)}else{return("[GL.KEYNOTFOUND for "+c.toString()+"]")}},log_glEnums:function(f,c,d){const e=d||GL;const b=[];for(let key in c){b.push("    "+key+": "+a.get_GLEnum(c[key],e))}console.log(f+"\n"+b.join("\n"))},log_FBStatus:function(c){const b=GL.checkFramebufferStatus(GL.FRAMEBUFFER);a.log_GLEnum(c,b)},log_GLEnum:function(e,c,d){const b=a.get_GLEnum(c,d);console.log(e,b)},catch_GLError:function(c){glErr=GL.getError();if(glErr){const b=a.get_GLEnum(glErr);console.log(c,"GL ERROR = "+b);return true}return false},display_shaderCompilationError:function(d,o,l){console.log("TIP: debugShaderSource is the buggy shader source !");window.debugShaderSource=o;const f=document.createElement("div");f.style.textAlign="left";f.style.position="absolute";f.style.overflowY="scroll";f.style.width="100%";f.style.height="100%";f.style.top="0px";f.style.left="0px";f.style.zIndex=2000;f.style.backgroundColor="rgba(0,0,0,0.9)";f.style.boxSizing="border-box";f.style.padding="20px";f.style.color="white";document.body.appendChild(f);const b=document.createElement("h1");b.innerHTML="GLDebugger.js - GLSL compilation error";f.appendChild(b);const e=function(r){const q=document.createElement("div");q.style.display="block";q.style.marginTop="2em";q.innerHTML="<b>"+r+"</b><br/>";f.appendChild(q)};e("ERROR in "+l+"");e("Raw error message:");const n=function(r){const q=document.createElement("textarea");q.style.width="600px";q.style.height="300px";f.appendChild(q);q.value=r};n(d);e("ERROR EXPLOITATION:");const c=d.split("ERROR");const p=o.split("\n");const g=document.createElement("ul");c.forEach(function(t){if(t===""){return}const v=document.createElement("li");v.innerHTML=t+"<br>";g.appendChild(v);const r=t.split(":");if(r.length<3){return}const q=parseInt(r[2]);const u=document.createElement("pre");u.innerHTML=p[q-1]+"\n"+p[q];u.style.color="lime";v.appendChild(u)});f.appendChild(g);e("Raw shader source:");n(o)}};return a})();var VBO=SharedVBO;var FBO=SharedFBO;var Texture=SharedTexture;var JEVBO=SharedVBO;var JETexture=SharedTexture;var JEFBO=SharedFBO;var JEShaders=(function(){let _isInitialized=false;const x=["uun_source","uun_colorTextureUsage"];const b=["uun_paramsMap","uun_paramsMapMask"];const l=["uun_projMatrixWebcam","uun_moveXRotateY","uun_postOffset","uun_rx","uun_focalFactor","uun_screenSizeFactor"];const g=["uun_viewerRot","uun_viewerPreOffset","uun_viewerPostOffset","uun_viewerTrans","uun_viewerPreScale","uun_FOVCorrectionFactor"];const t={};let _currentShaderId=-1,_currentShader=null,_shaderIdCount=0;function c(F,G,E,C){const D=F.createShader(G);F.shaderSource(D,E);F.compileShader(D);if(!F.getShaderParameter(D,F.COMPILE_STATUS)){const B=F.getShaderInfoLog(D);GLDebugger.display_shaderCompilationError(B,E,C);return false}return D}function A(D,C){if(JEContext.is_webgl2()){C.fragmentSource=C.fragmentSource.replace(/gl_FragData\[([0-3])\]/g,"gbuf$1")}C.glVertexShader=c(D,D.VERTEX_SHADER,C.vertexSource,C.name+" VERTEX");C.glFragmentShader=c(D,D.FRAGMENT_SHADER,C.fragmentSource,C.name+" FRAGMENT");const B=D.createProgram();D.attachShader(B,C.glVertexShader);D.attachShader(B,C.glFragmentShader);D.linkProgram(B);return B}function p(C){const B="#version 300 es\n";C.vertexSource=B+C.vertexSource.replace(/varying/g,"out");C.fragmentSource=B+C.fragmentSource.replace(/varying/g,"in");C.vertexSource=C.vertexSource.replace(/texture2D\(/g,"texture(");C.fragmentSource=C.fragmentSource.replace(/texture2D\(/g,"texture(");if(!C.isMRT){C.fragmentSource=C.fragmentSource.replace(/void main/g,"out vec4 FragColor;\nvoid main");C.fragmentSource=C.fragmentSource.replace(new RegExp("gl_FragColor","g"),"FragColor")}let aCounter=0;const D=[];C.vertexSource=C.vertexSource.replace(/attribute ([a-z]+[0-4]*) ([_a-zA-Z,0-9\s]+);/g,function(F,E,G){let s="";G.split(",").forEach(function(I){const H=I.trim();s+="layout(location = "+aCounter+") in "+E+" "+H+";\n";D.push(H);++aCounter});return s});C.aatList=D}function a(D,C){if(C.initialized){return false}const B=JEContext.is_webgl2();if(!JESETTINGS.isNNGL&&!B){D.enableVertexAttribArray(0)}if(!("isMRT" in C)){C.isMRT=false}if(C.isMRT){C.fragment_preprocessing=e.get_GLSLHeaderMRT();C.OESVersion=(B)?3:2;C.precisionMRT=(B)?"none":"highp"}C.id=_shaderIdCount++;if(!("OESVersion" in C)){C.OESVersion=2}if(!("fragment_preprocessing" in C)){C.fragment_preprocessing=""}if(!("vertex_preprocessing" in C)){C.vertex_preprocessing=""}if(!("precision" in C)){C.precision="highp"}if(C.precision!=="none"){C.fragmentSource="precision "+C.precision+" float;\n"+C.fragmentSource}C.fragmentSource=C.fragment_preprocessing+C.fragmentSource;if(!("vertexSource" in C)){C.vertexSource="precision lowp float;\nattribute vec2 aat_position;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_Position = vec4(aat_position, 0., 1.);\n  vUV = (aat_position*0.5) + vec2(0.5,0.5);\n}"}C.vertexSource=C.vertex_preprocessing+C.vertexSource;console.log("INFO in JEShader - init_shader(): ",C.name);if(B&&C.OESVersion>=3){p(C)}if(C.replaces){C.replaces.forEach(function(E){C.vertexSource=C.vertexSource.replace(E.search,E.replace);C.fragmentSource=C.fragmentSource.replace(E.search,E.replace)})}C.program=A(D,C);C.uniforms={};C.uniformsNames.forEach(function(E){C.uniforms[E]=D.getUniformLocation(C.program,E)});C.attributes={};C.attributesNumArray=[];C.vertexByteSize=0;if(!("attributesNames" in C)){C.attributesNames=["aat_position"]}if(!("attributesDims" in C)){C.attributesDims=[2]}C.attributesNames.forEach(function(F,E){let attrib=null;if(B&&C.OESVersion>=3){attrib=C.aatList.indexOf(F)}else{attrib=D.getAttribLocation(C.program,F)}if(attrib===-1){console.log("ERROR in JEShaders - init_shader(): cannot found attribute",F,"in shader",C.name);}C.attributes[F]=attrib;C.attributesNumArray.push(attrib);const G=4*C.attributesDims[E];C.vertexByteSize+=G});C.set=function(){if(_currentShaderId===C.id){return}if(_currentShaderId!==-1){_currentShader.unset()}_currentShaderId=C.id;_currentShader=C;D.useProgram(C.program);C.attributesNumArray.forEach(function(E,F){if(E===0){return}D.enableVertexAttribArray(E)})};C.unset=function(){_currentShaderId=-1;C.attributesNumArray.forEach(function(E,F){if(E===0){return}D.disableVertexAttribArray(E)})};C.initialized=true}function o(C,B){a(C,B);B.set();_currentShaderId=-1;return B}function u(){return{name:"COPY",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_FragColor = texture2D(uun_source, vUV);\n} \n",uniformsNames:["uun_source"],precision:"highp"}}function d(){return{name:"HALF",fragmentSource:"void main(void) { gl_FragColor = vec4(0.5, 0.5, 0.5, 0.5); }",uniformsNames:[],precision:"highp"}}function n(){return{name:"HALF MRT",fragmentSource:"const vec4 HALF = vec4(0.5, 0.5, 0.5, 0.5); void main(void) { gl_FragData[0] = HALF; gl_FragData[1] = HALF; gl_FragData[2] = HALF; gl_FragData[3] = HALF;}",uniformsNames:[],precision:"highp",isMRT:true}}function z(){t.shp_copy=u();t.shp_copyInvY={name:"COPY INV Y",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_FragColor = texture2D(uun_source, vec2(vUV.x, 1.-vUV.y));\n} \n",uniformsNames:["uun_source"],precision:"highp"};t.shp_copyLow={name:"COPY LOW",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_FragColor = texture2D(uun_source, vUV);\n} \n",uniformsNames:["uun_source"],precision:"lowp"};t.shp_mix={name:"MIX",fragmentSource:"uniform sampler2D uun_source, uun_destination;\nuniform float uun_alpha;\n\nvarying vec2 vUV;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\nvoid main(void) {\n  gl_FragColor = vec4(mix(texture2D(uun_destination, vUV).rgb, texture2D(uun_source, vUV).rgb, uun_alpha * ONE3), 1.);\n} \n",uniformsNames:["uun_source","uun_destination","uun_alpha"],precision:"highp"};t.shp_mixRGBE={name:"MIX RGBE",fragmentSource:"uniform sampler2D uun_source, uun_destination;\nuniform float uun_alpha;\n\nvarying vec2 vUV;\n\nconst vec4 ONE4 = vec4(1.,1.,1.,1.);\n\nvoid main(void) {\n  gl_FragColor = mix(texture2D(uun_destination, vUV), texture2D(uun_source, vUV), uun_alpha * ONE4);\n} \n",uniformsNames:["uun_source","uun_destination","uun_alpha"],precision:"highp"};t.shp_fakeMipmap={name:"FAKE MIPMAP GENERATION",fragmentSource:"uniform sampler2D uun_source, uun_avg;\nuniform vec2 uun_uvFactor;\nuniform float uun_edge, uun_gamma;\n\nvarying vec2 vUV;\n\nconst vec4 ONE4 = vec4(1.0,1.0,1.0,1.0);\n\n\nvoid main(void) {\n  vec4 colorAvg = texture2D(uun_avg, vUV * uun_uvFactor);\n  vec4 color = texture2D(uun_source, vUV * uun_uvFactor);\n\n  float t = smoothstep(uun_edge, 0., vUV.y);\n  t += smoothstep(1.-uun_edge, 1., vUV.y);\n  \n  gl_FragColor = pow(mix(color,colorAvg, t*ONE4), uun_gamma * ONE4);\n} \n",uniformsNames:["uun_source","uun_uvFactor","uun_avg","uun_edge","uun_gamma"]};t.shp_fakeMipmapRGBE={name:"FAKE MIPMAP GENERATION RGBE",fragmentSource:"uniform sampler2D uun_source, uun_avg;\nuniform vec2 uun_uvFactor;\nuniform float uun_edge, uun_gamma;\n\nvarying vec2 vUV;\n\nconst vec3 ONE3 = vec3(1.0,1.0,1.0);\n\n\nvec4 RGBtoRGBE(vec3 color){\n  vec3 value = color / 65536.0;\n  vec3 exponent = clamp(ceil(log2(value)), -128.0, 127.0);\n  float commonExponent = max(max(exponent.r, exponent.g), exponent.b);\n  float range = exp2(commonExponent);\n  vec3 mantissa = clamp(value / range, 0.0, 1.0);\n  return vec4(mantissa, (commonExponent + 128.0)/256.0);\n}\n\n\nvoid main(void) {\n  vec2 uv = vUV * uun_uvFactor;\n  \n  // mirror the texture along X axis:\n  float uRound = floor(uv.x);\n  float isOdd = mod(uRound, 2.0);\n  uv.x = mod(uv.x, 1.0); // repeat\n  uv.x = mix(uv.x, 1.0 - uv.x, isOdd); // mirror\n\n  vec3 colorAvg = texture2D(uun_avg, uv).rgb;\n  vec3 color = texture2D(uun_source, uv).rgb;\n\n  float t = smoothstep(uun_edge, 0., vUV.y);\n  t += smoothstep(1.-uun_edge, 1., vUV.y);\n  \n  vec3 zou = mix(color,colorAvg, t * ONE3);\n  vec4 rgbe = RGBtoRGBE(pow(zou, uun_gamma*ONE3));\n  \n  gl_FragColor = rgbe;\n\n  // DEBUG ZONE:\n  //gl_FragColor = mix(gl_FragColor, vec4(1., 0., 0., 1.0), step(1.0, uv.x) );\n} \n",uniformsNames:["uun_source","uun_uvFactor","uun_avg","uun_edge","uun_gamma"],precision:"highp"};t.shp_postProcessing={name:"POSTPROCESSING",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec4 color = texture2D(uun_source, vUV);\n  if (color.a < 0.5){\n    discard;\n  }\n  \n  gl_FragColor=color;\n} \n",uniformsNames:["uun_source"],precision:"lowp"};t.shp_postProcessingMSAA={name:"POSTPROCESSING with 4X MSAA",fragmentSource:"//OBSOLETE : PREFER FXAA\n\nuniform sampler2D uun_source, uun_previous; \nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\n\n//4X MSAA\nconst vec2 TOPLEFT = vec2(-0.9, 0.4);\nconst vec2 TOPRIGHT = vec2(0.4, 0.9);\nconst vec2 BOTTOMLEFT = vec2(-0.4, -0.9);\nconst vec2 BOTTOMRIGHT = vec2(0.9, -0.4);\n\n\nvoid main(void) {\n  vec2 uv = vUV;\n  \n  vec3 color = texture2D(uun_source, uv).rgb\n        +texture2D(uun_source, uv + uun_dxy * TOPLEFT).rgb\n        +texture2D(uun_source, uv + uun_dxy * TOPRIGHT).rgb\n        +texture2D(uun_source, uv + uun_dxy * BOTTOMLEFT).rgb\n        +texture2D(uun_source, uv + uun_dxy * BOTTOMRIGHT).rgb;\n\n  gl_FragColor = vec4(color/5., 1.);\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_postProcessingMSAAkinetic={name:"POSTPROCESSING with 4X MSAA WITH KINETIC BLUR",fragmentSource:"//OBSOLETE : PREFER FXAA\n\nuniform sampler2D uun_source, uun_previous, uun_state; \nuniform vec2 uun_dxy, uun_kineticRange;\n\nvarying vec2 vUV;\n\nconst vec3 ONE3=vec3(1.,1.,1.);\n\n//4X MSAA\nconst vec2 TOPLEFT = vec2(-0.9, 0.4);\nconst vec2 TOPRIGHT = vec2(0.4, 0.9);\nconst vec2 BOTTOMLEFT = vec2(-0.4, -0.9);\nconst vec2 BOTTOMRIGHT = vec2(0.9, -0.4);\n\n\nvoid main(void) {\n  vec2 uv = vUV;\n  \n  vec3 color = texture2D(uun_source, uv).rgb\n        +texture2D(uun_source, uv+uun_dxy*TOPLEFT).rgb\n        +texture2D(uun_source, uv+uun_dxy*TOPRIGHT).rgb\n        +texture2D(uun_source, uv+uun_dxy*BOTTOMLEFT).rgb\n        +texture2D(uun_source, uv+uun_dxy*BOTTOMRIGHT).rgb;\n\n  float qualityNormalized = texture2D(uun_state, vec2(0.75,0.5)).a;\n  float kineticCoeff = uun_kineticRange.x + pow(qualityNormalized, 2.)*(uun_kineticRange.y-uun_kineticRange.x);\n\n  vec3 colMixed = mix(color/5., texture2D(uun_previous, uv).rgb, kineticCoeff);\n\n  gl_FragColor = vec4(colMixed, 1.);\n\n  //DEBUG ZONE :\n  //gl_FragColor=vec4(1.,0.,0.,1.);\n  //gl_FragColor=texture2D(uun_previous, uv);\n\n  //cool effect : \n  //gl_FragColor=vec4(length(color-5.*texture2D(uun_source, uv)), 0.,0.,1.);\n} \n",uniformsNames:["uun_source","uun_previous","uun_dxy","uun_state","uun_kineticRange"],precision:"lowp"};t.shp_postProcessingFXAA={name:"POSTPROCESSING with FXAA",fragmentSource:"/**\n * @author alteredq / http://alteredqualia.com/\n * @author davidedc / http://www.sketchpatch.net/\n *\n * NVIDIA FXAA by Timothy Lottes\n * http://timothylottes.blogspot.com/2011/06/fxaa3-source-released.html\n * - WebGL port by @supereggbert\n * http://www.glge.org/demos/fxaa/\n */\n\nuniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\n\nconst vec3 LUMA = vec3( 0.299, 0.587, 0.114 );\nconst float FXAA_REDUCE_MIN  = 1.0/128.0;\nconst float FXAA_REDUCE_MUL = 1.0/8.0;\nconst float FXAA_SPAN_MAX = 8.0;\n\n\nvoid main(void) {\n  vec2 uv=vUV;\n\n  vec3 rgbNW = texture2D( uun_source, vUV + vec2( -1.0, -1.0 ) * uun_dxy ).xyz;\n  vec3 rgbNE = texture2D( uun_source, vUV + vec2( 1.0, -1.0 ) * uun_dxy ).xyz;\n  vec3 rgbSW = texture2D( uun_source, vUV + vec2( -1.0, 1.0 ) * uun_dxy ).xyz;\n  vec3 rgbSE = texture2D( uun_source, vUV + vec2( 1.0, 1.0 ) * uun_dxy ).xyz;\n\n  \n  vec3 rgbM  = texture2D( uun_source,  vUV ).xyz;\n    \n\n  float lumaNW = dot( rgbNW, LUMA );\n  float lumaNE = dot( rgbNE, LUMA );\n  float lumaSW = dot( rgbSW, LUMA );\n  float lumaSE = dot( rgbSE, LUMA );\n  float lumaM  = dot( rgbM,  LUMA );\n  float lumaMin = min( lumaM, min( min( lumaNW, lumaNE ), min( lumaSW, lumaSE ) ) );\n  float lumaMax = max( lumaM, max( max( lumaNW, lumaNE) , max( lumaSW, lumaSE ) ) );\n\n  vec2 dir;\n  dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE));\n  dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));\n\n  float dirReduce = max( ( lumaNW + lumaNE + lumaSW + lumaSE ) * ( 0.25 * FXAA_REDUCE_MUL ), FXAA_REDUCE_MIN );\n\n  float rcpDirMin = 1.0 / ( min( abs( dir.x ), abs( dir.y ) ) + dirReduce );\n  dir = min( vec2( FXAA_SPAN_MAX,  FXAA_SPAN_MAX),\n      max( vec2(-FXAA_SPAN_MAX, -FXAA_SPAN_MAX),\n        dir * rcpDirMin)) * uun_dxy;\n  vec3 rgbA = (1.0/2.0) * (\n  texture2D(uun_source,  vUV  + dir * (1.0/3.0 - 0.5)).rgb +\n  texture2D(uun_source,  vUV  + dir * (2.0/3.0 - 0.5)).rgb);\n  vec3 rgbB = rgbA * (1.0/2.0) + (1.0/4.0) * (\n  texture2D(uun_source,  vUV + dir * (0.0/3.0 - 0.5)).rgb +\n  texture2D(uun_source,  vUV + dir * (3.0/3.0 - 0.5)).rgb);\n  float lumaB = dot(rgbB, LUMA);\n\n  if ( ( lumaB < lumaMin ) || ( lumaB > lumaMax ) ) {\n\n    gl_FragColor = vec4(rgbA, 1.);\n     // gl_FragColor = vec4(1.,0.,0.,1.);\n  } else {\n\n    gl_FragColor = vec4(rgbB, 1.);\n    //gl_FragColor = vec4(0.,1.,0.,1.);\n\n  }\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_postProcessingMSAAalpha={name:"POSTPROCESSING with 4X MSAA with alpha",fragmentSource:"//OBSOLETE : PREFER FXAA\n\nuniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\n//4X MSAA\nconst vec2 TOPLEFT = vec2(-0.9, 0.4);\nconst vec2 TOPRIGHT = vec2(0.4, 0.9);\nconst vec2 BOTTOMLEFT = vec2(-0.4, -0.9);\nconst vec2 BOTTOMRIGHT = vec2(0.9, -0.4);\n\n\nvoid main(void) {\n  vec2 uv = vUV;\n  \n  vec4 color = texture2D(uun_source, uv)\n        +texture2D(uun_source, uv + uun_dxy * TOPLEFT)\n        +texture2D(uun_source, uv + uun_dxy * TOPRIGHT)\n        +texture2D(uun_source, uv + uun_dxy * BOTTOMLEFT)\n        +texture2D(uun_source, uv + uun_dxy * BOTTOMRIGHT);\n\n  \n  gl_FragColor = color / 5.;\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.RGBEtoRGB={name:"RGBEtoRGB",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\n\nvec3 RGBEtoRGB(vec4 color){\n  float exponent = color.a * 256.0 - 128.0;\n  vec3 mantissa = color.rgb;\n  return exp2(exponent) * mantissa * 65536.0;\n}\n\n// from http://www.graphics.cornell.edu/~bjw/rgbe/rgbe.c\nvoid main(void) {\n	vec4 color = texture2D(uun_source, vUV);\n	gl_FragColor = vec4(RGBEtoRGB(color), 1.);\n} \n",uniformsNames:["uun_source"],precision:"highp"};t.shp_RGBtoRGBE={name:"RGB to RGBE",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nconst vec3 ZERO3 = vec3(0.,0.,0.);\n\nvec4 RGBtoRGBE(vec3 color){\n  vec3 value = color / 65536.0;\n  vec3 exponent = clamp(ceil(log2(value)), -128.0, 127.0);\n  float commonExponent = max(max(exponent.r, exponent.g), exponent.b);\n  float range = exp2(commonExponent);\n  vec3 mantissa = clamp(value / range, 0.0, 1.0);\n  return vec4(mantissa, (commonExponent + 128.0)/256.0);\n}\n\n\n// from http://www.graphics.cornell.edu/~bjw/rgbe/rgbe.c\nvoid main(void) {\n  vec3 color = texture2D(uun_source, vUV).rgb;\n  gl_FragColor = RGBtoRGBE(max(color, ZERO3));\n} \n",uniformsNames:["uun_source"],precision:"highp"};t.shp_envLight={name:"ENV LIGHT",fragmentSource:"uniform sampler2D uun_env, uun_light;\nuniform float uun_lightCoefficient, uun_envLightCoefficient;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec3 colorLight = texture2D(uun_light, vUV).rgb;\n  vec3 colorEnv = texture2D(uun_env, vUV).rgb;\n\n  gl_FragColor = vec4(colorEnv*uun_envLightCoefficient + uun_lightCoefficient * colorLight, 1.);\n} \n",uniformsNames:["uun_env","uun_light","uun_lightCoefficient","uun_envLightCoefficient"],precision:"highp"};t.shp_irradiance={name:"IRRADIANCE",fragmentSource:"uniform sampler2D uun_envLight, uun_random;\nuniform float uun_gamma;\n\nvarying vec2 vUV;\n\nconst int N = 8888;\nconst float PI = 3.141592;\nconst vec2 ZERO2 = vec2(0.,0.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec3 ZERO3 = vec3(0.,0.,0.);\n\nvoid main(void) {\n  // current irradiance spherical coordinates:\n  float theta = PI * ((vUV.x*2.0)-1.0);     //between -PI and PI\n  float phi=(PI/2.0)*((vUV.y*2.0)-1.0); //between -PI/2 and PI/2\n\n  // sampling:\n  float sampleTheta, samplePhi, sampleColor;\n  float sampleTheta0, samplePhi0;\n  vec4 sampleRandom;\n  vec3 color = ZERO3;\n  vec2 uv = ZERO2;\n  vec2 uvRandom = ZERO2;\n\n  for (int i=0; i<N; i+=1){\n    uvRandom.x = float(i);\n    uvRandom.y = floor(uvRandom.x/64.0);\n    sampleRandom = texture2D(uun_random, uvRandom/64.0);\n    sampleTheta = PI * sampleRandom.r;              //between -PI and PI\n    samplePhi = 2.0 * asin(sqrt(0.25+sampleRandom.g*0.25));\n\n    sampleTheta0 = theta + samplePhi * cos(sampleTheta);\n    samplePhi0 = phi + samplePhi * sin(sampleTheta);\n\n    uv.x = 0.5 + 0.5 * sampleTheta0 / PI; //between 0 and 1\n    uv.y = 0.5 + samplePhi0/PI;       //between 0 and 1\n\n    color += pow(texture2D(uun_envLight, uv).rgb, uun_gamma*ONE3);\n  }\n\n  color /= float(N);\n  gl_FragColor = vec4(color, 1.0);\n\n  // DEBUG ZONE:\n  //gl_FragColor=texture2D(envLight, vUV); return;\n  //gl_FragColor=texture2D(random, vUV); return;\n  //gl_FragColor=vec4(vUV, 0.0, 1.0);\n} \n",uniformsNames:["uun_envLight","uun_random","uun_gamma"],precision:"lowp",replaces:[{search:"8888",replace:JESETTINGS.irradianceNumberRays[JEContext.get_level()]}]};t.shp_glowBlur={name:"GLOW BLUR",fragmentSource:"uniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec4 col0 = texture2D(uun_source, vUV);\n\n  float glowBlurred =\n      (8./254.) * texture2D(uun_source, vUV-3.*uun_dxy).a\n       +(28./254.) * texture2D(uun_source, vUV-2.*uun_dxy).a\n       +(56./254.) * texture2D(uun_source, vUV-uun_dxy).a\n       +(70./254.) * col0.a\n       +(56./254.) * texture2D(uun_source, vUV+uun_dxy).a\n       +(28./254.) * texture2D(uun_source, vUV+2.*uun_dxy).a\n       +(8./254.)  * texture2D(uun_source, vUV+3.*uun_dxy).a;\n\n  gl_FragColor = vec4(col0.rgb, 4.*glowBlurred);\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_glowApply={name:"GLOW APPLY",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\nvoid main(void) {\n  vec4 color = texture2D(uun_source, vUV);\n  float glow = 0.3 * pow(color.a, 2.);\n\n  gl_FragColor=vec4(color.rgb + glow * ONE3, 1.);\n} \n",uniformsNames:["uun_source"],precision:"lowp"};t.shp_blur={name:"GAUSSIAN BLUR",fragmentSource:"uniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n\n  vec4 col = (8./254.) * texture2D(uun_source, vUV-3.*uun_dxy)\n       + (28./254.) * texture2D(uun_source, vUV-2.*uun_dxy)\n       + (56./254.) * texture2D(uun_source, vUV-uun_dxy)\n       + (70./254.) * texture2D(uun_source, vUV)\n       + (56./254.) * texture2D(uun_source, vUV+uun_dxy)\n       + (28./254.) * texture2D(uun_source, vUV+2.*uun_dxy)\n       + (8./254.)  * texture2D(uun_source, vUV+3.*uun_dxy);\n       \n  gl_FragColor = col;\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_fastBlur={name:"FAST BLUR",fragmentSource:"uniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec4 col=texture2D(uun_source, vUV-3.*uun_dxy)\n       + texture2D(uun_source, vUV-2.*uun_dxy)\n       + texture2D(uun_source, vUV-uun_dxy)\n       + texture2D(uun_source, vUV)\n       + texture2D(uun_source, vUV+uun_dxy)\n       + texture2D(uun_source, vUV+2.*uun_dxy)\n       + texture2D(uun_source, vUV+3.*uun_dxy);\n       \n  gl_FragColor = col / 7.;\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_avgLineColor={name:"AVERGAGE LINE COLOR",fragmentSource:"uniform sampler2D uun_source;\n\nvarying vec2 vUV;\n\nconst vec4 ZERO4 = vec4(0.,0.,0.,0.);\n\nconst float N = 256.;\n\nvoid main(void) {\n  vec4 avgColor = ZERO4;\n  float n = 0.0;\n  vec2 uv;\n  for (float i=0.0; i<N; i+=1.0){\n    uv = vec2((i + 0.5)/N, vUV.y);\n    avgColor += texture2D(uun_source, uv);\n    n += 1.0;\n  }\n\n  gl_FragColor = avgColor / n;\n  \n  // DEBUG ZONE:\n  //gl_FragColor = vec4(1., 0., 0., 1.);\n} \n",uniformsNames:["uun_source"],precision:"highp"};t.shp_irradianceSeamless={name:"IRRADIANCE SEAMLESS",fragmentSource:"uniform sampler2D uun_source, uun_avg;\n\nvarying vec2 vUV;\n\nconst vec4 ONE4 = vec4(1.0,1.0,1.0,1.0);\nconst float POLEEDGE0 = 0.0; //between 0 and 0.5\nconst float POLEEDGE1 = 0.3; //should be upper to POLEEDGE0\n\nvoid main(void) {\n  vec4 colorAvg = texture2D(uun_avg, vUV);\n  vec4 color = texture2D(uun_source, vUV);\n\n  float t = smoothstep(POLEEDGE1, POLEEDGE0, vUV.y);\n  t += smoothstep(1.-POLEEDGE1, 1.-POLEEDGE0, vUV.y);\n\n  gl_FragColor = mix(color,colorAvg, t * ONE4);\n} \n",uniformsNames:["uun_source","uun_avg"],precision:"highp"};t.shp_irradianceSeamlessRGBE={name:"IRRADIANCE SEAMLESS RGBE",fragmentSource:"uniform sampler2D uun_source, uun_avg;\n\nvarying vec2 vUV;\n\nconst vec3 ONE3 = vec3(1.0,1.0,1.0);\nconst float POLEEDGE0 = 0.0; //between 0 and 0.5\nconst float POLEEDGE1 = 0.3; //should be upper to POLEEDGE0\n\n\nvec4 RGBtoRGBE(vec3 color){\n  vec3 value = color / 65536.0;\n  vec3 exponent = clamp(ceil(log2(value)), -128.0, 127.0);\n  float commonExponent = max(max(exponent.r, exponent.g), exponent.b);\n  float range = exp2(commonExponent);\n  vec3 mantissa = clamp(value / range, 0.0, 1.0);\n  return vec4(mantissa, (commonExponent + 128.0)/256.0);\n}\n\n\nvoid main(void) {\n  vec3 colorAvg = texture2D(uun_avg, vUV).rgb;\n  vec3 color = texture2D(uun_source, vUV).rgb;\n\n  float t = smoothstep(POLEEDGE1, POLEEDGE0, vUV.y);\n  t += smoothstep(1.-POLEEDGE1, 1.-POLEEDGE0, vUV.y);\n\n  gl_FragColor = RGBtoRGBE(mix(color,colorAvg, t*ONE3));\n\n  // DEBUG ZONE:\n  //gl_FragColor=vec4(color, 1.);\n  //gl_FragColor=vec4(colorAvg, 1.);\n\n  //gl_FragColor=vec4(1.,0.,0.,1.);\n} \n",uniformsNames:["uun_source","uun_avg"],precision:"highp"};t.shp_loading={name:"NNGL LOADING",fragmentSource:"uniform sampler2D uun_source, uun_background, uun_mask, uun_nngl;\nuniform vec4 uun_loadingColor;\nuniform vec2 uun_loadingScale;\nuniform float uun_time, uun_loadingAngle, uun_forceDisableLoading;\n\nvarying vec2 vUV;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec2 HALF2 = vec2(0.5,0.5);\nconst float PI = 3.141592;\n\n\nvoid main(void) {\n  \n  vec4 color = texture2D(uun_source, vUV);\n  vec4 backgroundColor = texture2D(uun_background, vec2(1.-vUV.x, vUV.y));\n\n  float isDetected = step(texture2D(uun_nngl, vec2(0.25,0.5)).r, 1.);\n\n  vec2 uvCentered = (vUV*2.0) - ONE2;\n  float mask=texture2D(uun_mask, uvCentered * uun_loadingScale * 0.5 + HALF2).r;\n\n  //uun_time encodes the theta\n  float pixelTheta = atan(uvCentered.x, uvCentered.y);\n  float radarTheta = -(mod(uun_time, 2.0*PI)-PI);\n  float dTheta = mod(pixelTheta-radarTheta+PI, 2.0*PI)-PI;\n  float maskAtt = 1.-smoothstep(0., uun_loadingAngle, dTheta);\n  maskAtt *= (sign(dTheta)+1.)/2.;\n\n  vec4 loadingColor = backgroundColor + maskAtt * uun_loadingColor*mask;\n  gl_FragColor = mix(color, loadingColor, isDetected*uun_forceDisableLoading);\n\n  // DEBUG ZONE:\n  //gl_FragColor=vec4(maskAtt, 0.,0.,1.);\n  //gl_FragColor=mask*vec4(1.,1.,1.,1.);\n  //gl_FragColor=vec4((0.1*texture2D(uun_nngl, vec2(0.25,0.5)).a-1.)*100., 0.,0.,1.);\n} \n",uniformsNames:["uun_source","uun_mask","uun_nngl","uun_background","uun_loadingColor","uun_time","uun_loadingAngle","uun_forceDisableLoading","uun_loadingScale"],precision:"lowp"};const B=["uun_uposition","uun_normals","uun_diffuse","uun_matParams","uun_envLight","uun_irradiance","uun_bias","uun_camera","uun_background","uun_envLightSize","uun_angleReflectOnHead","uun_reflectOnHeadColor","uun_dAngleReflectOnHead","uun_reflectOnHeadFactor"];if(JESETTINGS.aoEnable){t.shp_deferred={name:"DEFERRED",fragmentSource:"uniform sampler2D uun_uposition, uun_normals, uun_diffuse, uun_matParams, uun_envLight, uun_irradiance, uun_ao, uun_background;\nuniform vec3 uun_camera, uun_reflectOnHeadColor;\nuniform float uun_bias, uun_aoMax, uun_angleReflectOnHead, uun_dAngleReflectOnHead, uun_envLightSize;\n\nvarying vec2 vUV;\n\nconst vec3 ZERO3 = vec3(0.,0.,0.);\nconst float PI = 3.141592;\nconst vec3 LUMA = vec3( 0.299, 0.587, 0.114 );\nconst float GLOWMAX = 2.;\n\n\nvec3 RGBEtoRGB(vec4 color){\n  float exponent = color.a * 256.0 - 128.0;\n  vec3 mantissa = color.rgb;\n  return exp2(exponent) * mantissa * 65536.0;\n}\n\nvec2 compute_uv(vec3 direction){\n  float theta = atan(direction.x, direction.z); //+thetaOffset;  \n  float phi = acos(-direction.y);\n  return vec2(0.5 - 0.5*theta/PI, 1.-phi/PI);\n}\n\nvec2 compute_uvFakeMipmap(vec3 direction, float mipmapLevel){\n  vec2 mipmapScale = vec2(1.,0.5) / pow(2.0, mipmapLevel);\n  vec2 mipmapOffset = vec2(0., 1.-pow(0.5, mipmapLevel));\n\n  float theta = atan(direction.x, direction.z); //+thetaOffset;  \n  float phi = acos(-direction.y);\n  \n  float un = 0.5 + 0.5*theta/PI;\n  float vn = phi/PI;\n\n  float du = pow(2.0, mipmapLevel) / uun_envLightSize;\n  un = (1.0 - du) * un;\n  \n  return mipmapOffset + vec2(un, vn) * mipmapScale;\n}\n\nvoid main(void) {\n  vec4 co4 = texture2D(uun_uposition, vUV);\n  vec3 bgColor = texture2D(uun_background, vec2(1.-vUV.x, vUV.y)).rgb;\n\n  if (co4.a<0.01) {\n    gl_FragColor = vec4(bgColor, 0.);\n    return;\n  }\n\n  float forcedAlpha = co4.a;\n\n  vec3 co = co4.rgb;\n  vec3 look = co + uun_camera;  \n\n  vec4 material = texture2D(uun_matParams, vUV);\n  \n  vec4 no4 = texture2D(uun_normals, vUV);\n  vec3 no = no4.rgb;\n  float alpha = no4.a;\n\n  vec4 colorDiffuseFP = texture2D(uun_diffuse, vUV);\n  vec3 colorDiffuse = colorDiffuseFP.rgb;\n\n  float fresnelMin = material.r;\n  float roughness = material.g;\n  \n  float fresnelPowMax = floor(material.b*255.);\n  float fresnelPow = floor(fresnelPowMax/16.);\n  float fresnelMax = (fresnelPowMax-16.*fresnelPow) / 16.;\n  fresnelPow /= 16.;\n\n  float metalness = material.a;\n\n  alpha = 1. - (1.0-alpha) * (1.-colorDiffuseFP.a);\n\n  // diffuse light:\n  vec2 uvDiffuse = compute_uv(-no);\n  vec3 lightDiffuse = (1.-metalness) * RGBEtoRGB(texture2D(uun_irradiance, uvDiffuse));\n  \n  // specular light:\n  vec3 lookDirection = normalize(look);\n  vec3 lightSpecular = ZERO3;\n  vec3 r = reflect(-lookDirection, no);  \n  vec2 uvSpecular = compute_uvFakeMipmap(r, floor(roughness*uun_bias));\n  float angleReflect = acos(-r.z);\n    \n  float reflectOnHeadCoeff = smoothstep(uun_angleReflectOnHead-uun_dAngleReflectOnHead, uun_angleReflectOnHead + uun_dAngleReflectOnHead, angleReflect);\n  lightSpecular = mix(RGBEtoRGB(texture2D(uun_envLight, uvSpecular)), uun_reflectOnHeadColor, reflectOnHeadCoeff);\n  \n  // use Schlick approx to compute fresnel:\n  // fresnel=1 -> fully reflected, 0 -> fully refracted\n  float fresnel = fresnelMin + (fresnelMax-fresnelMin) * pow(1.-dot(no, -lookDirection),fresnelPow*16.);\n  fresnel = clamp(fresnel, 0.,1.);\n\n  // ambient occlusion:\n  float aoFactor = 1. - uun_aoMax * texture2D(uun_ao, vUV).r;\n  lightSpecular *= pow(aoFactor, 2.);\n  lightDiffuse *= aoFactor;\n\n  \n  vec3 color = colorDiffuse * mix(lightDiffuse, lightSpecular, fresnel);\n  vec3 mixedColor = mix(bgColor, color, forcedAlpha * (alpha * (1.-fresnel) + fresnel));\n\n  float glowIntensity = dot(color, LUMA);\n  float alphaGlow = max(0., (glowIntensity-1.) / (GLOWMAX-1.));\n\n  gl_FragColor=vec4(color, alphaGlow);\n  \n  // DEBUG ZONE:\n  //gl_FragColor=vec4(co/100.,1.);\n  //gl_FragColor=vec4(no,1.);\n  //gl_FragColor=vec4(lightSpecular, 1.);\n  //gl_FragColor=lightSpecular;\n  //gl_FragColor=texture2D(envLight, vUV);     \n}\n",uniformsNames:B.concat(["uun_ao","uun_aoMax"]),precision:"highp"}}t.shp_deferredNoAO={name:"DEFERRED NOAO",fragmentSource:"uniform sampler2D uun_uposition, uun_normals, uun_diffuse, uun_matParams, uun_envLight, uun_irradiance, uun_background;\nuniform vec3 uun_camera, uun_reflectOnHeadColor;\nuniform float uun_bias, uun_angleReflectOnHead, uun_dAngleReflectOnHead, uun_reflectOnHeadFactor, uun_postProcessingGamma, uun_postProcessingSaturation, uun_envLightSize;\n\nvarying vec2 vUV;\n\nconst vec3 ZERO3 = vec3(0.,0.,0.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst float PI = 3.141592;\nconst vec3 LUMA = vec3( 0.299, 0.587, 0.114 );\nconst float GLOWMAX = 2.;\n\nvec3 RGBEtoRGB(vec4 color){\n  float exponent = color.a * 256.0 - 128.0;\n  vec3 mantissa = color.rgb;\n  return exp2(exponent) * mantissa * 65536.0;\n}\n\n// for diffuse light:\nvec2 compute_uv(vec3 direction){\n  float theta = atan(direction.x, -direction.z);\n  float phi = acos(-direction.y);\n  return vec2(0.5-0.5*theta/PI, 1.-phi/PI);\n}\n\n// for specular light:\nvec2 compute_uvFakeMipmap(vec3 direction, float mipmapLevel){\n  float pw = pow(2.0, mipmapLevel);\n\n  vec2 mipmapScale = vec2(1., 0.5) / pw;\n  vec2 mipmapOffset = vec2(0., 1. - 1.0/pw);\n\n  float theta = atan(direction.x, direction.z); // in [-PI, PI]\n  float phi = acos(-direction.y); // in [0, PI]\n\n  float un = 0.5 + 0.5*theta/PI;\n  float vn = phi/PI;\n\n  float du = 0.5 * pw / uun_envLightSize;\n  un = (1.0 - du) * un;\n  \n  return mipmapOffset + vec2(un, vn) * mipmapScale;\n  //return mipmapOffset + vec2(0.5 + 0.5*theta/PI, 0.025 + 0.95*phi/PI )*mipmapScale;\n}\n\nvoid main(void) {\n  vec4 co4 = texture2D(uun_uposition, vUV);\n  vec4 bgColor = texture2D(uun_background, vec2(1.-vUV.x, vUV.y));\n \n  if (co4.a<0.01) {\n    gl_FragColor = vec4(bgColor.rgb, 0.);\n    return;\n  }\n\n  float forcedAlpha = co4.a;\n\n  vec3 co = co4.rgb;\n  vec3 look = co + uun_camera;  \n\n  vec4 material = texture2D(uun_matParams, vUV);\n  \n  vec4 no4 = texture2D(uun_normals, vUV);\n  vec3 no = no4.rgb;\n  float alpha = no4.a;\n\n \n  vec4 colorDiffuseFP = texture2D(uun_diffuse, vUV);\n  vec3 colorDiffuse = colorDiffuseFP.rgb;\n  if (forcedAlpha > 1.){\n    gl_FragColor = vec4(mix(bgColor.rgb, colorDiffuse, colorDiffuseFP.a), 1.);\n    return;\n  }\n\n  // input gamma correction:\n  colorDiffuse = pow(colorDiffuse, uun_postProcessingGamma * ONE3);\n  \n  float fresnelMin = material.r;\n  float roughness = material.g;\n  float metalness = material.a;\n\n  // demultiplex fresnelPow and fresnelMax from blue channel:\n  float fresnelPowMax = floor(material.b*255.);\n  float fresnelPow = floor(fresnelPowMax/16.);\n  float fresnelMax = (fresnelPowMax-16.*fresnelPow) / 16.;\n  fresnelPow /= 16.;\n  \n  alpha = 1. - (1.0-alpha) * (1.-colorDiffuseFP.a);\n  \n  // diffuse light:\n  vec2 uvDiffuse = compute_uv(no);\n  vec3 colorIrradiance = RGBEtoRGB(texture2D(uun_irradiance, uvDiffuse));\n  \n  vec3 lightDiffuse = (1.-metalness) * colorIrradiance;\n  \n  // specular light:\n  vec3 lookDirection = normalize(look);\n  vec3 lightSpecular = ZERO3;\n  vec3 r = reflect(-lookDirection, no);  \n  float roughnessIndex = floor(roughness*uun_bias);\n  vec2 uvSpecular = compute_uvFakeMipmap(r, roughnessIndex);\n  \n  float angleReflect = acos(-r.z);\n  float reflectOnHeadCoeff = smoothstep(uun_angleReflectOnHead-uun_dAngleReflectOnHead, uun_angleReflectOnHead+uun_dAngleReflectOnHead, angleReflect);\n  vec3 colorEnv = RGBEtoRGB(texture2D(uun_envLight, uvSpecular));\n  lightSpecular = mix(colorEnv, uun_reflectOnHeadColor, reflectOnHeadCoeff * uun_reflectOnHeadFactor);\n  \n  // use Schlick approx to compute fresnel:\n  // fresnel=1 -> fully reflected, 0 -> fully refracted\n  float fresnel = fresnelMin + (fresnelMax-fresnelMin) * pow(1.+dot(no, lookDirection), fresnelPow*15.);\n  fresnel = clamp(fresnel, 0.,1.);\n\n  vec3 glassesColor = colorDiffuse * mix(lightDiffuse, lightSpecular, fresnel); //correction 2016-10-19 - apply colorDiffuse to both lightings\n  float totalAlpha = forcedAlpha * (alpha*(1.-fresnel)+fresnel);\n  vec3 color = mix(bgColor.rgb, pow(glassesColor, ONE3/uun_postProcessingGamma), totalAlpha);\n  \n  // we use the alpha channel to store the HDR luminosity\n  // no glow -> =0\n  // glow max -> 1\n  float grayScale = dot(color, LUMA);\n  float alphaGlow = max(0., (grayScale-1.) / (GLOWMAX-1.));\n\n  // POSTPROCESSING:\n  // saturation :\n  color = mix(grayScale*ONE3, color, mix(1., uun_postProcessingSaturation, totalAlpha) * ONE3);\n\n  //OUTPUT\n  //DO NOT REMOVE the //end at the end of the following line :\n  gl_FragColor = vec4(color, alphaGlow);//end\n  //this line is replaced in JEShaders.js if raw alpha output (serverFallback mode)\n\n  // DEBUG ZONE:\n  //gl_FragColor = vec4(1.,0.,0.,1.);\n  //gl_FragColor = vec4(glassesColor, 1.0);\n  //gl_FragColor = vec4(colorDiffuseFP.rgb,1.);\n  //gl_FragColor=vec4(color, 1.);\n  //gl_FragColor=vec4(co/100.,1.);\n  //gl_FragColor=vec4(no,1.);\n  //gl_FragColor=vec4(0.1 * lightDiffuse, 1.);\n  //gl_FragColor=vec4(uvDiffuse,0.,1.);\n  //gl_FragColor = vec4(lightSpecular, 1.0);\n  //gl_FragColor=texture2D(uun_envLight, vUV);\n  //gl_FragColor=vec4(colorIrradiance, 1.);\n  //gl_FragColor=vec4(lookDirection,1.); \n} \n",uniformsNames:B.concat(["uun_postProcessingGamma","uun_postProcessingSaturation"]),precision:"highp"};if(JESETTINGS.rawOutputWithAlpha){t.shp_deferredNoAO.fragmentSource=t.shp_deferredNoAO.fragmentSource.replace(/[^/]gl\_FragColor([^;]+)\;\/\/end/g,"gl_FragColor=vec4(color, totalAlpha);")}if(JESETTINGS.aoEnable){t.shp_AO={name:"AMBIENT OCCLUSION",fragmentSource:"/*PRECOMPILER_NOGLSLX*/uniform sampler2D uun_uposition, uun_normals;\nuniform mat4 uun_Vmatrix;\nuniform vec2 uun_ab, uun_dxy, uun_uvTilt;\nuniform float uun_theta, uun_opacity, uun_lightAtt, uun_aoDzFactor, uun_aoDzFactorMin, uun_aoSharpness, uun_maxDpEdge0, uun_maxDpEdge1, uun_aoMax;\n\nvarying vec2 vUV;\n\nconst float PI = 3.14159265;\nconst float HALFPI = 1.570796;\nconst float N = 8888.8; //12\n\n\nvoid main(void) {\n  vec2 uvt = vUV + uun_uvTilt;\n\n  vec4 pos = texture2D(uun_uposition, uvt);\n  if (pos.a<0.01) {\n    gl_FragColor = vec4(0.,0.,0.,1.);\n    return;\n  }\n\n  vec3 co0 = pos.rgb;\n  \n  float c = cos(uun_theta);\n  float s = sin(uun_theta);\n\n  vec3 no0 = texture2D(uun_normals, uvt).rgb;\n\n  // compute scale factor:\n  float zv = (uun_Vmatrix * vec4(co0, 1.)).z; //z in the view ref\n  vec2 scale = uun_ab / abs(zv);\n\n  // first ray:\n  vec2 uv; //uv of the point of the ray\n  vec3 co; //3D scene co of the point of the ray\n  vec2 duv = uun_dxy * vec2(c,s) * scale;\n  vec3 dp, dpn;\n\n  float dzMax = 0.;\n  float angleMin = 0.;\n  float angle;\n\n  for (float i=0.0; i<N; i+=1.0){\n    uv = uvt + i * duv;\n    co = texture2D(uun_uposition, uv).rgb;\n    dp = co - co0;\n    dpn = normalize(dp); //vector P0 P\n    angle = atan(dot(no0,dpn), length(cross(no0,dpn)));\n    angle *= 1. - smoothstep(uun_maxDpEdge0, uun_maxDpEdge1, length(dp));\n    angleMin = max(angleMin, angle);\n    dzMax = max(dzMax, sin(angle) * length(dp));\n  }\n\n  float angleMinInv = 0.;\n  for (float i=0.0; i<N; i+=1.0){\n    uv = uvt - i * duv;\n    co = texture2D(uun_uposition, uv).rgb;\n    dp = co - co0;\n    dpn = normalize(dp); //vector P0 P\n    angle = atan(dot(no0,dpn), length(cross(no0,dpn)));\n    angle *= 1.-smoothstep(uun_maxDpEdge0, uun_maxDpEdge1, length(dp));\n    dzMax = max(dzMax, sin(angle)*length(dp));\n    angleMinInv = max(angleMinInv, angle);\n  }\n\n\n  duv = uun_dxy*vec2(s,c)*scale;\n  float angleMin2 = 0.;\n  for (float i=0.0; i<N; i+=1.0){\n    uv = uvt + i * duv;\n    co = texture2D(uun_uposition, uv).rgb;\n    dp = co - co0;\n    dpn = normalize(dp); //vector P0 P    \n    angle = atan(dot(no0,dpn), length(cross(no0,dpn)));\n    angle *= 1. - smoothstep(uun_maxDpEdge0, uun_maxDpEdge1, length(dp));\n    dzMax = max(dzMax, sin(angle)*length(dp));\n    angleMin2 = max(angleMin2, angle);\n  }\n\n  float angleMin2Inv = 0.;\n  for (float i=0.0; i<N; i+=1.0){\n    uv = uvt - i * duv;\n    co = texture2D(uun_uposition, uv).rgb;\n    dp = co - co0;\n    dpn = normalize(dp); //vector P0 P\n    angle = atan(dot(no0,dpn), length(cross(no0,dpn)));\n    angle *= 1. - smoothstep(uun_maxDpEdge0, uun_maxDpEdge1, length(dp));\n    dzMax = max(dzMax, sin(angle)*length(dp));\n    angleMin2Inv = max(angleMin2Inv, angle);\n  }\n\n  float omegaMin = (PI/4.0) * (angleMin + angleMinInv) * (angleMin2 + angleMin2Inv);\n  \n  float dzFactor = clamp(dzMax/uun_aoDzFactor, uun_aoDzFactorMin, 1.);\n  float ao = dzFactor * clamp(uun_lightAtt*omegaMin*uun_aoSharpness, 0., uun_aoMax);\n    \n  gl_FragColor = vec4(ao,ao,ao,uun_opacity);\n} \n",uniformsNames:["uun_uposition","uun_normals","uun_lightAtt","uun_opacity","uun_theta","uun_dxy","uun_vTilt","uun_aoDzFactor","uun_aoDzFactorMin","uun_aoSharpness","uun_maxDpEdge0","uun_maxDpEdge1","uun_Vmatrix","uun_ab","uun_aoMax"],replaces:[{search:"8888.8",replace:JESETTINGS.aoRaySteps[JEContext.get_level()].toFixed(1)}],precision:"lowp"};t.shp_AOPostProcessing={name:"AMBIENT OCCLUSION POSTPROCESSING",fragmentSource:"uniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\nconst vec2 TOPLEFT = vec2(-0.9, 0.4);\nconst vec2 TOPRIGHT = vec2(0.4, 0.9);\nconst vec2 BOTTOMLEFT = vec2(-0.4, -0.9);\nconst vec2 BOTTOMRIGHT = vec2(0.9, -0.4);\n\nconst vec2 TOPLEFT2 = vec2(-1.9, 0.9);\nconst vec2 TOPRIGHT2 = vec2(0.9, 1.9);\nconst vec2 BOTTOMLEFT2 = vec2(-0.9, -1.9);\nconst vec2 BOTTOMRIGHT2 = vec2(1.9, -0.9);\n\n\nvoid main(void) {\n  vec2 uv = vUV;\n  \n  vec4 color = texture2D(uun_source, uv)\n        + texture2D(uun_source, uv + uun_dxy * TOPLEFT)\n        + texture2D(uun_source, uv + uun_dxy * TOPRIGHT)\n        + texture2D(uun_source, uv + uun_dxy * BOTTOMLEFT)\n        + texture2D(uun_source, uv + uun_dxy * BOTTOMRIGHT);\n\n  color += ( texture2D(uun_source, uv + uun_dxy * TOPLEFT2)\n        + texture2D(uun_source, uv + uun_dxy * TOPRIGHT2)\n        + texture2D(uun_source, uv + uun_dxy * BOTTOMLEFT2)\n        + texture2D(uun_source, uv + uun_dxy * BOTTOMRIGHT2));\n\n  gl_FragColor = color / 9.;\n} \n",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"}}t.shp_shadowDepth={name:"SHADOW depth",fragmentSource:"varying vec3 vPosition;\n\nvoid main(void) {\n  gl_FragColor = vec4(vPosition,1.);\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vPosition;\n\nvoid main(void) {\n  vec4 pPosition = uun_Pmatrix * uun_Vmatrix * uun_Mmatrix * vec4(aat_position, 1.);\n  gl_Position = pPosition;\n  vPosition = pPosition.xyz / pPosition.w;\n} \n",uniformsNames:["uun_Pmatrix","uun_Vmatrix","uun_Mmatrix"],precision:"lowp"};t.shp_shadow={name:"SHADOW",fragmentSource:"uniform sampler2D uun_depth, uun_irradiance, uun_random;\nuniform mat4 uun_Pmatrix, uun_VInvMatrix;\nuniform vec2 uun_wh;\nuniform float uun_lightFactor;\n\nvarying vec2 vUV;\n\nconst float N = 8888.8;  //number of rays launched\nconst float M = 9999.9;  //number of ray steps\nconst float Rmin = 25.; //min max size of the ray\nconst float Rmax = 50.; //max max size of the ray\nconst float Rpow = 1.2;\n\n\nconst float PI = 3.141592;\nconst vec4 ZERO4 = vec4(0.,0.,0.,0.);\nconst vec4 ONE4 = vec4(1.,1.,1.,1.);\nconst vec2 HALF2 = vec2(0.5,0.5);\n\nvec2 compute_uv(vec3 direction){\n  float theta = atan(direction.x, direction.z);\n  float phi = acos(direction.y);\n  return vec2(0.5-0.5*theta/PI, 1.-phi/PI);\n}\n\nvoid main(void) {\n  vec2 vUVy = vec2(vUV.x, 1.-vUV.y);\n  \n  // position of the point in view coordinates:\n  vec3 position_v = vec3(uun_wh*(vUVy-HALF2), 0.);\n\n  // position of the point in scene coordinates:\n  vec3 position_s = vec3(uun_VInvMatrix*vec4(position_v, 1.));\n\n  // sampling:\n  float sampleTheta, samplePhi, R;\n  vec4 sampleColor = ZERO4;\n  vec2 uvRandom;\n  vec3 dr, drs;\n  vec4 pClip, sampleRandom, pv;\n  vec3 pn;\n  int isHit;\n  \n  for (float i=0.; i<N; i+=1.){ //loop on rays\n    uvRandom.x = i;\n    uvRandom.y = floor(uvRandom.x/64.0);\n    sampleRandom = texture2D(uun_random, uvRandom/64.0);\n    \n    sampleTheta = PI*sampleRandom.r;              //between -PI and PI\n    samplePhi=2.0*asin(sqrt(0.25+sampleRandom.g*0.25)); //uniform hemispheric distribution. pole is phi=0\n\n    // unit dir vector of the ray in the view ref:\n    dr = vec3(cos(sampleTheta)*sin(samplePhi), sin(sampleTheta)*sin(samplePhi), -cos(samplePhi));\n    R = Rmin+(0.5+0.5*sampleRandom.b)*(Rmax-Rmin);\n\n\n    // launch the ray (theta, phi):\n    isHit = 0;\n    for (float j=0.0; j<=M; j+=1.0){\n      pv = vec4(position_v+dr*R*pow(j/M, Rpow), 1.); //position in the view ref\n      pClip = uun_Pmatrix * pv;       //position in clipping coordinates\n      pn = pClip.xyz / pClip.w; //position in normalized device coordinates\n\n      if (texture2D(uun_depth, HALF2+HALF2*pn.xy).z<pn.z){\n        isHit = 1;\n        break;\n      }\n    }\n    if (isHit==1) {\n      continue;\n    }\n    drs = vec3(uun_VInvMatrix*vec4(dr, 0.));\n    sampleColor += texture2D(uun_irradiance, compute_uv(drs));\n\n  } //end loop en rays\n\n  gl_FragColor = vec4(uun_lightFactor*sampleColor.rgb/N, 1.);\n} \n",uniformsNames:["uun_depth","uun_irradiance","uun_random","uun_Pmatrix","uun_VInvMatrix","uun_wh","uun_lightFactor"],replaces:[{search:"8888.8",replace:JESETTINGS.shadowNumberRays[JEContext.get_level()].toFixed(1)},{search:"9999.9",replace:JESETTINGS.shadowRaySteps[JEContext.get_level()].toFixed(1)}],precision:"lowp"};t.shp_shadowBlur={name:"SHADOW GAUSSIAN BLUR",fragmentSource:"uniform sampler2D uun_source;\nuniform vec2 uun_dxy;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec4 col = (4./14.) * texture2D(uun_source, vUV-uun_dxy)\n       +(6./14.) * texture2D(uun_source, vUV)\n       +(4./14.) * texture2D(uun_source, vUV+uun_dxy);\n       \n  gl_FragColor = col;\n} ",uniformsNames:["uun_source","uun_dxy"],precision:"lowp"};t.shp_shadowDraw={name:"SHADOW DRAW",fragmentSource:"uniform sampler2D uun_source, uun_render;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_FragColor = texture2D(uun_source, vUV);\n} \n",vertexSource:"attribute vec3 aat_position;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vec4 pPosition = uun_Pmatrix * uun_Vmatrix * vec4(aat_position, 1.);\n  gl_Position = pPosition;\n  vUV = aat_uv;\n} \n",uniformsNames:["uun_Pmatrix","uun_Vmatrix","uun_source"],attributesNames:["aat_position","aat_uv"],precision:"lowp"};if(JEContext.can_MRT()){r()}else{f()}}function r(){const D=["uun_state","uun_preOffset","uun_preScale","uun_beginBendZ","uun_bendStrength","uun_windowDim","uun_matParams","uun_diffuseColor","uun_matParamA","uun_alpha","uun_maskBranchStart","uun_maskBranchEnd","uun_postOffset"].concat(l,g);if(!JEContext.is_clearDrawBuffersWorking()){t.shp_clearMRT={name:"CLEAR MRT",vertexSource:"attribute vec2 aat_position;\n\nvoid main(void) {\n  gl_Position = vec4(aat_position, 0., 1.);\n}",fragmentSource:"void main(void) {\n  gl_FragData[0] = vec4(0.,0.,0.,0.);\n  gl_FragData[1] = vec4(0.,0.,0.,0.);\n  gl_FragData[2] = vec4(0.,0.,0.,0.);\n  gl_FragData[3] = vec4(0.,0.,0.,0.);\n} \n",uniformsNames:[],precision:"lowp",isMRT:true}}t.shp_uniColorMRT={name:"UNICOLOR MRT",vertexSource:"attribute vec2 aat_position;\n\nvoid main(void) {\n  gl_Position = vec4(aat_position, 0., 1.);\n}",fragmentSource:"uniform vec4 color;\nvoid main(void) {\n  gl_FragData[0] = color;\n  gl_FragData[1] = color;\n  gl_FragData[2] = color;\n  gl_FragData[3] = color;\n} \n",uniformsNames:["color"],isMRT:true};t.shp_gbuffersNNGLcolor={name:"GBUFFERS NNGL C0LOR",fragmentSource:"uniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA;\n\nvarying vec3 vPosition, vNormal;\nvarying float vAlpha, vY;\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha); //uun_alpha is the true alpha\n  gl_FragData[2] = vec4(uun_diffuseColor, 0.0);\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[2]=vec4(normalize(vNormal), 1.);\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec3 vPosition, vNormal;\nvarying float vAlpha, vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n  vPosition = cPos;\n  vY = aat_position.y;\n} \n",uniformsNames:D,attributesNames:["aat_position","aat_normal"],attributesDims:[3,3],isMRT:true};t.shp_gbuffersNNGLtexture={name:"GBUFFERS NNGL DIFFUSE TEXTURE",fragmentSource:"uniform sampler2D uun_source;\nuniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n  \n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n  vUV = aat_uv;\n  vPosition = cPos;\n  vY = aat_position.y;\n} \n",uniformsNames:D.concat(x),attributesNames:["aat_position","aat_normal","aat_uv"],attributesDims:[3,3,2],isMRT:true};t.shp_gbuffersNNGLtextureNormalMap={name:"GBUFFERS NNGL DIFFUSE TEXTURE + NORMALMAP",fragmentSource:"uniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_diffuseColor;\nuniform sampler2D uun_source, uun_normalMap;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  vec3 viewDir = vec3(0.,0.,-1.); //view direction in the scene ref\nvec3 n = normalize(vNormal);\n\nvec3 map = texture2D(uun_normalMap, vUV ).xyz;\nmap = normalize(map * 255./127. - 128./127.*ONE3);\n\nvec3 t = vTangents.xyz;\nvec3 b = cross(n, t)*vTangents.w; \nmat3 tbn = mat3(t,b,n);\nvec3 PN = tbn * map; //Perturbed Normal\n\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(PN, alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vTangents = aat_tangents;\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n  vUV = aat_uv;\n  vPosition = cPos;\n  vY = aat_position.y;\n} \n",uniformsNames:D.concat(x,["uun_normalMap"]),attributesNames:["aat_tangents","aat_position","aat_normal","aat_uv"],attributesDims:[4,3,3,2],isMRT:true};t.shp_gbuffersNNGLtextureParamsMap={name:"GBUFFERS NNGL DIFFUSE TEXTURE + PARAMSMAP",fragmentSource:"uniform sampler2D uun_source, uun_paramsMap;\nuniform vec4 uun_matParams, uun_alpha, uun_paramsMapMask;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n  \n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n  vUV = aat_uv;\n  vPosition = cPos;\n  vY = aat_position.y;\n} \n",uniformsNames:D.concat(x,b),attributesNames:["aat_position","aat_normal","aat_uv"],attributesDims:[3,3,2],isMRT:true};t.shp_gbuffersNNGLtextureNormalParamsMap={name:"GBUFFERS NNGL DIFFUSE TEXTURE + NORMALMAP + PARAMSMAP",fragmentSource:"uniform sampler2D uun_source, uun_normalMap, uun_paramsMap;\nuniform vec4 uun_matParams, uun_alpha, uun_paramsMapMask;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  vec3 viewDir = vec3(0.,0.,-1.); //view direction in the scene ref\nvec3 n = normalize(vNormal);\n\nvec3 map = texture2D(uun_normalMap, vUV ).xyz;\nmap = normalize(map * 255./127. - 128./127.*ONE3);\n\nvec3 t = vTangents.xyz;\nvec3 b = cross(n, t)*vTangents.w; \nmat3 tbn = mat3(t,b,n);\nvec3 PN = tbn * map; //Perturbed Normal\n\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n\n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(PN, alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vTangents = aat_tangents;\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n  vUV = aat_uv;\n  vPosition = cPos;\n  vY = aat_position.y;\n} \n",uniformsNames:D.concat(x,["uun_normalMap"],b),attributesNames:["aat_tangents","aat_position","aat_normal","aat_uv"],attributesDims:[4,3,3,2],isMRT:true};const C=["uun_Pmatrix","uun_Vmatrix","uun_Mmatrix","uun_matParams","uun_diffuseColor","uun_matParamA","uun_alpha"];t.shp_gbufferscolor={name:"GBUFFERS - COLOR",fragmentSource:"uniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA;\n\nvarying vec3 vPosition, vNormal;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha);\n  gl_FragData[2] = vec4(uun_diffuseColor, 0.0);\n  gl_FragData[3] = matParams;\n\n\n  // DEBUG ZONE:\n\n  //gl_FragData[2]=vec4(normalize(vNormal), 1.);\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vPosition, vNormal;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vPosition = scenePosition.xyz;\n  vNormal = sceneNormal.xyz;\n  vAlpha = 1.0;\n  vY = aat_position.y;\n} \n",uniformsNames:C,attributesNames:["aat_position","aat_normal"],isMRT:true};t.shp_gbuffers={name:"GBUFFERS",fragmentSource:"uniform sampler2D uun_source;\nuniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;\n\n  // DEBUG ZONE:\n  //gl_FragData[0]=vec4(0.,0.,0.,1.); //position, isDisplayed\n  //gl_FragData[1]=vec4(0.,0.,1.,1.); //normal, alpha\n  //gl_FragData[2]=vec4(1.,0.,0.,0.); //color, fresnelMax\n  //gl_FragData[3]=vec4(0.,0.5,1.,0.); //fresnelMin, roughness, fresnelPow, metalNess\n  \n}",vertexSource:"attribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vUV = aat_uv;\n  vPosition = scenePosition.xyz;\n  vNormal = sceneNormal.xyz;\n  vAlpha = 1.0;\n  vY = aat_position.y;\n} \n",uniformsNames:C.concat(x),attributesNames:["aat_position","aat_normal","aat_uv"],isMRT:true};const B=["uun_normalMap","uun_cameraPosition"];t.shp_gbuffersNormalMap={name:"GBUFFERS NORMAL MAP",fragmentSource:"uniform sampler2D uun_source, uun_normalMap;\nuniform vec4 uun_matParams, uun_alpha;\nuniform vec3 uun_cameraPosition, uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  vec3 viewDir = vec3(0.,0.,-1.); //view direction in the scene ref\nvec3 n = normalize(vNormal);\n\nvec3 map = texture2D(uun_normalMap, vUV ).xyz;\nmap = normalize(map * 255./127. - 128./127.*ONE3);\n\nvec3 t = vTangents.xyz;\nvec3 b = cross(n, t)*vTangents.w; \nmat3 tbn = mat3(t,b,n);\nvec3 PN = tbn * map; //Perturbed Normal\n\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(PN, alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;    \n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vTangents = aat_tangents;\n  vUV = aat_uv;\n  vPosition = scenePosition.xyz;\n  vNormal = sceneNormal.xyz;\n  vAlpha = 1.0;\n  vY = aat_position.y;\n} \n",uniformsNames:C.concat(x,B),attributesNames:["aat_position","aat_normal","aat_uv","aat_tangents"],isMRT:true};t.shp_gbuffersParamsMap={name:"GBUFFERS PARAMS MAP",fragmentSource:"// no NNGL mode, material with diffuseMap, paramsMap but no normalMap\n\nuniform sampler2D uun_source, uun_paramsMap;\nuniform vec4 uun_matParams, uun_alpha, uun_paramsMapMask;\nuniform vec3 uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(normalize(vNormal), alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams; \n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vUV = aat_uv;\n  vPosition = scenePosition.xyz;\n  vNormal = sceneNormal.xyz;\n  vAlpha = 1.0;\n  vY = aat_position.y;\n} \n",uniformsNames:C.concat(x,b),attributesNames:["aat_position","aat_normal","aat_uv"],isMRT:true};t.shp_gbuffersNormalParamsMap={name:"GBUFFERS NORMAL PARAMS MAP",fragmentSource:"uniform sampler2D uun_source, uun_normalMap, uun_paramsMap;\nuniform vec4 uun_matParams, uun_alpha, uun_paramsMapMask;\nuniform vec3 uun_cameraPosition, uun_diffuseColor;\nuniform float uun_matParamA, uun_colorTextureUsage;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n\n  vec3 viewDir = vec3(0.,0.,-1.); //view direction in the scene ref\nvec3 n = normalize(vNormal);\n\nvec3 map = texture2D(uun_normalMap, vUV ).xyz;\nmap = normalize(map * 255./127. - 128./127.*ONE3);\n\nvec3 t = vTangents.xyz;\nvec3 b = cross(n, t)*vTangents.w; \nmat3 tbn = mat3(t,b,n);\nvec3 PN = tbn * map; //Perturbed Normal\n\n\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n  \n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragData[0] = vec4(vPosition, vAlpha);\n  gl_FragData[1] = vec4(PN, alpha);\n  gl_FragData[2] = diffuse;\n  gl_FragData[3] = matParams;    \n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\nvarying float vAlpha, vY;\n\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vTangents = aat_tangents;\n  vUV = aat_uv;\n  vPosition = scenePosition.xyz;\n  vNormal = sceneNormal.xyz;\n  vAlpha = 1.0;\n  vY = aat_position.y;\n} \n",uniformsNames:C.concat(x,B,b),attributesNames:["aat_position","aat_normal","aat_uv","aat_tangents"],isMRT:true}}function v(){e.set_uniformsStatic("shp_gbufferDiffuse",[{type:"1i",name:"uun_source",value:0}]);e.set_uniformsStatic("shp_gbufferNormalsNormalMap",[{type:"1i",name:"uun_normalMap",value:0}]);e.set_uniformsStatic("shp_gbufferMatParamsParamsMap",[{type:"1i",name:"uun_paramsMap",value:0}])}function f(){console.log("INFO in JEShaders - declare_noDrawBuffersShaders()");const B=["uun_state","uun_preOffset","uun_preScale","uun_beginBendZ","uun_bendStrength","uun_windowDim","uun_postOffset"].concat(l,g);t.shp_gbufferPositionNNGL={name:"GBUFFER POSITION NNGL",fragmentSource:"varying vec3 vPosition;\nvarying float vAlpha;\n\nvoid main(void) {\n  gl_FragColor = vec4(vPosition, vAlpha);\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_maskBranchStart, uun_maskBranchEnd, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec3 vPosition;\nvarying float vAlpha;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\n  vPosition = cPos;\n  vAlpha = smoothstep(uun_maskBranchStart, uun_maskBranchEnd, aat_position.z);\n} \n",uniformsNames:["uun_maskBranchStart","uun_maskBranchEnd"].concat(B),attributesNames:["aat_position"],precision:"highp"};t.shp_gbufferDiffuseNNGLtexture={name:"GBUFFER DIFFUSE NNGL TEXTURE",fragmentSource:"uniform sampler2D uun_source;\nuniform vec3 uun_diffuseColor;\nuniform float uun_colorTextureUsage;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragColor = diffuse;\n} \n",vertexSource:"attribute vec3 aat_position;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec2 vUV;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\n  vUV = aat_uv;\n} \n",uniformsNames:["uun_diffuseColor"].concat(x,B),attributesNames:["aat_position","aat_uv"],attributesDims:[3,2],precision:"lowp"};t.shp_gbufferDiffuseNNGLcolor={name:"GBUFFER DIFFUSE NNGL COLOR",fragmentSource:"uniform vec3 uun_diffuseColor;\n\nvoid main(void) {\n  gl_FragColor = vec4(uun_diffuseColor, 0.0);\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n} \n",uniformsNames:["uun_diffuseColor"].concat(B),attributesDims:[3],precision:"lowp"};t.shp_gbufferNormalsNNGL={name:"GBUFFER NORMALS NNGL",fragmentSource:"uniform vec4 uun_alpha;\n\nvarying vec3 vNormal;\nvarying float vY;\n\nvoid main(void) {\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n  gl_FragColor = vec4(normalize(vNormal), alpha);\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec3 vNormal;\nvarying float vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n	\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n\n  vY=aat_position.y;\n} \n",uniformsNames:["uun_alpha","uun_postOffset"].concat(B),attributesNames:["aat_position","aat_normal"],precision:"highp"};t.shp_gbufferNormalsNNGLNormalMap={name:"GBUFFER NORMALS NNGL NORMALS MAP NNGL",fragmentSource:"uniform sampler2D uun_normalMap;\nuniform vec4 uun_alpha;\n\nvarying vec4 vTangents;\nvarying vec3 vNormal;\nvarying vec2 vUV;\nvarying float vY;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\n\nvoid main(void) {\n  vec3 viewDir = vec3(0.,0.,-1.);//normalize(vPosition); //view direction in the scene ref\n\n  vec3 n = normalize(vNormal);\n\n  vec3 map = texture2D(uun_normalMap, vUV ).xyz;\n  map = normalize(map * 255./127. - 128./127.*ONE3);\n     \n  vec3 t = vTangents.xyz; //normalize(cross(n, vec3(0.0, 0.0, 1.0))); \n  vec3 b = cross(n, t) * vTangents.w; \n  mat3 tbn = mat3(t,b,n);\n\n  vec3 PN = tbn * map; //Perturbed Normal\n\n  if (dot(PN, viewDir)>0.){\n    PN = vNormal;\n  }\n\n  float alpha = uun_alpha.x + uun_alpha.y * smoothstep(-uun_alpha.w, -uun_alpha.z, vY);\n  gl_FragColor = vec4(PN, alpha);\n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec4 vTangents;\nvarying vec3 vNormal;\nvarying vec2 vUV;\nvarying float vY;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n	\nvNormal = rotMatrix * aat_normal * vec3(1., -1., -1.);\n  vTangents = aat_tangents;\n  vUV = aat_uv;\n  vY = aat_position.y;\n} \n",uniformsNames:["uun_alpha","uun_postOffset","uun_normalMap"].concat(B),attributesNames:["aat_tangents","aat_position","aat_normal","aat_uv"],attributesDims:[4,3,3,2],precision:"highp"};t.shp_gbufferMatParamsNNGL={name:"GBUFFER MATERIAL PARAMETERS NNGL",fragmentSource:"uniform vec4 uun_matParams;\nuniform float uun_matParamA;\n\n//uun_matParams=[\n//  fresnelMin\n//  roughNess\n//  fresnelPow\n//  metalness\n//]\n\nvoid main(void) {\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragColor = matParams;\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n} \n",uniformsNames:["uun_matParams","uun_matParamA"].concat(B),precision:"lowp"};t.shp_gbufferMatParamsParamsMapNNGL={name:"GBUFFER MATERIAL PARAMETERS + PARAMS MAP NNGL",fragmentSource:"uniform sampler2D uun_paramsMap;\nuniform vec4 uun_matParams, uun_paramsMapMask;\nuniform float uun_matParamA;\n\nvarying vec2 vUV;\n\n//uun_matParams=[\n//  fresnelMin\n//  roughNess\n//  fresnelPow\n//  metalness\n//]\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n\n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragColor = matParams;\n} \n",vertexSource:"attribute vec3 aat_position;\nattribute vec2 aat_uv;\n\nuniform sampler2D uun_state;\nuniform vec3 uun_preOffset;\nuniform vec2 uun_windowDim, uun_focal;\nuniform float uun_preScale, uun_beginBendZ, uun_bendStrength, uun_aspectRatio;\n\nvarying vec2 vUV;\n\nconst vec2 ONE2 = vec2(1.,1.);\nconst vec3 ONE3 = vec3(1.,1.,1.);\nconst vec2 INV2 = vec2(-1., 1.);\n\nuniform mat4 uun_projMatrixWebcam;\nuniform vec3 uun_postOffset, uun_viewerRot, uun_viewerPreOffset, uun_viewerPostOffset;\nuniform float uun_moveXRotateY, uun_viewerTrans, uun_viewerPreScale, uun_rx, uun_focalFactor, uun_screenSizeFactor, uun_FOVCorrectionFactor;\n\n\nmat3 create_rotMatrix(vec3 euler) {\n  // see https://fr.wikipedia.org/wiki/Matrice_de_rotation\n  vec3 c = cos(euler);\n  vec3 s = sin(euler);\n  return mat3(\n    c.y*c.z,         s.z,     s.y*c.z,\n    c.y*s.z*c.x-s.x*s.y,   -c.z*c.x,  s.y*s.z*c.x+c.y*s.x,\n    c.y*s.z*s.x+s.y*c.x,  -s.x*c.z,  s.y*s.z*s.x-c.y*c.x\n  );\n}\n\n\nvoid main(void) {\n  vec4 dataState = texture2D(uun_state, vec2(0.25, 0.5));\n\n  vec2 t2 = uun_viewerTrans * ONE2;\n  vec3 t3 = uun_viewerTrans * ONE3;\n\n  // 2D transform:\n  vec2 windowScaledDim = mix(dataState.a * uun_windowDim, ONE2, t2);\n  vec2 cornerInf = (2.*dataState.gb-ONE2)*(1.-t2);\n  cornerInf.x *= -1.;\n  \n  // rotation matrix:\n  vec3 rvec = mix(texture2D(uun_state, vec2(0.75, 0.5)).rgb+vec3(uun_rx, 0.,0.), uun_viewerRot, t3);  \n  mat3 rotMatrix = create_rotMatrix(rvec);\n\n  vec3 preOffset = mix(uun_preOffset, uun_viewerPreOffset, t3);\n  float preScale = mix(uun_preScale, uun_viewerPreScale, uun_viewerTrans);\n  vec3 postOffset = mix(uun_postOffset, uun_viewerPostOffset, t3);\n\n  // far -> dataState.a close to 0, near -> close to 10\n  // dataState.a small -> far. medium=5\n  float screenSizeFactor = mix(uun_screenSizeFactor, 1., uun_viewerTrans);\n  vec2 zGlasses = uun_focalFactor/windowScaledDim;\n\n  // open branches:\n  vec3 basePosition = aat_position;\n  float branchBend = max(0.0, -aat_position.z-uun_beginBendZ) * uun_bendStrength;\n  basePosition.x += branchBend * sign(aat_position.x) * (1.-uun_viewerTrans);\n\n  // glasses position in the fixed-head ref:\n  vec3 cPos = rotMatrix * (basePosition+preOffset) * preScale + postOffset;\n  \n  cPos.x += uun_moveXRotateY * sin(rvec.y); //dirty tweak\n\n  \n  //PROJECTION MATRIX CORRECTION\n  vec2 screenSize = zGlasses * screenSizeFactor;\n  vec3 pos3D = vec3(cornerInf*screenSize, -zGlasses) + cPos*vec3(1., -1., -1.);\n  \n  gl_Position = uun_projMatrixWebcam * (vec4(uun_FOVCorrectionFactor*ONE2, ONE2) * vec4(pos3D, 1.));\n  \n\n\n  vUV = aat_uv;\n\n} \n",uniformsNames:["uun_matParams","uun_matParamA"].concat(b,B),attributesNames:["aat_position","aat_uv"],attributesDims:[3,2],precision:"lowp"};const C=["uun_Pmatrix","uun_Vmatrix","uun_Mmatrix"];t.shp_gbufferPosition={name:"GBUFFER POSITION",fragmentSource:"varying vec3 vPosition;\nvarying float vAlpha;\n\nvoid main(void) {\n  gl_FragColor = vec4(vPosition, vAlpha);\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vPosition;\nvarying float vAlpha;\n\nvoid main(void) {\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vPosition = scenePosition.xyz;\n  vAlpha = 1.;\n} \n",uniformsNames:C,precision:"highp"};t.shp_gbufferNormals={name:"GBUFFER NORMALS",fragmentSource:"varying vec3 vNormal;\n\nvoid main(void) {\n  gl_FragColor = vec4(normalize(vNormal), 1.);\n} \n",vertexSource:"attribute vec3 aat_position, aat_normal;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec3 vNormal;\nvarying float vY;\n\nvoid main(void) {\n\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n  gl_Position = uun_Pmatrix * uun_Vmatrix * uun_Mmatrix * vec4(aat_position, 1.);\n\n  vNormal = sceneNormal.xyz;\n  vY = aat_position.y;\n\n} \n",uniformsNames:C,attributesNames:["aat_position","aat_normal"],precision:"highp"};t.shp_gbufferNormalsNormalMap={name:"GBUFFER NORMALS NORMAL MAP",fragmentSource:"uniform sampler2D uun_normalMap;\nuniform vec3 uun_cameraPosition;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\n\nconst vec3 ONE3 = vec3(1.,1.,1.);\n\n\nvoid main(void) {\n  vec3 viewDir = normalize(vPosition+uun_cameraPosition); //view direction in the scene ref\n\n  vec3 n = normalize(vNormal);\n\n  vec3 map = texture2D(uun_normalMap, vUV ).xyz;\n  map = normalize(map * 255./127. - 128./127.*ONE3);\n     \n  vec3 t = vTangents.xyz; //normalize(cross(n, vec3(0.0, 0.0, 1.0))); \n  vec3 b = cross(n, t)*vTangents.w; \n  mat3 tbn = mat3(t,b,n);\n\n  vec3 PN = tbn * map; //Perturbed Normal\n\n  if (dot(PN, viewDir)>0.){\n    PN = vNormal;\n  }\n\n  gl_FragColor = vec4(PN, 1.);\n} \n",vertexSource:"attribute vec4 aat_tangents;\nattribute vec3 aat_position, aat_normal;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec4 vTangents;\nvarying vec3 vPosition, vNormal;\nvarying vec2 vUV;\n\nvoid main(void) {\n\n  vec4 sceneNormal = uun_Mmatrix * vec4(aat_normal, 0.);\n  vec4 scenePosition = uun_Mmatrix * vec4(aat_position, 1.);\n\n  gl_Position = uun_Pmatrix * uun_Vmatrix * scenePosition;\n\n  vTangents = aat_tangents;\n  vNormal = sceneNormal.xyz;\n  vUV = aat_uv;\n  vPosition = scenePosition.xyz;\n} \n",uniformsNames:["uun_normalMap","uun_cameraPosition"].concat(C),attributesNames:["aat_position","aat_normal","aat_uv","aat_tangents"],precision:"highp"};t.shp_gbufferDiffuse={name:"GBUFFER DIFFUSE",fragmentSource:"uniform sampler2D uun_source;\nuniform vec3 uun_diffuseColor;\nuniform float uun_colorTextureUsage;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n\n  // inputs:\n//   <float> uun_colorTextureUsage: coefficient - =0 -> the base color is replaced by the texture color, 1-> the base color is multiplied by the texture color\n//   <sampler2D> uun_source: diffuse color texture\n//   <vec3> uun_diffuseColor: base color\n\n// output:\n//   <vec4> diffuse\n\nvec4 diffuseColorTexture = texture2D(uun_source, vUV);\nvec3 colorReplaced = mix(uun_diffuseColor, diffuseColorTexture.rgb, diffuseColorTexture.a);\n\nvec4 diffuse = vec4( mix(diffuseColorTexture.rgb*uun_diffuseColor, colorReplaced, uun_colorTextureUsage),  diffuseColorTexture.a);\n\n  gl_FragColor = diffuse;\n\n  // DEBUG ZONE:\n  //gl_FragColor+=vec4(0.,1.,0.,1.);\n  //gl_FragColor = vec4(uun_diffuseColor, 1.0);\n} \n",vertexSource:"attribute vec3 aat_position;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec2 vUV;\n\nconst vec4 OFFSET=vec4(0.,0.,0.0005,0.);\n\nvoid main(void) {\n  gl_Position = uun_Pmatrix * uun_Vmatrix * uun_Mmatrix * vec4(aat_position, 1.) + OFFSET;\n  vUV = aat_uv;\n} \n",uniformsNames:["uun_diffuseColor"].concat(x,C),attributesNames:["aat_position","aat_uv"],replaces:[{search:"0.0005",replace:(SharedContext.can_floatRTT()?"0.0005":"0.0")}],precision:"lowp"};t.shp_gbufferMatParams={name:"GBUFFER MATERIAL PARAMETERS",fragmentSource:"uniform vec4 uun_matParams;\nuniform float uun_matParamA;\n\n//uun_matParams=[\n//  fresnelMin\n//  roughNess\n//  fresnelPow\n//  metalness\n//]\n\nvoid main(void) {\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragColor = matParams;\n} \n",vertexSource:"attribute vec3 aat_position;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvoid main(void) {\n  gl_Position = uun_Pmatrix * uun_Vmatrix * uun_Mmatrix * vec4(aat_position, 1.);\n} \n",uniformsNames:["uun_matParams"].concat(C),precision:"highp"};t.shp_gbufferMatParamsParamsMap={name:"GBUFFER MATERIAL PARAMETERS + PARAMS MAP",fragmentSource:"uniform sampler2D uun_paramsMap;\nuniform vec4 uun_matParams, uun_paramsMapMask;\nuniform float uun_matParamA;\n\nvarying vec2 vUV;\n\n//uun_matParams=[\n//  fresnelMin\n//  roughNess\n//  fresnelPow\n//  metalness\n//]\n\nvec2 demultiplex(float n, float cut) {\n	float ni = floor(n*255.+0.01);\n	float decal = pow(2., cut);\n	float decalComp = 256. / decal;\n	float d = ni / decal;\n	float a = floor(d);\n	float b = (d-a) * decal;\n	return vec2(a / (decalComp-1.0), b / (decal-1.0)); //a and b are between 0 and 1\n} //end demultiplex()\n\nvoid main(void) {\n  float matParamA = uun_matParamA;\n  vec4 matParams = uun_matParams;\n\n   vec4 matParamsMapColor = texture2D(uun_paramsMap, vUV);\n \n//to use this shader chunk, you SHOUD include in the header of the shaders\n// matParamsMapHeader.gl\n\n//required inputs :\n//  uun_paramsMapMask : normalized vec4, which channel of the param mask we should apply. 0 -> do not apply the channel, 1-> apply\n//  uun_paramsMap : texture of the params map\n//  matParams : vec4, material parameters already computed = \n//      matParams=[\n//        fresnelMin\n//        roughNess\n//        fresnelPow\n//        metalness\n//      ]\n//  matParamA : fresnelMax\n\n\n//outputs : update matParams and matParamA values\n\n\n//  composition of matParamsMapColor:\n// 	RED : fresnelMin. the spec.fresnelMin value is overwritten if the paramsTexture is applied (see ALPHA)\n//	GREEN : roughness. the spec.roughness value is overwritten if the paramsTexture is applied (see ALPHA)\n//	BLUE : - fresnelPow encoded by the 4 weaker bits. It is an integer from 0 to 15\n//	       - inverted fresnelMax is encoded by the 4 strongest bits (if BLUE<16, fresnelMax = 1)\n//	ALPHA : last bit : applyParamTexture - = 0 if the paramsTexture is not applied, =1 if the param texture is applied\n//		    7 first bits : metalness\n\n\n// demultiplex blue channel:\nvec2 dem = demultiplex(matParamsMapColor.b, 4.0);\nfloat fresnelMax = 1. - dem.x; //stronger bits\nfloat fresnelPow = dem.y; //weaker bits\n\n// demultiplex alpha channel:\ndem = demultiplex(matParamsMapColor.a, 1.0);\nfloat metalness = dem.x; //stronger bits\nfloat applyParamTexture = dem.y; //weaker bit\n\n// texture formated values:\nvec4 matParamsMap = vec4(matParamsMapColor.rg, fresnelPow, metalness);\nfloat matParamMapA = fresnelMax;\n\n// mix with current material values:\nmatParams = mix(matParams, matParamsMap, uun_paramsMapMask * applyParamTexture);\nmatParamA = mix(matParamA, matParamMapA, uun_paramsMapMask.b * applyParamTexture);\n\n// DEBUG ZONE:\n//matParams.g=1.;\n\n  //convert 8 bits normalized floats uun_matParams.b and uun_matParamA\n//to 1 8 bits float constitued by 2 4-bits floats\n//put the result in matParams.b\n\n//inputs : \n// <vec4> matParams\n// <float> matParamA\n\n//outputs : refresh matParams\n\n//vec4 matParams=uun_matParams;\n\n//compute 4 bits floats\nfloat reducedA = floor(15.99*matParamA); //between 0 and 15\nfloat reducedB = floor(15.99*matParams.b); //between 0 and 15\nmatParams.b = (reducedA+16.*reducedB) / 255.; //between 0 and 1\n\n  gl_FragColor = matParams;\n} \n",vertexSource:"attribute vec3 aat_position;\nattribute vec2 aat_uv;\n\nuniform mat4 uun_Pmatrix, uun_Vmatrix, uun_Mmatrix;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  gl_Position = uun_Pmatrix * uun_Vmatrix * uun_Mmatrix * vec4(aat_position, 1.);\n\n  vUV = aat_uv;\n} \n",uniformsNames:["uun_matParams"].concat(b,C),attributesNames:["aat_position","aat_uv"],attributesDims:[3,2],precision:"highp"}}function q(){for(let shaderId in t){a(GL,t[shaderId])}}const e={get_GLSLHeaderMRT:function(){if(JEContext.is_webgl2()){return"precision highp float;\n            layout(location = 0) out vec4 gbuf0;\n            layout(location = 1) out vec4 gbuf1;\n            layout(location = 2) out vec4 gbuf2;\n            layout(location = 3) out vec4 gbuf3;\n"}else{return"#extension GL_EXT_draw_buffers : require\n"}},add_shader:function(C,B){t[C]=B;if(_isInitialized){a(GL,t[C])}},replace_shader:function(C,B){t[C]=B;B.initialized=false;a(GL,t[C])},is_initialized:function(){return _isInitialized},init:function(C){z();q();const D=[{type:"1i",name:"uun_source",value:0}];e.set_uniformsStatic("shp_copy",D);e.set_uniformsStatic("shp_copyLow",D);e.set_uniformsStatic("shp_mix",[{type:"1i",name:"uun_destination",value:1}].concat(D));e.set_uniformsStatic("shp_mixRGBE",[{type:"1i",name:"uun_destination",value:1}].concat(D));e.set_uniformsStatic("shp_fakeMipmap",[{type:"1i",name:"uun_avg",value:1}].concat(D));e.set_uniformsStatic("shp_fakeMipmapRGBE",[{type:"1i",name:"uun_avg",value:1}].concat(D));e.set_uniformsStatic("shp_postProcessing",D);e.set_uniformsStatic("shp_postProcessingMSAA",D);e.set_uniformsStatic("shp_postProcessingMSAAkinetic",[{type:"1i",name:"uun_previous",value:1},{type:"1i",name:"uun_state",value:2}].concat(D));e.set_uniformsStatic("shp_postProcessingFXAA",D);e.set_uniformsStatic("shp_postProcessingMSAAalpha",D);e.set_uniformsStatic("shp_RGBtoRGBE",D);e.set_uniformsStatic("shp_envLight",[{type:"1i",name:"uun_env",value:0},{type:"1i",name:"uun_light",value:1}]);e.set_uniformsStatic("shp_irradiance",[{type:"1i",name:"uun_envLight",value:0},{type:"1i",name:"uun_random",value:1}]);e.set_uniformsStatic("shp_glowBlur",D);e.set_uniformsStatic("shp_glowApply",D);e.set_uniformsStatic("shp_blur",D);e.set_uniformsStatic("shp_fastBlur",D);e.set_uniformsStatic("shp_avgLineColor",D);e.set_uniformsStatic("shp_irradianceSeamless",[{type:"1i",name:"uun_avg",value:1}].concat(D));e.set_uniformsStatic("shp_irradianceSeamlessRGBE",[{type:"1i",name:"uun_avg",value:1}].concat(D));if(JESETTINGS.aoEnable){e.set_uniformsStatic("shp_AO",[{type:"1i",name:"uun_uposition",value:0},{type:"1i",name:"uun_normals",value:1},{type:"1f",name:"uun_aoDzFactor",value:JESETTINGS.aoDzFactor},{type:"1f",name:"uun_aoDzFactorMin",value:JESETTINGS.aoDzFactorMin},{type:"1f",name:"uun_aoSharpness",value:JESETTINGS.aoSharpness},{type:"1f",name:"uun_maxDpEdge0",value:JESETTINGS.aoMaxDpEdge0},{type:"1f",name:"uun_maxDpEdge1",value:JESETTINGS.aoMaxDpEdge1},{type:"1f",name:"uun_lightAtt",value:1},{type:"1f",name:"uun_aoMax",value:1}]);e.set_uniformsStatic("shp_AOPostProcessing",D)}const B=[{type:"1i",name:"uun_uposition",value:0},{type:"1i",name:"uun_normals",value:1},{type:"1i",name:"uun_diffuse",value:2},{type:"1i",name:"uun_envLight",value:3},{type:"1i",name:"uun_irradiance",value:4},{type:"1i",name:"uun_matParams",value:6},{type:"1i",name:"uun_background",value:7},{type:"1f",name:"uun_reflectOnHeadFactor",value:0},{type:"1f",name:"uun_angleReflectOnHead",value:0},{type:"1f",name:"uun_dAngleReflectOnHead",value:0}];if(JESETTINGS.aoEnable){e.set_uniformsStatic("shp_deferred",B.concat([{type:"1f",name:"uun_aoMax",value:JESETTINGS.aoMax[JEContext.get_level()]},{type:"1i",name:"uun_ao",value:5}]))}e.set_uniformsStatic("shp_deferredNoAO",B.concat([{type:"1f",name:"uun_postProcessingGamma",value:JESETTINGS.postProcessingGamma},{type:"1f",name:"uun_postProcessingSaturation",value:JESETTINGS.postProcessingSaturation}]));e.set_uniformsStatic("shp_shadow",[{type:"1i",name:"uun_depth",value:0},{type:"1i",name:"uun_irradiance",value:1},{type:"1i",name:"uun_random",value:2},{type:"1f",name:"uun_lightFactor",value:JESETTINGS.shadowLightFactor}]);e.set_uniformsStatic("shp_shadowBlur",D);e.set_uniformsStatic("shp_shadowDraw",D);e.set_uniformsStatic("shp_loading",[{type:"1i",name:"uun_mask",value:1},{type:"1i",name:"uun_nngl",value:2},{type:"1i",name:"uun_background",value:3},{type:"1f",name:"uun_forceDisableLoading",value:1},{type:"2f",name:"uun_loadingScale",value:[0,0]}].concat(D));if(JEContext.can_MRT()){e.set_uniformsStatic("shp_gbuffers",D);e.set_uniformsStatic("shp_gbuffersNormalMap",[{type:"1i",name:"uun_normalMap",value:1}].concat(D));e.set_uniformsStatic("shp_gbuffersParamsMap",[{type:"1i",name:"uun_paramsMap",value:1}].concat(D));e.set_uniformsStatic("shp_gbuffersNormalParamsMap",[{type:"1i",name:"uun_normalMap",value:1},{type:"1i",name:"uun_paramsMap",value:2}].concat(D))}else{v()}_isInitialized=true},set_noDrawBuffersShaders:function(){console.log("INFO in JEShaders - set_noDrawBuffersShaders()");f();q();v()},get_currentShaderId:function(){return _currentShader.id},get_uniformsNNGLFit:function(){return l},get_uniformsNNGLViewer:function(){return g},log_current:function(){console.log("INFO in JEShaders.JS - log_current: Current SHP is ",_currentShader.name)},set:function(B){if(!(B in t)){console.log("ERROR in JEShader.js - set: unknow shader: ",B)}SharedShaders.set_shadersProvider(e);t[B].set()},set_shpCopyGL:function(B){return o(B,u())},set_shpHalfGL:function(B){return o(B,d())},set_shpHalfMRTGL:function(B){return o(B,n())},unset:function(){if(_currentShaderId!==-1){_currentShader.unset()}},set_vertexPointers:function(){let offset=0;_currentShader.attributesNumArray.forEach(function(C,B){const D=_currentShader.attributesDims[B];GL.vertexAttribPointer(C,D,GL.FLOAT,false,_currentShader.vertexByteSize,offset);offset+=4*D})},set_vertexPointersQuad:function(){e.set_vertexPointersQuadGL(GL)},set_vertexPointersQuadGL:function(B){B.vertexAttribPointer(_currentShader.attributesNumArray[0],2,B.FLOAT,false,8,0)},set_attribPointerPositionOnly:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,12,0)},set_attribPointerPosition:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,32,0)},set_attribPointerPositionNoUVs:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,24,0)},set_attribPointerNormals:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_normal,3,GL.FLOAT,false,32,12)},set_attribPointerNormalsNoUVs:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_normal,3,GL.FLOAT,false,24,12)},set_attribPointerUvs:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_uv,2,GL.FLOAT,false,32,24)},set_attribPointersPositionUvs:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,20,0);GL.vertexAttribPointer(_currentShader.attributes.aat_uv,2,GL.FLOAT,false,20,12)},set_attribPointerDrawBuffers:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,32,0);GL.vertexAttribPointer(_currentShader.attributes.aat_normal,3,GL.FLOAT,false,32,12);GL.vertexAttribPointer(_currentShader.attributes.aat_uv,2,GL.FLOAT,false,32,24)},set_attribPointerDrawBuffersNoUvs:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,32,0);GL.vertexAttribPointer(_currentShader.attributes.aat_normal,3,GL.FLOAT,false,32,12)},set_attribPointerDrawBuffersNoUvs2:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_position,3,GL.FLOAT,false,24,0);GL.vertexAttribPointer(_currentShader.attributes.aat_normal,3,GL.FLOAT,false,24,12)},set_attribPointerTangents:function(){GL.vertexAttribPointer(_currentShader.attributes.aat_tangents,4,GL.FLOAT,false,16,0)},set_uniformDynamic1i:function(B,C){GL.uniform1i(_currentShader.uniforms[B],C)},set_uniformDynamic1f:function(B,C){GL.uniform1f(_currentShader.uniforms[B],C)},set_uniformDynamic2f:function(D,C,B){GL.uniform2f(_currentShader.uniforms[D],C,B)},set_uniformDynamic2fv:function(B,C){GL.uniform2fv(_currentShader.uniforms[B],C)},set_uniformDynamic3f:function(E,D,C,B){GL.uniform3f(_currentShader.uniforms[E],D,C,B)},set_uniformDynamic3fv:function(B,C){GL.uniform3fv(_currentShader.uniforms[B],C)},set_uniformDynamic4fv:function(B,C){GL.uniform4fv(_currentShader.uniforms[B],C)},set_uniformDynamicMatrix2fv:function(B,C){GL.uniformMatrix2fv(_currentShader.uniforms[B],false,C)},set_uniformDynamicMatrix3fv:function(B,C){GL.uniformMatrix3fv(_currentShader.uniforms[B],false,C)},set_uniformDynamicMatrix4fv:function(B,C){GL.uniformMatrix4fv(_currentShader.uniforms[B],false,C)},set_uniformsStatic:function(C,B){e.set(C);B.forEach(function(D){switch(D.type){case"4f":GL.uniform4fv(_currentShader.uniforms[D.name],D.value);break;case"3f":GL.uniform3fv(_currentShader.uniforms[D.name],D.value);break;case"2f":GL.uniform2fv(_currentShader.uniforms[D.name],D.value);break;case"1f":GL.uniform1f(_currentShader.uniforms[D.name],D.value);break;case"1i":GL.uniform1i(_currentShader.uniforms[D.name],D.value);break;case"mat2":GL.uniformMatrix2fv(_currentShader.uniforms[D.name],false,D.value);break;case"mat4":GL.uniformMatrix4fv(_currentShader.uniforms[D.name],false,D.value);break;default:console.log("WARNING in Shaders - set_uniformsStatic: unknow uniform type: ",D.type)}})},free_memory:function(){for(let shaderId in t){const B=t[shaderId];GL.detachShader(B.program,B.glVertexShader);GL.detachShader(B.program,B.glFragmentShader);GL.deleteShader(B.glVertexShader);GL.deleteShader(B.glFragmentShader);GL.deleteProgram(B.program)}},destroy:function(){},debug_getExterns:function(){const B=[];for(let shaderName in t){B.push("_shaders."+shaderName)}console.log(B.join(","))}};return e})();var JENNGL=(function(){const g={};const c=[];let _isInitialized=false;const a={fit:0,viewer:1,transition:2};let _mode=a.fit;let _modeCoeff=0;let _focalFactor=-1,_focalFactorViewer=-1;let _moveXRotateY=-1,_viewerFOVCorrectionFactor=1;let _branchesFadingStartEnd=null;let _isHeadMask=false,_headMask=null;let _isShadowGlasses=false,_isShadowGlassesEnabled=false;let _isDeformGlasses=false;let _isBlurBackground=false,_isBlurBackgroundEnabled=false;const f={isInitialized:false,isEnabled:false,texture:null,textureCopy:null,dx:-1,dy:-1,scale:1};const e={enabled:false,texture:null,speed:-1};let _backgroundShadowFBO=null,_blurredBackgroundTexture=null;let _backgroundShadowTexture=null,_lightParamsTexture=null,_viewerTextureBackground=null,_backgroundViewerMixedTexture=null;let _stateTexture=null;const b=[{type:"1f",name:"uun_viewerTrans",value:0},{type:"1f",name:"uun_maskBranchStart",value:0},{type:"1f",name:"uun_maskBranchEnd",value:0},{type:"1f",name:"uun_focalFactor",value:1},{type:"1f",name:"uun_moveXRotateY",value:0},{type:"1f",name:"uun_FOVCorrectionFactor",value:1}];const d={init:function(v,t){g.settings=v;JEContext.update_AA();JEMaterial.enable_NNGL();JEInteractor.enable_NNGL(v.viewerScale0);_focalFactor=v.focalFactor;_focalFactorViewer=v.viewerFocalFactor;_moveXRotateY=v.moveXRotateY;_viewerFOVCorrectionFactor=v.viewerFOVCorrectionFactor;const n=[{type:"1f",name:"uun_focalFactor",value:_focalFactor},{type:"1f",name:"uun_moveXRotateY",value:_moveXRotateY},{type:"1f",name:"uun_screenSizeFactor",value:v.screenSizeFactor},{type:"mat4",name:"uun_projMatrixWebcam",value:v.projMatrixWebcam},{type:"2f",name:"uun_windowDim",value:v.windowDim}];v.uniformsNNGLFittingMode=n;const z=[{type:"3f",name:"uun_viewerRot",value:[0,0,0]},{type:"3f",name:"uun_viewerPreOffset",value:v.viewerPreOffset},{type:"3f",name:"uun_viewerPostOffset",value:v.viewerPostOffset},{type:"1f",name:"uun_viewerTrans",value:0},{type:"1f",name:"uun_viewerPreScale",value:v.viewerScale0},{type:"1f",name:"uun_FOVCorrectionFactor",value:1}];v.uniformsNNGLViewerMode=z;d.init_extensions(v,t);if(!_isInitialized&&!("postOffset" in v)){v.postOffset=[0,0,120]}f.isInitialized=SETTINGS.glowEnable;f.isEnabled=f.isInitialized;if(!_isInitialized&&f.isInitialized){const x=JEContext.get_overWidth()*f.scale;const p=JEContext.get_overHeight()*f.scale;const u={isLinear:true,isPot:false,width:x,height:p};f.texture=JETexture.instance(u);f.textureCopy=JETexture.instance(u);f.dx=1/x;f.dy=1/p}const l=[{type:"1i",name:"uun_state",value:1},{type:"3f",name:"uun_postOffset",value:v.postOffset},{type:"1f",name:"uun_beginBendZ",value:v.beginBendZ},{type:"1f",name:"uun_bendStrength",value:v.bendStrength}].concat(n,z);_branchesFadingStartEnd=v.maskBranchStartEnd;console.log("INFO in JENNGL - init(): maskBranchStartEnd =",v.maskBranchStartEnd);const r=[{type:"1f",name:"uun_maskBranchStart",value:_branchesFadingStartEnd[0]},{type:"1f",name:"uun_maskBranchEnd",value:_branchesFadingStartEnd[1]}];if(JEContext.can_MRT()){const q=[{type:"1i",name:"uun_source",value:0}];const o=[{type:"1i",name:"uun_normalMap",value:2}];JEShaders.set_uniformsStatic("shp_gbuffersNNGLcolor",l.concat(r));JEShaders.set_uniformsStatic("shp_gbuffersNNGLtexture",[].concat(q,l,r));JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureNormalMap",[].concat(q,o,l,r));JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureParamsMap",[{type:"1i",name:"uun_paramsMap",value:2}].concat(q,l,r));JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureNormalParamsMap",[{type:"1i",name:"uun_paramsMap",value:3}].concat(q,o,l,r))}else{JEShaders.set_uniformsStatic("shp_gbufferPositionNNGL",l.concat(r));JEShaders.set_uniformsStatic("shp_gbufferDiffuseNNGLtexture",[{type:"1i",name:"uun_source",value:0}].concat(l));JEShaders.set_uniformsStatic("shp_gbufferDiffuseNNGLcolor",l);JEShaders.set_uniformsStatic("shp_gbufferNormalsNNGL",l);JEShaders.set_uniformsStatic("shp_gbufferNormalsNNGLNormalMap",l.concat([{type:"1i",name:"uun_normalMap",value:0}]));JEShaders.set_uniformsStatic("shp_gbufferMatParamsNNGL",l);JEShaders.set_uniformsStatic("shp_gbufferMatParamsParamsMapNNGL",l.concat([{type:"1i",name:"uun_paramsMap",value:0}]))}JEShaders.set_uniformsStatic("shp_postProcessingMSAAkinetic",[{type:"2f",name:"uun_kineticRange",value:v.temporalKineticBlurRange}]);JEShaders.set_uniformsStatic((JESETTINGS.aoEnable)?"shp_deferred":"shp_deferredNoAO",[{type:"1f",name:"uun_angleReflectOnHead",value:v.angleReflectOnHead},{type:"3f",name:"uun_reflectOnHeadColor",value:v.reflectOnHeadColor},{type:"1f",name:"uun_dAngleReflectOnHead",value:v.dAngleReflectOnHead},{type:"1f",name:"uun_reflectOnHeadFactor",value:1},{type:"3f",name:"uun_camera",value:v.PBRCameraPosition}]);e.isEnabled=v.loadingEnable;if(e.isEnabled){e.texture=v.loadingTexture;JEShaders.set_uniformsStatic("shp_loading",[{type:"4f",name:"uun_loadingColor",value:v.loadingColor},{type:"1f",name:"uun_loadingAngle",value:v.loadingAttenuationAngle},{type:"2f",name:"uun_loadingScale",value:v.loadingScale}]);e.speed=v.loadingSpeed}c.forEach(function(A){A.set_NNGL(v)});_isInitialized=true},set_glasses:function(l){if(_isShadowGlassesEnabled){JEEXTENSIONS.ShadowGlasses.set_glasses(l)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_glasses(l)}},init_extensions:function(n,l){console.log("INFO in JENNGL: init_extensions() with NNGLSettings = ",n);if(("ShadowGlasses" in JEEXTENSIONS)&&n.shadowGlassesEnable&&JEContext.can_MRT()){JEEXTENSIONS.ShadowGlasses.init(n);_isShadowGlasses=true;l.push(function(o){JEEXTENSIONS.ShadowGlasses.set_glasses(o);_isShadowGlassesEnabled=true})}if(("DeformGlasses" in JEEXTENSIONS)&&n.deformGlassesEnable){JEEXTENSIONS.DeformGlasses.init(n);l.push(function(o){JEEXTENSIONS.DeformGlasses.set_glasses(o);_isDeformGlasses=true})}if(("BlurBackground" in JEEXTENSIONS)&&n.blurBackgroundEnable){JEEXTENSIONS.BlurBackground.init(n);_isBlurBackground=true;_isBlurBackgroundEnabled=true}if("HeadMask" in JEEXTENSIONS){JEEXTENSIONS.HeadMask.init(n);_headMask=JEEXTENSIONS.HeadMask.instance_headMask0({width:n.headMaskWidth,height:n.headMaskWidth*2,depth:1.5*n.headMaskWidth,dz:-n.headMaskDz,cutEdgeRadius:n.headMaskCutEdgeRadius,cutEdgeSegments:n.headMaskCutEdgeSegments});_isHeadMask=true}},set_textures:function(l,p,o,n){console.log("INFO in JENNGL: set_stateTextures()");if(l){_stateTexture=l;if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.set_stateTexture(l)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_stateTexture(l)}if(_isBlurBackground){JEEXTENSIONS.BlurBackground.set_stateTexture(l)}c.forEach(function(q){q.set_stateTexture(l)})}if(o){_lightParamsTexture=o}if(n){_viewerTextureBackground=n}},update_NNGLUniforms:function(l){if(JEContext.can_MRT()){JEShaders.set_uniformsStatic("shp_gbuffersNNGLcolor",l);JEShaders.set_uniformsStatic("shp_gbuffersNNGLtexture",l);JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureNormalMap",l);JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureParamsMap",l);JEShaders.set_uniformsStatic("shp_gbuffersNNGLtextureNormalParamsMap",l)}else{JEShaders.set_uniformsStatic("shp_gbufferPositionNNGL",l);JEShaders.set_uniformsStatic("shp_gbufferDiffuseNNGLtexture",l);JEShaders.set_uniformsStatic("shp_gbufferDiffuseNNGLcolor",l);JEShaders.set_uniformsStatic("shp_gbufferNormalsNNGL",l);JEShaders.set_uniformsStatic("shp_gbufferNormalsNNGLNormalMap",l);JEShaders.set_uniformsStatic("shp_gbufferMatParamsNNGL",l);JEShaders.set_uniformsStatic("shp_gbufferMatParamsParamsMapNNGL",l)}},set_preOffset:function(l,q,o){const n=[l[0]+q[0],l[1]+q[1],l[2]+q[2]];const p=[n[0]+o[0],n[1]+o[1],n[2]+o[2]];g.preOffset=p;g.modelPreOffset=q;g.userPreOffset=o;d.update_NNGLUniforms([{type:"3f",name:"uun_preOffset",value:p}]);if(JEContext.can_MRT()){if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.set_preOffset(l,q,o)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_preOffset(p)}}if(_isHeadMask){JEEXTENSIONS.HeadMask.set_preOffset(l)}},set_preScale:function(o,n,l){const p=o*n*l;g.modelPreScale=n;g.userPreScale=l;g.globalPreScale=o;d.update_NNGLUniforms([{type:"1f",name:"uun_preScale",value:p}]);if(JEContext.can_MRT()){if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.set_preScale(o*n,l)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_preScale(p)}}if(_isHeadMask){JEEXTENSIONS.HeadMask.set_preScale(o)}},restore_fromCache:function(){d.set_preOffset(g.preOffset,g.modelPreOffset,g.userPreOffset);d.set_preScale(g.globalPreScale,g.modelPreScale,g.userPreScale);d.set_rotX(g.rx);d.init(g.settings);d.set_bend(g.bendBeginZ,g.bendStrength)},set_rotX:function(l){g.rx=l;d.update_NNGLUniforms([{type:"1f",name:"uun_rx",value:l}]);if(JEContext.can_MRT()){if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.set_rx(l)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_rx(l)}}},set_bend:function(n,l){g.bendBeginZ=n;g.bendStrength=l;d.update_NNGLUniforms([{type:"1f",name:"uun_beginBendZ",value:n},{type:"1f",name:"uun_bendStrength",value:l}])},set_maskBranch:function(l){_branchesFadingStartEnd=l;console.log("INFO in JENNGL - set_maskBranch(): maskBranchStartEnd =",l);if(_mode===a.fit){d.update_NNGLUniforms([{type:"1f",name:"uun_maskBranchStart",value:_branchesFadingStartEnd[0]},{type:"1f",name:"uun_maskBranchEnd",value:_branchesFadingStartEnd[1]}])}},set_fitToViewerCoeff:function(l){const n=function(){if(_isHeadMask){JEEXTENSIONS.HeadMask.toggle(false)}if(e.isEnabled){JEShaders.set_uniformsStatic("shp_loading",[{type:"1f",name:"uun_forceDisableLoading",value:0}])}};if(l<=0){_modeCoeff=0;if(_mode!==a.fit){_mode=a.fit;JEInteractor.reset_NNGLValues();if(_isHeadMask){JEEXTENSIONS.HeadMask.toggle(true)}if(e.isEnabled){JEShaders.set_uniformsStatic("shp_loading",[{type:"1f",name:"uun_forceDisableLoading",value:1}])}}}else{if(l>=1){_modeCoeff=1;if(_mode!==a.viewer){_mode=a.viewer;JEInteractor.switch_onOff(true)}n()}else{_modeCoeff=l;if(_mode!==a.transition){JEInteractor.switch_onOff(false);_mode=a.transition;n()}}}JEShaders.set_uniformsStatic("shp_deferredNoAO",[{type:"1f",name:"uun_reflectOnHeadFactor",value:1-l}]);b[0].value=_modeCoeff;b[1].value=_branchesFadingStartEnd[0]*(1-l)+l*-300;b[2].value=_branchesFadingStartEnd[1]*(1-l)+l*-300;b[3].value=_focalFactor*(1-l)+l*_focalFactorViewer;b[4].value=_moveXRotateY*(1-l);b[5].value=(1-l)+l*_viewerFOVCorrectionFactor;if(_isShadowGlassesEnabled){JEEXTENSIONS.ShadowGlasses.set_transitionCoeff(_modeCoeff,b)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.set_transitionCoeff(_modeCoeff,b)}d.update_NNGLUniforms(b)},draw_objectsDrawBuffers:function(l){_stateTexture.bind_toSampler(1);l.forEach(function(n){n.draw_drawBuffersNNGL()});if(_isHeadMask){_headMask.draw()}},is_viewerMode:function(){return(_mode===a.viewer)},bind_stateTextureToSampler:function(l){_stateTexture.bindForce_toSampler(l)},add_service:function(l){c.push(l)},switch_shadowGlasses:function(l){_isShadowGlassesEnabled=l&&_isShadowGlasses},switch_bgBlur:function(l){_isBlurBackgroundEnabled=l&&_isBlurBackground},set_deformGlassesZoom:function(l){if(_isDeformGlasses&&JEContext.can_MRT()){JEEXTENSIONS.DeformGlasses.set_zoom(l)}},update_model:function(l){if(JEContext.can_MRT()){if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.update_model(l)}if(_isDeformGlasses){JEEXTENSIONS.DeformGlasses.update_model(l)}}},draw_glow:function(n,l){if(!f.isEnabled){return false}f.texture.set_rttVp();n.bind_toSampler(0);JEShaders.set("shp_glowBlur");JEShaders.set_uniformDynamic2f("uun_dxy",0,f.dy);JEVBO.draw_quad(false,false);f.textureCopy.set_rtt();f.texture.bind_toSampler(0);JEShaders.set_uniformDynamic2f("uun_dxy",f.dx,0);JEVBO.draw_quad(false,false);JEShaders.set("shp_glowApply");l.set_rttVp();f.textureCopy.bind_toSampler(0);JEVBO.draw_quad(false,false);return true},switch_glow:function(l){f.isEnabled=l&&f.isInitialized},resize:function(q,l,r){const n=q*r;const p=l*r;if(f.isInitialized){const t=n*f.scale;const o=p*f.scale;f.texture.resize(t,o);f.textureCopy.resize(t,o);f.dx=1/t;f.dy=1/o}},set_backgroundTexture:function(p,q){const l=p.get_width(),o=p.get_height();console.log("INFO in JENNGL: set_backgroundTexture()");const n={width:l,height:o,isPot:false};if(!_isShadowGlasses){console.log("WARNING in JENNGL: set_backgroundTexture() launched but _isShadowGlasses = false")}if(_isShadowGlasses){if(_backgroundShadowTexture){_backgroundShadowTexture.remove()}_backgroundShadowTexture=JETexture.instance(n)}_backgroundShadowFBO=JEFBO.instance({width:l,height:o});if(_isBlurBackground||_isDeformGlasses){JEEXTENSIONS.BlurBackground.set_bgSize(l,o);if(_blurredBackgroundTexture){_blurredBackgroundTexture.remove()}_blurredBackgroundTexture=JETexture.instance(n)}else{_blurredBackgroundTexture=p}if(_isShadowGlasses){JEEXTENSIONS.ShadowGlasses.set_bgSize(l,o)}if(q){if(_backgroundViewerMixedTexture){_backgroundViewerMixedTexture.remove()}_backgroundViewerMixedTexture=JETexture.instance(n)}},draw_backgroundTexture:function(l){let backgroundTexture=null;switch(_mode){case a.fit:backgroundTexture=l;break;case a.transition:_backgroundShadowFBO.bind(false,true);_backgroundViewerMixedTexture.set_rtt();JEShaders.set("shp_mix");JEShaders.set_uniformDynamic1f("uun_alpha",_modeCoeff);l.bind_toSampler(1);_viewerTextureBackground.bind_toSampler(0);JEVBO.draw_quad(true,true);backgroundTexture=_backgroundViewerMixedTexture;break;case a.viewer:backgroundTexture=_viewerTextureBackground;break}if(!_isShadowGlassesEnabled||_mode===a.viewer||!JEContext.can_MRT()){return backgroundTexture}backgroundTexture.bindForce_toSampler(0);if(_isBlurBackgroundEnabled){JEEXTENSIONS.BlurBackground.draw(backgroundTexture,_blurredBackgroundTexture)}_backgroundShadowFBO.bind(false,!_isBlurBackgroundEnabled);if(_isDeformGlasses){if(_isBlurBackgroundEnabled){backgroundTexture.bind_toSampler(0)}else{_blurredBackgroundTexture.set_rtt();JEShaders.set("shp_copyLow");JEVBO.draw_quad(true,true)}JEEXTENSIONS.DeformGlasses.draw()}_blurredBackgroundTexture.bind_toSampler(0);_lightParamsTexture.bindForce_toSampler(2);JEEXTENSIONS.ShadowGlasses.draw();_backgroundShadowTexture.set_rtt();JEShaders.set("shp_copyLow");if(_isBlurBackgroundEnabled||_isDeformGlasses){_blurredBackgroundTexture.bind_toSampler(0)}else{backgroundTexture.bind_toSampler(0)}JEVBO.draw_quad(true,!JESETTINGS.aoEnable);JEEXTENSIONS.ShadowGlasses.add();return _backgroundShadowTexture},draw_loading:function(n,l){if(!e.isEnabled){return false}JEShaders.set("shp_loading");JEShaders.set_uniformDynamic1f("uun_time",n*e.speed);e.texture.bind_toSampler(1);JENNGL.bind_stateTextureToSampler(2);if(_blurredBackgroundTexture){_blurredBackgroundTexture.bind_toSampler(3)}else{l.bind_toSampler(3)}return true}};return d})();var JEScene=(function(){const n=[],f=[];let _gbuffers={diffuse:false,position:false,normals:false};const o=[],l=[];let _light=null;let _counter=0,_isFPSCounter=false;let _renderTexture=null,_renderTexture1=null,_renderTexture2=null,_renderTexturePrevious=null;let _isInitialized=false,_isPlaying=false,_isStarted=false,_isNoDraw=false,_isOffline=false;let _isOverSampled=false,_isDepthMask=false;let _timerAnimate=false,_timerSleep=false,_noDrawTimer=false;let _backgroundTexture=null,_isBackgroundTexture=false;let _isNNGL=false,_isNNGLtexturesReady=false;let _isKineticBlur=false;let _isBackgroundFilter=false,_backgroundFilterTexture=false,_backgroundFilterShader=false;function g(){n.forEach(function(r){r.draw_positions(_isNNGL)})}function p(){n.forEach(function(r){r.draw_diffuse(_isNNGL)})}function b(){n.forEach(function(r){r.draw_matParams(_isNNGL)})}function q(){n.forEach(function(r){r.draw_normals(_isNNGL)})}function e(){if(_isNNGL){JENNGL.draw_objectsDrawBuffers(n)}else{n.forEach(function(r){r.draw_drawBuffersNoNNGL()})}}function c(){if(_noDrawTimer){clearTimeout(_noDrawTimer)}_noDrawTimer=setTimeout(function(){_isNoDraw=false;_noDrawTimer=false},16)}function a(r){r()}const d={init:function(){console.log("INFO in JEScene: init()");GL.enable(GL.DEPTH_TEST);GL.depthFunc(GL.LEQUAL);GL.clearDepth(1);if(JESETTINGS.cullingEnable){GL.enable(GL.CULL_FACE);GL.frontFace((JESETTINGS.cullingFrontFace==="CCW")?GL.CCW:GL.CW);GL.cullFace(GL.BACK)}else{GL.disable(GL.CULL_FACE)}d.create_gbuffers();const t={isPot:false,isLinear:false,width:JEContext.get_overWidth(),height:JEContext.get_overHeight(),nChannels:4,isFloat:false};_renderTexture=JETexture.instance(t);const r=Object.assign({},t,{isLinear:true,width:JEContext.get_width(),height:JEContext.get_height()});_renderTexture1=JETexture.instance(r);_renderTexture2=JETexture.instance(r);if(JESETTINGS.nnglMode){const u=Object.assign({},r,{isLinear:false});_renderTexturePrevious=JETexture.instance(u)}_isDepthMask=SharedContext.can_floatRTT();if(!JESETTINGS.nnglMode){_light=JELight.instance({background_env:JESETTINGS.background_env,background_light:JESETTINGS.background_light,background_lightCoefficient:JESETTINGS.background_lightCoefficient,background_envLightCoefficient:JESETTINGS.background_envLightCoefficient})}_isInitialized=true},create_gbuffers:function(){if(JEContext.can_MRT()){_gbuffers=JEGbuffers.instance({})}else{_gbuffers.diffuse=JEGbuffer.instance({shaderId:(JESETTINGS.nnglMode)?false:"shp_gbufferDiffuse",isFloat:false,isResizable:true,clearColor:[0,0,0,0],nChannels:4});_gbuffers.position=JEGbuffer.instance({shaderId:(JESETTINGS.nnglMode)?false:"shp_gbufferPosition",isFloat:true,isResizable:true,clearColor:[0,0,0,0],nChannels:4});_gbuffers.normals=JEGbuffer.instance({shaderId:false,isFloat:true,isResizable:true,clearColor:[0,0,0,0],nChannels:4});_gbuffers.matParams=JEGbuffer.instance({shaderId:false,isFloat:false,isResizable:true,clearColor:[0,0,0,0],nChannels:4})}},get_light:function(){return _light},set_light:function(r){console.log("INFO in JEScene - set_light()");_light=r},switch_offline:function(r){_isOffline=r},update_model:function(r){console.log("INFO in JEScene() - update_model()");JENNGL.update_model(r)},set_NNGL:function(r){JENNGL.init(r,o);if(!JEContext.can_MRT()){_gbuffers.diffuse.set_shaderId(false);_gbuffers.position.set_shaderId("shp_gbufferPositionNNGL")}_isKineticBlur=true;_isNNGL=true},restore_NNGLFromCache:function(){JENNGL.restore_fromCache()},add_NNGLService:function(r){JENNGL.add_service(r)},set_NNGLPreOffset:function(r,u,t){JENNGL.set_preOffset(r,u,t)},set_NNGLPreScale:function(u,t,r){JENNGL.set_preScale(u,t,r)},set_NNGLBend:function(t,r){JENNGL.set_bend(t,r)},set_NNGLBranchesFading:function(r){JENNGL.set_maskBranch(r)},set_NNGLRotX:function(r){JENNGL.set_rotX(r)},set_fitToViewerCoeff:function(r){JENNGL.set_fitToViewerCoeff(r)},set_NNGLTextures:function(r,v,u,t){JENNGL.set_textures(r,v,u,t);if(v){d.set_backgroundTexture(v,(t)?true:false)}_isNNGLtexturesReady=true},switch_shadowGlasses:function(r){JENNGL.switch_shadowGlasses(r)},set_deformGlassesZoom:function(r){JENNGL.set_deformGlassesZoom(r)},switch_bgBlur:function(r){JENNGL.switch_bgBlur(r)},switch_glow:function(r){JENNGL.switch_glow(r)},add_backgroundFilter:function(r){if(!_isBackgroundTexture){console.log("WARNING in JEScene - add_backgroundFilter(): you should call JEScene.set_backgroundTexture first. abort");return}_isBackgroundFilter=true;_backgroundFilterTexture=JETexture.instance({width:_backgroundTexture.get_width(),height:_backgroundTexture.get_height(),isPot:false});_backgroundFilterShader=r},set_backgroundTexture:function(r,t){console.log("INFO in JEScene: set_backgroundTexture() launched");if(typeof(r)==="string"){_backgroundTexture=JETexture.instance({url:r,isFloat:false})}else{_backgroundTexture=r}if(_isNNGL){JENNGL.set_backgroundTexture(_backgroundTexture,t)}_isBackgroundTexture=true},add_object:function(r){n.push(r);if(o.length!==0){o.forEach(function(t){t(r)});o.splice(0,o.length)}},remove_object:function(t){const r=n.indexOf(t);if(r!==-1){n.splice(r,1)}},add_shadow:function(r){f.push(r)},remove_shadow:function(t){const r=f.indexOf(t);if(r!==-1){f.splice(r,1)}},switch_play:function(r){if(!_isNNGL){return}_isPlaying=r},animate:function(r){if(JESETTINGS.nnglMode&&(!_isNNGL||!_isNNGLtexturesReady)){setTimeout(d.animate,100);return}if(!_isPlaying){return}if(_isNoDraw||(_counter>JESETTINGS.nRendersSleeping&&_isOverSampled)){if(_timerAnimate){clearTimeout(_timerAnimate)}++_counter;window.cancelAnimationFrame(d.animate);_timerAnimate=setTimeout(function(){window.requestAnimationFrame(d.animate)},16);return}if(_isFPSCounter){window.FPSCounter.tik()}d.render(r);++_counter;if(_isNNGL){return}if(_isPlaying){window.requestAnimationFrame(d.animate)}},call_beforeRender:function(r){l.push(r)},render:function(t){if((JESETTINGS.nnglMode&&(!_isNNGL||!_isNNGLtexturesReady))||!_isInitialized){return}l.forEach(a);if(JEContext.can_MRT()){if((!_gbuffers.set()&&!JEContext.is_webgl2())||JESETTINGS.debugDrawBuffersFail){JEContext.unset_drawBuffers();d.create_gbuffers();JEGbuffer.add_depth();JEShaders.set_noDrawBuffersShaders();if(JESETTINGS.nnglMode){JENNGL.restore_fromCache()}GL.flush();window.requestAnimationFrame(d.animate);return}if(!_isNNGL){JEMesh.resetRender_noNNGL()}e();_gbuffers.unset();if(_isDepthMask){GL.depthMask(false)}}else{if(_isNNGL){JENNGL.bind_stateTextureToSampler(1)}_gbuffers.diffuse.set(true,true,true);p();_gbuffers.diffuse.unset();if(_isDepthMask){GL.depthMask(false)}_gbuffers.matParams.set(false,!_isDepthMask,false);b();_gbuffers.matParams.unset();_gbuffers.position.set(true,!_isDepthMask,false);JECamera.draw();g();_gbuffers.position.unset();_gbuffers.normals.set(false,!_isDepthMask,false);q();_gbuffers.normals.unset()}GL.disable(GL.DEPTH_TEST);if(!_isDepthMask){GL.depthMask(false)}if(JESETTINGS.aoEnable){JEAO.draw()}const r=d.get_backgroundTexture();if(r===null){return}r.bind_toSampler(7);JEShaders.set((JESETTINGS.aoEnable)?"shp_deferred":"shp_deferredNoAO");JEGbuffer.bind_fbo();_renderTexture.set_rttVp();if(JESETTINGS.rawOutputWithAlpha){GL.enable(GL.BLEND);GL.clearColor(0,0,0,0);GL.clear(GL.COLOR_BUFFER_BIT);GL.blendFunc(GL.ONE,GL.ONE_MINUS_SRC_ALPHA)}else{GL.disable(GL.BLEND)}if(!_isNNGL){JECamera.draw_position()}_gbuffers.position.bind_toSampler(0);_gbuffers.normals.bind_toSampler(1);_gbuffers.diffuse.bind_toSampler(2);_light.bind_envLightTextureToSampler(3);_gbuffers.matParams.bind_toSampler(6);_light.bind_irradianceTextureToSampler(4);_light.draw_biasFactor();if(JESETTINGS.aoEnable){JEAO.bind_toSampler(5)}JEVBO.draw_quad(true,true);FBO.bind_default();if(JESETTINGS.rawOutputWithAlpha){GL.disable(GL.BLEND);JEShaders.set("shp_postProcessingMSAAalpha");_renderTexture2.set_rttVp();_renderTexture.bind_toSampler(0);JEVBO.draw_quad(false,false);_renderTexture1.set_rtt();_renderTexture2.bind_toSampler(0);JEVBO.draw_quad(false,false);JEFBO.unbind();JETexture.unbind_all();GL.viewport(0,0,JEContext.get_width(),JEContext.get_height());JEShaders.set("shp_copyLow");_renderTexture1.bind_toSampler(0);JEVBO.draw_quad(false,false);GL.enable(GL.DEPTH_TEST);GL.depthMask(true);GL.flush();return}if(!JENNGL.draw_glow(_renderTexture,_renderTexture1)){JEShaders.set("shp_copyLow");_renderTexture1.set_rttVp();_renderTexture.bind_toSampler(0);JEVBO.draw_quad(false,false)}JEShaders.set("shp_postProcessingFXAA");_renderTexture2.set_rttVp();_renderTexture1.bind_toSampler(0);JEVBO.draw_quad(false,false);_renderTexture1.set_rtt();_renderTexture2.bind_toSampler(0);if(_isKineticBlur&&_isNNGL){JEShaders.set("shp_postProcessingMSAAkinetic");_renderTexturePrevious.bind_toSampler(1);JENNGL.bind_stateTextureToSampler(2);JEVBO.draw_quad(false,false);JEShaders.set("shp_copyLow");_renderTexturePrevious.set_rttVp();_renderTexture1.bind_toSampler(0);JEVBO.draw_quad(false,false)}else{JEShaders.set("shp_postProcessingMSAA");JEVBO.draw_quad(false,false);_renderTexture1.bind_toSampler(0)}JEFBO.unbind();GL.viewport(0,0,JEContext.get_width(),JEContext.get_height());if(!_isNNGL||!JENNGL.draw_loading(t,r)){JEShaders.set("shp_copyLow")}JEVBO.draw_quad(false,false);GL.enable(GL.DEPTH_TEST);GL.depthMask(true);GL.flush()},get_backgroundTexture:function(){if(!_isBackgroundTexture){return JETexture.get_transparentTexture()}if(!_isNNGL){return _backgroundTexture}let backgroundFilteredTexture=null;if(_isBackgroundFilter&&!JENNGL.is_viewerMode()){JEShaders.set(_backgroundFilterShader);JEFBO.bind_default();_backgroundFilterTexture.set_vp();_backgroundFilterTexture.set_rtt();_backgroundTexture.bind_toSampler(0);backgroundFilteredTexture=_backgroundFilterTexture;JEVBO.draw_quad(true,true)}else{backgroundFilteredTexture=_backgroundTexture}let backgroundTexture=JENNGL.draw_backgroundTexture(backgroundFilteredTexture);return backgroundTexture},start_animate:function(){if(JESETTINGS.debugNoStartAnimate||_isPlaying){return}console.log("INFO in JEScene: start_animate()");_isPlaying=true;d.animate(Date.now());if(!_isStarted){JEWorkerMain.start_animatePhysics()}if(!_isStarted){JEInteractor.update_params(false)}if(_timerSleep){clearTimeout(_timerSleep)}if(JESETTINGS.aoEnable){JEAO.set_noGhostingMode()}_timerSleep=setTimeout(d.sleep,JESETTINGS.autoSleepTimeout);if(!_isStarted){JEContext.hide_loading()}_isStarted=true},stop_animate:function(){if(!_isPlaying){return}_isPlaying=false;_isOverSampled=false;cancelAnimationFrame(d.animate)},sleep:function(){if(_isOverSampled||!_isStarted||_isNoDraw||JESETTINGS.debugNoSleep){return}console.log("INFO in JEScene: sleep()");_isNoDraw=true;_isOverSampled=true;if(_timerSleep){clearTimeout(_timerSleep)}if(_noDrawTimer){clearTimeout(_noDrawTimer)}JECamera.get_current().reset_slots();_timerSleep=setTimeout(function(){JEContext.update_overSamplingFactor(JESETTINGS.overSamplingFactor);if(JESETTINGS.aoEnable){JEAO.unset_noGhostingMode()}_counter=0;c()},24)},wake:function(){if(!_isOverSampled||!_isStarted||_isNoDraw){return}console.log("INFO in JEScene: wake()");_isNoDraw=true;_isOverSampled=false;_counter=0;JECamera.get_current().reset_slots();if(_timerSleep){clearTimeout(_timerSleep)}if(_noDrawTimer){clearTimeout(_noDrawTimer)}_timerSleep=setTimeout(function(){JEContext.update_overSamplingFactor(1);if(JESETTINGS.aoEnable){JEAO.set_noGhostingMode()}c()},16)},has_FPSCounter:function(){_isFPSCounter=true},disable_FPSCounter:function(){if(_isFPSCounter&&FPSCounter){FPSCounter.remove()}_isFPSCounter=false},switch_kineticBlur:function(r){_isKineticBlur=r},update_postProcessingParameters:function(){JEShaders.set_uniformsStatic("shp_deferredNoAO",[{type:"1f",name:"uun_postProcessingGamma",value:JESETTINGS.postProcessingGamma},{type:"1f",name:"uun_postProcessingSaturation",value:JESETTINGS.postProcessingSaturation}])},resize:function(v,r,z){const t=v*z;const u=r*z;console.log("INFO in JEScene - resize() to: ",v,r);_renderTexture.resize(t,u);_renderTexture1.resize(v,r);_renderTexture2.resize(v,r);if(JESETTINGS.nnglMode){_renderTexturePrevious.resize(v,r)}JENNGL.resize(v,r,z);const x=[{type:"2f",name:"uun_dxy",value:[1/v,1/r]}];JEShaders.set_uniformsStatic("shp_postProcessingFXAA",x);JEShaders.set_uniformsStatic("shp_postProcessingMSAA",x);JEShaders.set_uniformsStatic("shp_postProcessingMSAAalpha",x)},free_memory:function(){n.concat(f).forEach(function(r){r.free_memory()});n.splice(0,n.length);f.splice(0,f.length);_gbuffers.diffuse.remove();_gbuffers.normals.remove();_gbuffers.matParams.remove();_gbuffers.position.remove();_renderTexture.remove();_renderTexture1.remove();_renderTexture2.remove();if(_renderTexturePrevious){_renderTexturePrevious.remove()}_isNoDraw=true}};return d})();var JEEXTENSIONS={};var JEContext=(function(){let _domCv=null,_width=0,_height=0;const a={notCompatible:-1,veryLight:0,light:1,full:2,insane:3};let _level=a.notCompatible;let _isExiting=false,_isInsaneMode=false;const b={textureCompressed:false,textureAnisotropic:false,uintIndices:false,srgb:false,drawBuffers:false,isTextureCompressed:false,isTextureAnisotropic:false,isUintIndices:false,isSrgb:false,isDrawBuffers:false};let _overSamplingFactor=1;let _isInitialized=false;let _onLoadCallback=false;let _isUseManySamplers=false;let _screenshotImage=false;let _isRequireWebgl1Extensions=false,_isWebgl2=false;let _isClearDrawBuffersWorking=false;function d(){JEGbuffer.resize(_width*_overSamplingFactor,_height*_overSamplingFactor);if(c.can_MRT()){JEGbuffers.resize(_width*_overSamplingFactor,_height*_overSamplingFactor)}JEScene.resize(_width,_height,_overSamplingFactor);if(JESETTINGS.aoEnable){JEAO.resize(_width*_overSamplingFactor,_height*_overSamplingFactor,_overSamplingFactor)}c.update_AA()}const c={init:function(g){console.log("INFO: JEContext - init() ============================================================= ");if(("onload" in g)&&g.onload){_onLoadCallback=g.onload}if(!("expand" in g)){g.expand=false}if(!("insaneMode" in g)){g.insaneMode=false}if(!("cv" in g)){g.cv=false}if(!("glSource" in g)){g.glSource=false}if(!("alpha" in g)){g.alpha=false}if(!("preserveDrawingBuffer" in g)){g.preserveDrawingBuffer=false}if(g.insaneMode){_isInsaneMode=true}if(g.cv){_domCv=g.cv}else{_domCv=document.getElementById(g.canvasId)}if(g.expand){c.expand()}try{if(g.glSource){window.GL=g.glSource.get_GL()}else{const f={antialias:false,alpha:g.alpha,depth:true,premultipliedAlpha:false,stencil:false,preserveDrawingBuffer:g.preserveDrawingBuffer};window.GL=_domCv.getContext("webgl",f)}_isWebgl2=(g.glSource)?g.glSource.is_webgl2():false;_isRequireWebgl1Extensions=!_isWebgl2;if(GL.getParameter(GL.MAX_TEXTURE_IMAGE_UNITS)<8){c.do_noWebgl("too few texture image units")}if(!SharedContext.init()){return c.do_noWebgl("invalid config")}if(JESETTINGS.useAnisotropic){b.textureAnisotropic=GL.getExtension("EXT_texture_filter_anisotropic");if(b.textureAnisotropic){b.isTextureAnisotropic=true}}if(JESETTINGS.useDDS){b.textureCompressed=GL.getExtension("WEBGL_compressed_texture_s3tc");if(b.textureCompressed&&("COMPRESSED_RGBA_S3TC_DXT5_EXT" in b.textureCompressed)){if(b.textureCompressed.COMPRESSED_RGBA_S3TC_DXT5_EXT){b.isTextureCompressed=true}}}if(_isRequireWebgl1Extensions){b.uintIndices=GL.getExtension("OES_element_index_uint")||GL.getExtension("MOZ_OES_element_index_uint")||GL.getExtension("WEBKIT_OES_element_index_uint");if(b.uintIndices){b.isUintIndices=true}}if(!_isWebgl2&&JESETTINGS.useSrgb){b.srgb=GL.getExtension("EXT_sRGB");if(b.srgb){b.isSrgb=true}}if(_isRequireWebgl1Extensions){b.drawBuffers=GL.getExtension("WEBGL_draw_buffers");if(b.drawBuffers&&!JESETTINGS.debugDisableDrawBuffers){b.isDrawBuffers=true}}else{b.isDrawBuffers=GL.getParameter(GL.MAX_DRAW_BUFFERS)>=4;if(!b.isDrawBuffers){console.log("WARNING in JEContext - init(): WebGL2 is enabled but there is not enough DRAW_BUFFERS")}}if(b.isDrawBuffers){const l=c.determine_MRTFloatCapability();if(!l){console.log("WARNING in JEContext - init(): MRT on float or half float buffers does not work properly. Fallback to sequential gbuffers processing")}b.isDrawBuffers=b.isDrawBuffers&&l}}catch(n){return c.do_noWebgl(n)}if(GL===null||!GL){return c.do_noWebgl("NO_GL")}if(g.expand){window.addEventListener("resize",c.expand,false)}_domCv.addEventListener("contextmenu",function(o){o.preventDefault();return false},false);_width=_domCv.width;_height=_domCv.height;c.init_all();return true},init_all:function(){_level=(_isInsaneMode)?a.insane:a.full;if(!SharedContext.can_floatRTT()){_level=Math.min(_level,a.light)}if(!SharedContext.can_RTT4Channels()){_level=Math.min(_level,a.veryLight)}console.log("INFO in JEContext - init_all(): level = ",_level);JEMaterial.init();JEGbuffer.init();for(let extensionName in JEEXTENSIONS){JEEXTENSIONS[extensionName].preInit()}JEShaders.init();JECamera.init();JEInteractor.init();JEScene.init();JEWorkerMain.init();if(JESETTINGS.aoEnable){JEAO.init()}if(typeof(FPSCounter)!=="undefined"){FPSCounter.init()}c.update_AA();c.determine_clearDrawBuffersCapability();_isInitialized=true;if(_onLoadCallback){_onLoadCallback()}return true},determine_clearDrawBuffersCapability:function(){if(!b.isDrawBuffers){return}const f=256;const e=JEGbuffers.instance({width:f,height:1});e.bind();GL.viewport(0,0,f,1);JEShaders.set("shp_uniColorMRT");JEShaders.set_uniformDynamic4fv("color",[1,0,0,1]);JEVBO.draw_quad(true,true);GL.clearColor(0,0,0,0);GL.clear(GL.COLOR_BUFFER_BIT||GL.DEPTH_BUFFER_BIT);JEFBO.unbind();JEShaders.set("shp_copyLow");e.normals.bind_toSampler(0);JEVBO.draw_quad(false,false);const g=new Uint8Array(4*f);GL.readPixels(0,0,f,1,GL.RGBA,GL.UNSIGNED_BYTE,g);_isClearDrawBuffersWorking=(g[(f-1)*4]<=1);if(!_isClearDrawBuffersWorking){console.log("WARNING in JEContext - determine_clearDrawBuffersCapability(): GPU drivers are too shitty to clear buffers correctly if MRT enabled :(")}},determine_MRTFloatCapability:function(){const g=JEGbuffers.instance({width:1,height:1});const e=function(){g.remove()};if(!g.set()){e();return false}JEShaders.set_shpHalfMRTGL(GL);JEVBO.fill_viewportForTest(GL);GL.bindFramebuffer(GL.FRAMEBUFFER,null);JEShaders.set_shpCopyGL(GL);g.diffuse.bindForce_toSampler(0);SharedVBO.fill_viewportForTest(GL);const f=new Uint8Array(4);GL.readPixels(0,0,1,1,GL.RGBA,GL.UNSIGNED_BYTE,f);e();if(Math.abs(f[0]-127)>3){console.log("ERROR in JEContext.determine_MRTFloatCapability(): readBufferPixel = ",f,"(should be [127,127,127,127])");return false}return true},is_webgl2:function(){return _isWebgl2},get_width:function(){return _width},get_height:function(){return _height},get_overWidth:function(){return _overSamplingFactor*c.get_width()},get_overHeight:function(){return _overSamplingFactor*c.get_height()},get_aspectRatio:function(){return _width/_height},get_level:function(){return _level},is_insaneMode:function(){return(_level===a.insane)},is_clearDrawBuffersWorking:function(){return _isClearDrawBuffersWorking},can_MRT:function(){return b.isDrawBuffers},unset_drawBuffers:function(){b.isDrawBuffers=false},is_useManySamplers:function(){return _isUseManySamplers},can_normalMap:function(){return(c.get_level()>a.veryLight)},can_heightMap:function(){return c.can_MRT()&&c.get_level()>a.veryLight},get_colorsMRT:function(e){let base=GL,suffix="";if(!_isWebgl2){base=b.drawBuffers;suffix="_WEBGL"}return[base["COLOR_ATTACHMENT0"+suffix],base["COLOR_ATTACHMENT1"+suffix],base["COLOR_ATTACHMENT2"+suffix],base["COLOR_ATTACHMENT3"+suffix]].splice(0,e)},get_colorAttachement:function(e){return c.get_colorsMRT(4)[e]},get_srgbFormat:function(){if(_isWebgl2){return(GL.SRGB)?GL.SRGB:GL.RGBA}else{return(b.isSrgb)?b.srgb.SRGB_ALPHA_EXT:GL.RGBA}},is_anisotropicFiltering:function(){return b.isTextureAnisotropic},get_extTextureAnisotropic:function(){return b.textureAnisotropic},map_colorAttachments:function(e){if(c.is_webgl2()){GL.drawBuffers(c.get_colorsMRT(e))}else{b.drawBuffers.drawBuffersWEBGL(c.get_colorsMRT(e))}},expand:function(){console.log("INFO in JEContext - expand(): set full screen");JEScene.wake();c.resize(window.innerWidth,window.innerHeight);JEScene.sleep()},resize:function(f,e){console.log("INFO in JEContext - resize: set cv dim to ",f,e);if(!_domCv){return}if(f===_width&&e===_height){return}_width=f,_height=e;_domCv.width=_width;_domCv.height=_height;if(!_isInitialized){return}JECamera.resize();d()},update_AA:function(){const e=[{type:"2f",name:"uun_dxy",value:[1/JEContext.get_overWidth(),1/JEContext.get_overHeight()]}];JEShaders.set_uniformsStatic("shp_postProcessingFXAA",e);JEShaders.set_uniformsStatic("shp_postProcessingMSAA",e)},update_overSamplingFactor:function(e){_overSamplingFactor=e;d()},add_eventListener:function(e,f){_domCv.addEventListener(e,f,false)},do_noWebgl:function(e){_level=a.notCompatible;if(JESETTINGS.noWebGLRedirectURL){location.href=JESETTINGS.noWebGLRedirectURL}else{let errorMsg="ERROR in JEContext - init(): cannot create the WebGL context";if(e){errorMsg+=": "+e}throw new Error(errorMsg);alert(errorMsg);console.log(errorMsg)}return false},can_webgl:function(){return(_level>=a.veryLight)},lose_context:function(){if(_isExiting){return}alert("ERROR: Webgl context is lost")},restored_context:function(){},show_loading:function(){const e=document.getElementById("loading");if(e){e.style.display="block"}},hide_loading:function(){const e=document.getElementById("loading");if(e){e.style.display="none"}},screenshot:function(){if(!_screenshotImage){_screenshotImage=new Image()}_screenshotImage.src=_domCv.toDataURL("image/png");return _screenshotImage},get_domCv:function(){return _domCv},free_memory:function(){_isExiting=true;if(!c.can_webgl()){return}JETexture.unbind_all();JEScene.free_memory();JEVBO.free_memory();JEGbuffer.free_memory();if(JESETTINGS.aoEnable){JEAO.free_memory()}JELight.free_memory();JEWorkerMain.free_memory();JEShaders.free_memory();JETexture.free_memory();GL.flush();GL=null;console.log("INFO in JEContext - free_memory(): CLEAN !")}};return c})();var JECamera=(function(){let __currentCamera=false,__isCurrentCameraSet=false;const a=[];return{init:function(){console.log("INFO in Camera: init()")},instance:function(d){if(!("resizable" in d)){d.resizable=true}if(!("zNear" in d)){d.zNear=0.1}if(!("zFar" in d)){d.zFar=100}if(!("direction" in d)){d.direction=[0,0,-1]}if(!("fov" in d)){d.fov=45}const e=new JETHREE.Quaternion();const c=new JETHREE.Matrix4();const l=new JETHREE.Vector3(50,-50,-400);let _projMatrix=null;c.setPosition(l);const b=new Int8Array(20);const g=new Int8Array(20);let _shaderSlotAOP=0,_shaderSlotAOV=0;let _shaderSlotPos=0,_shaderSlotPosNormalMap=0;const f={draw:function(){if(!g[JEShaders.get_currentShaderId()]){JEShaders.set_uniformDynamicMatrix4fv("uun_Vmatrix",c.elements);g[JEShaders.get_currentShaderId()]=1}if(!b[JEShaders.get_currentShaderId()]){JEShaders.set_uniformDynamicMatrix4fv("uun_Pmatrix",_projMatrix);b[JEShaders.get_currentShaderId()]=1}},draw_ao:function(){if(!_shaderSlotAOV){JEShaders.set_uniformDynamicMatrix4fv("uun_Vmatrix",c.elements);_shaderSlotAOV=1}if(!_shaderSlotAOP){JEShaders.set_uniformDynamic2f("uun_ab",_projMatrix[0],_projMatrix[5]);_shaderSlotAOP=1}},draw_position:function(){if(_shaderSlotPos){return}JEShaders.set_uniformDynamic3f("uun_camera",l.x,l.y,l.z);_shaderSlotPos=1},draw_positionNormals:function(){if(_shaderSlotPosNormalMap){return}JEShaders.set_uniformDynamic3f("uun_cameraPosition",l.x,l.y,l.z);_shaderSlotPosNormalMap=1},compute_projMatrix:function(){_projMatrix=JElib_matrix.get_projectionPerspective(d.fov,JEContext.get_aspectRatio(),d.zNear,d.zFar);for(let i=0;i<20;++i){b[i]=0}_shaderSlotAOP=0},set_movMatrixElements:function(n,o){l.setX(o[0]).setY(o[1]).setZ(o[2]);c.elements.set(n);for(let i=0;i<20;++i){g[i]=0}_shaderSlotAOV=0;_shaderSlotPos=0;_shaderSlotPosNormalMap=0},reset_slots:function(){_shaderSlotPos=0;_shaderSlotPosNormalMap=0;for(let i=0;i<20;++i){g[i]=0}},debug:function(){return{projMatrix:_projMatrix,position:l,movMatrix:c}}};f.compute_projMatrix();__currentCamera=f;__isCurrentCameraSet=true;if(d.resizable){a.push(f)}return f},draw:function(){if(!__isCurrentCameraSet){return}__currentCamera.draw()},draw_ao:function(){if(!__isCurrentCameraSet){return}__currentCamera.draw_ao()},draw_position:function(){if(!__isCurrentCameraSet){return}__currentCamera.draw_position()},draw_positionNormals:function(){if(!__isCurrentCameraSet){return}__currentCamera.draw_positionNormals()},resize:function(){a.forEach(function(b){b.compute_projMatrix()})},get_current:function(){return __currentCamera}}})();var JEGbuffer=(function(){const a=[];let __fbo=null;return{init:function(){__fbo=JEFBO.instance({width:JEContext.get_overWidth(),height:JEContext.get_overHeight(),isDepth:!JEContext.can_MRT()})},instance:function(b){if(!("width" in b)){b.width=JEContext.get_overWidth()}if(!("height" in b)){b.height=JEContext.get_overHeight()}if(!("isFloat" in b)){b.isFloat=false}if(!("isResizable" in b)){b.isResizable=false}if(!("clearColor" in b)){b.clearColor=[0,0,0,0]}if(!("nChannels" in b)){b.nChannels=4}const c=JETexture.instance({isFloat:b.isFloat&&SharedContext.can_floatRTT(),isHalfFloat:b.isFloat,width:b.width,height:b.height,isPot:false,isLinear:false,nChannels:b.nChannels});let _isSetShaders=(("shaderId" in b)&&b.shaderId)?true:false;let _shaderId=b.shaderId;const d={set:function(e,g,f){if(f){__fbo.bind(false,f)}c.set_rtt();if(e){GL.clearColor(b.clearColor[0],b.clearColor[1],b.clearColor[2],b.clearColor[3]);__fbo.clear_color()}if(g){__fbo.clear_depth()}if(_isSetShaders){JEShaders.set(_shaderId)}},set_shaderId:function(e){_shaderId=e;_isSetShaders=(e)?true:false},unset:function(){c.unset_rtt()},bind_toSampler:function(e){c.bind_toSampler(e)},resize:function(f,e){c.resize(f,e)},debug:function(){c.debug()},remove:function(){c.remove()}};if(b.isResizable){a.push(d)}return d},resize:function(c,b){__fbo.resize(c,b);a.forEach(function(d){d.resize(c,b)})},bind_fbo:function(){__fbo.bind_only()},add_depth:function(){__fbo.add_depth()},set_vp:function(){__fbo.set_vp()},clear_fboDepth:function(){__fbo.clear_depth()},clear_fboColor:function(){__fbo.clear_color()},clear_fbo:function(){__fbo.clear()},free_memory:function(){__fbo.remove()}}})();var JEGbuffers=(function(){const a=[];return{instance:function(p){if(!("width" in p)){p.width=JEContext.get_overWidth()}if(!("height" in p)){p.height=JEContext.get_overHeight()}const g=GL.createFramebuffer();let _width=p.width,_height=p.height;let _isFirstTime=true;const n={isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,width:_width,height:_height,isPot:false,isLinear:false,nChannels:4};const o=JETexture.instance(n);const e=JETexture.instance(n);const f=JETexture.instance(n);const d=JETexture.instance(n);const c=JEFBO.get_glDrawTarget();const q=JEFBO.get_glReadTarget();GL.bindFramebuffer(c,g);const b=GL.createRenderbuffer();GL.bindRenderbuffer(GL.RENDERBUFFER,b);GL.renderbufferStorage(GL.RENDERBUFFER,GL.DEPTH_COMPONENT16,_width,_height);GL.framebufferRenderbuffer(c,GL.DEPTH_ATTACHMENT,GL.RENDERBUFFER,b);GL.clearDepth(1);GL.framebufferTexture2D(c,JEContext.get_colorAttachement(0),GL.TEXTURE_2D,o.get(),0);GL.framebufferTexture2D(c,JEContext.get_colorAttachement(1),GL.TEXTURE_2D,e.get(),0);GL.framebufferTexture2D(c,JEContext.get_colorAttachement(2),GL.TEXTURE_2D,d.get(),0);GL.framebufferTexture2D(c,JEContext.get_colorAttachement(3),GL.TEXTURE_2D,f.get(),0);JEContext.map_colorAttachments(4);GL.bindFramebuffer(c,null);JEFBO.reset();const l={position:o,normals:e,matParams:f,diffuse:d,bind:function(){GL.bindFramebuffer(c,g);JEFBO.reset()},set:function(){GL.checkFramebufferStatus(q);GL.bindFramebuffer(c,g);JEFBO.reset();if(_isFirstTime){const r=GL.checkFramebufferStatus(q);if(r!==GL.FRAMEBUFFER_COMPLETE){console.log("WARNING in Gbuffers - set(): There is an error with WEBGL_DRAW_BUFFERS. Switch off the extension");return false}_isFirstTime=false}GL.viewport(0,0,_width,_height);GL.clearColor(0,0,0,0);if(JEShaders.is_initialized()&&!JEContext.is_clearDrawBuffersWorking()){JEShaders.set("shp_clearMRT");JEVBO.draw_quad(false,false)}GL.clear(GL.COLOR_BUFFER_BIT|GL.DEPTH_BUFFER_BIT);return true},unset:function(){},resize:function(t,r){_width=t;_height=r;o.resize(t,r);e.resize(t,r);d.resize(t,r);f.resize(t,r);GL.bindRenderbuffer(GL.RENDERBUFFER,b);GL.renderbufferStorage(GL.RENDERBUFFER,GL.DEPTH_COMPONENT16,_width,_height);GL.bindRenderbuffer(GL.RENDERBUFFER,null)},debug:function(){e.bind_toSampler(0)},remove:function(){o.remove();e.remove();d.remove();f.remove();GL.deleteRenderbuffer(b);GL.deleteFramebuffer(g);const r=a.indexOf(l);if(r!==-1){a.splice(r,1)}}};a.push(l);return l},resize:function(c,b){a.forEach(function(d){d.resize(c,b)})}}})();var JELight=(function(){const a=[];const b=JESETTINGS.background_RGBE;return{instance:function(c){if(!c.background_env){c.background_env=false}if(!c.background_light){c.background_light=false}if(!c.background_lightCoefficient){c.background_lightCoefficient=0}if(!c.background_envLightCoefficient){c.background_envLightCoefficient=0}let _backgroundWidth=0,_backgroundIrradianceWidth=0,_isLoaded=false;let _envTexture=null,_lightTexture=null;let _envLightTexture=null,_irradianceTexture=null,_irradianceTextureBlurred=null,_lineColorTexture=null,_irradianceSeamlessTexture=null;let _fakeMipmapEnvLight=null;let _bias=0;const e=[];function f(){console.log("INFO in Light - build_envLightTexture(): build the environnement HDR texture and irradiance texture");_envLightTexture=JETexture.instance({isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,isPot:false,isMipmap:false,isLinear:false,isMirrorY:true,width:_backgroundWidth,height:_backgroundWidth/2,nChannels:3});JEFBO.bind_default();_envLightTexture.set_rttVp();JEShaders.set("shp_envLight");JEShaders.set_uniformDynamic1f("uun_lightCoefficient",c.background_lightCoefficient);JEShaders.set_uniformDynamic1f("uun_envLightCoefficient",c.background_envLightCoefficient);_envTexture.bind_toSampler(0);_lightTexture.bind_toSampler(1);JEVBO.draw_quad(true,true)}function l(){if(_isLoaded){g();return}console.log("INFO in JELight: build_irradianceTexture()");_fakeMipmapEnvLight=JEFakeMipmap.instance({texture:_envLightTexture,isRGBE:b});_backgroundIrradianceWidth=JESETTINGS.backgroundIrradiance_width[JEContext.get_level()];_irradianceTexture=JETexture.instance({isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,isPot:true,isLinear:false,isMirrorY:true,width:_backgroundIrradianceWidth,height:_backgroundIrradianceWidth/2,nChannels:3});_irradianceTextureBlurred=JETexture.instance({isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,isPot:true,isLinear:false,isMirrorY:true,width:_backgroundIrradianceWidth,height:_backgroundIrradianceWidth/2,nChannels:3});_lineColorTexture=JETexture.instance({isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,isPot:true,width:1,height:_backgroundIrradianceWidth/2,nChannels:3});_irradianceSeamlessTexture=JETexture.instance({isFloat:SharedContext.can_floatRTT()&&!b,isHalfFloat:true&&!b,isPot:false,isLinear:true,isMirrorY:true,isMipmap:false,width:_backgroundIrradianceWidth,height:_backgroundIrradianceWidth/2,nChannels:(b)?4:3});_isLoaded=true;g();e.forEach(function(n){n()});e.splice(0,e.length);console.log("INFO in JELight - build_irradianceTexture(): callback launched !")}function g(){if(!_isLoaded){return}JEFBO.bind_default();_fakeMipmapEnvLight.refresh_fakeMipmap();_irradianceTexture.set_rttVp();JEShaders.set("shp_irradiance");_envLightTexture.bind_toSampler(0);JEShaders.set_uniformDynamic1f("uun_gamma",JESETTINGS.postProcessingGamma);JETexture.bind_random(1);JEVBO.draw_quad(true,true);const n=JESETTINGS.irradianceBlurNPass[JEContext.get_level()];for(let i=0;i<n;++i){_irradianceTextureBlurred.set_rtt();JEShaders.set("shp_blur");JEShaders.set_uniformDynamic2f("uun_dxy",1/_backgroundIrradianceWidth,0);_irradianceTexture.bind_toSampler(0);JEVBO.draw_quad(false,false);_irradianceTexture.set_rtt();JEShaders.set_uniformDynamic2f("uun_dxy",0,2/_backgroundIrradianceWidth);_irradianceTextureBlurred.bind_toSampler(0);JEVBO.draw_quad(false,false)}_lineColorTexture.set_rttVp();JEShaders.set("shp_avgLineColor");_irradianceTexture.bind_toSampler(0);JEVBO.draw_quad(false,false);JEShaders.set((b)?"shp_irradianceSeamlessRGBE":"shp_irradianceSeamless");_irradianceSeamlessTexture.set_rttVp();_irradianceTexture.bind_toSampler(0);_lineColorTexture.bind_toSampler(1);JEVBO.draw_quad(false,false);JETexture.unbind(0);JETexture.unbind(1)}const d={init:function(){let nLoaded=0;function n(){if(++nLoaded===2){f();l()}}_backgroundWidth=JESETTINGS.background_width[JEContext.get_level()];_bias=Math.log2(_backgroundWidth)-1;if(c.background_env){_envTexture=JETexture.instance({isPot:false,url:c.background_env,callback:n,nChannels:3,isFlipY:false});_lightTexture=JETexture.instance({isPot:false,url:c.background_light,callback:n,nChannels:3,isFlipY:false})}},set_envLightTexture:function(n){_envLightTexture=n;l()},bind_envLightTextureToSampler:function(n){if(!_isLoaded){return}_fakeMipmapEnvLight.bind_toSampler(n);JEShaders.set_uniformDynamic1f("uun_envLightSize",_fakeMipmapEnvLight.get_width())},bind_irradianceTextureToSampler:function(n){if(!_isLoaded){return}_irradianceSeamlessTexture.bind_toSampler(n)},draw_biasFactor:function(){JEShaders.set_uniformDynamic1f("uun_bias",_bias)},get_bias:function(){return _bias},get_width:function(){return _backgroundWidth},call_onload:function(n){if(_isLoaded){n()}else{e.push(n)}},debug:function(){if(!_isLoaded){console.log("WARNING in Light - debug(): Light is not loaded");return}_fakeMipmapEnvLight.debug()},get_irradiance:function(){return _irradianceSeamlessTexture},get_bias:function(){return _bias},free_memory:function(){if(_envTexture){_envTexture.remove()}if(_lightTexture){_lightTexture.remove()}_irradianceTexture.remove();_lineColorTexture.remove();_irradianceTextureBlurred.remove();_fakeMipmapEnvLight.remove();_irradianceSeamlessTexture.remove();_envLightTexture.remove()}};a.push(d);d.init();return d},free_memory:function(){a.forEach(function(c){c.free_memory()})}}})();var JEMixedLight=(function(){return{instance:function(n){const e=n.lightSource;const l=n.lightDestination;let _t=0;const b=e.get_width();const g=JESETTINGS.background_RGBE;const c=JETexture.instance({isFloat:SharedContext.can_floatRTT()&&!g,isHalfFloat:true&&!g,isLinear:true,isMipmap:false,isPot:false,width:b,nChannels:(g)?4:3,isFlipY:false});const o=JETexture.instance({isFloat:SharedContext.can_floatRTT()&&!g,isHalfFloat:true&&!g,isPot:false,isLinear:true,isMirrorY:true,isMipmap:false,width:b,height:b/2,nChannels:(g)?4:3});const d=JEFBO.instance({width:b,height:b});const a=(g)?"shp_mixRGBE":"shp_mix";const f={set_t:function(p){_t=p;JEShaders.set(a);GL.viewport(0,0,b,b);d.set_rtt();c.set_rtt();JEShaders.set_uniformDynamic1f("uun_alpha",_t);e.bind_envLightTextureToSampler(1);l.bind_envLightTextureToSampler(0);JEVBO.draw_quad(true,true);GL.viewport(0,0,b,b/2);o.set_rtt();e.bind_irradianceTextureToSampler(1);l.bind_irradianceTextureToSampler(0);JEVBO.draw_quad(false,false);GL.flush()},bind_envLightTextureToSampler:function(p){c.bind_toSampler(p)},bind_irradianceTextureToSampler:function(p){o.bind_toSampler(p)},draw_biasFactor:function(){JEShaders.set_uniformDynamic1f("uun_bias",e.get_bias()*(1-_t)+l.get_bias()*_t)},debug:function(){c.debug()}};return f}}})();var JEInteractor=(function(){const d={disabled:-1,idle:0,rotate:1,pinch:2,transition:3,pan:4};let _mode=d.idle;let _isNNGL=false,_NNGLrotVector=false,_NNGLuniforms=false,_NNGLscale0=1;let _oldX=0,_oldY=0,_oldD=0,_oldT=0,_dX=0,_dY=0,_dt=16,_domCv=null,_theta=JESETTINGS.theta0,_phi=JESETTINGS.phi0,_camDistance=JESETTINGS.cameraDistance0,_timer=false,_amortization=0;const o=new Float32Array([0,0,0,0,0]),a=[JESETTINGS.cameraX0,JESETTINGS.cameraY0];const c=function(){if(_timer){clearInterval(_timer);_timer=false}};const e=function(t){if(_mode===d.pinch||_mode===d.disabled){return}_dX=0,_dY=0;c();JEScene.wake();const r=(("changedTouches" in t)&&t.touches.length);t.preventDefault();if(r&&t.touches.length===2){_mode=d.pinch;_oldD=JElib_vector2.distanceFromScalars(t.touches[0].pageX,t.touches[0].pageY,t.touches[1].pageX,t.touches[1].pageY)}else{if(!r&&t.button===2){_mode=d.pan}else{_mode=d.rotate}_oldX=(!r)?t.clientX:t.touches[0].clientX,_oldY=(!r)?t.clientY:t.touches[0].clientY}return false};const g=function(r){if(_mode===d.idle||_mode===d.disabled){return}if((_dX!==0||_dY!==0)&&_mode===d.rotate&&_amortization){c();_oldT=Date.now();_timer=setInterval(l.keep_movement,_dt)}else{JEScene.sleep()}_mode=d.idle};const p=function(v){if(_mode===d.idle||_mode===d.disabled){return false}const r=(("touches" in v)&&v.touches.length);v.preventDefault();if(_mode===d.pinch){const x=JElib_vector2.distanceFromScalars(v.touches[0].pageX,v.touches[0].pageY,v.touches[1].pageX,v.touches[1].pageY);f(-(_oldD-x)*JESETTINGS.pinchSensibility);_oldD=x}else{const u=(!r)?v.clientX:v.touches[0].clientX,t=(!r)?v.clientY:v.touches[0].clientY;_dX=(u-_oldX)*2*Math.PI/JEContext.get_width();_dY=(t-_oldY)*2*Math.PI/JEContext.get_height();if(_mode===d.pan){b()}else{q()}_oldX=u,_oldY=t}};const q=function(){_theta+=_dX;_phi+=_dY;_phi=JElib_maths.clamp(_phi,JESETTINGS.phiMin,JESETTINGS.phiMax);l.update_params()};const b=function(){a[0]+=_dX*JESETTINGS.panSensibility;a[1]-=_dY*JESETTINGS.panSensibility;a[0]=JElib_maths.clamp(a[0],-JESETTINGS.pivotXMax,JESETTINGS.pivotXMax);a[1]=JElib_maths.clamp(a[1],-JESETTINGS.pivotYMax,JESETTINGS.pivotYMax);l.update_params()};const n=function(r){if(_mode===d.disabled){return}_dX=0,_dY=0;c();f(JESETTINGS.wheelSensibility*r.deltaY/window.innerHeight);r.preventDefault()};const f=function(r){let zoomFactor=(_camDistance-JESETTINGS.cameraDistanceMin)/(JESETTINGS.cameraDistanceMax-JESETTINGS.cameraDistanceMin);zoomFactor=1-Math.pow(1-zoomFactor,JESETTINGS.zoomPow);_camDistance+=r*(1+zoomFactor*JESETTINGS.zoomSpeedMax);_camDistance=JElib_maths.clamp(_camDistance,JESETTINGS.cameraDistanceMin,JESETTINGS.cameraDistanceMax);l.update_params()};const l={init:function(){console.log("INFO in JEInteractor: init()");_amortization=JESETTINGS.amortization[JEContext.get_level()];_dt=JESETTINGS.dt[JEContext.get_level()];JEContext.add_eventListener("mousedown",e);JEContext.add_eventListener("mouseup",g);JEContext.add_eventListener("mouseout",g);JEContext.add_eventListener("mousemove",p);JEContext.add_eventListener("mousemove",p);JEContext.add_eventListener("wheel",n);JEContext.add_eventListener("touchstart",e);JEContext.add_eventListener("touchend",g);JEContext.add_eventListener("touchmove",p)},update_params:function(r){if(_isNNGL){_NNGLrotVector[0]=-_phi;_NNGLrotVector[1]=_theta;_NNGLuniforms[1].value=_camDistance*(_NNGLscale0/JESETTINGS.cameraDistance0);JENNGL.update_NNGLUniforms(_NNGLuniforms)}else{o[0]=_theta;o[1]=_phi;o[2]=_camDistance;o[3]=a[0];o[4]=a[1];JEWorkerMain.send_params(o,r)}},keep_movement:function(){if((_dX<0.0001&&_dY<0.0001)||_mode===d.disabled){c();_dX=0;_dY=0;if(_mode===d.idle){JEScene.sleep()}}const r=Date.now();const u=r-_oldT;_oldT=r;const v=Math.pow(_amortization,u/_dt);_dX*=v;_dY*=v;q()},enable_NNGL:function(r){if(_isNNGL){return}_isNNGL=true;_mode=d.disabled;_NNGLrotVector=[0,0,0];_NNGLuniforms=[{name:"uun_viewerRot",type:"3f",value:_NNGLrotVector},{name:"uun_viewerPreScale",type:"1f",value:1}];_NNGLscale0=r},switch_onOff:function(r){if(_mode===d.disabled&&r){_mode=d.idle}if(!r){_mode=d.disabled}},reset_NNGLValues:function(){_dX=0,_dY=0;_theta=JESETTINGS.theta0;_phi=JESETTINGS.phi0;_camDistance=JESETTINGS.cameraDistance0;l.update_params()},set_camDistance:function(r){_camDistance=r},set_camPivot:function(r){a[0]=r[0];a[1]=r[1];JESETTINGS.cameraPivotZ=r[2]},set_camAngles:function(r,t){_theta=r;_phi=t}};return l})();var JEMesh=(function(){const a={shp_gbuffers:false,shp_gbufferscolor:false,shp_gbuffersNormalMap:false,shp_gbuffersParamsMap:false,shp_gbuffersNormalParamsMap:false};return{instance:function(g){if(!JEContext.can_webgl()){return false}if(!("autoCenter" in g)){g.autoCenter=false}if(!("autoScale" in g)){g.autoScale=false}if(!("callbackMaterials" in g)){g.callbackMaterials=false}let _threeVertices=null,_threeFaces=null,_threeNormals=null,_threeUvs=null;let _indices=null,_vbo=null;let _tangents=null,_vboTangents=null,_isVboTangents=false;const A=new JETHREE.Quaternion();const e=new JETHREE.Vector3();const r=new JETHREE.Matrix4();const t=new JETHREE.Box3();const o=[];let _modelURL=null;const f=[{n:0,offset:0}];const p=[];let _isVisible=false,_isLoaded=false;let _materialsURLs=[],_materials=[];let _isNormalTexture=false,_isUVs=false,_isMaterials=false;function l(U){if(!that){return}if(U.tweaker){if(!window.JEELIZVTO){console.log("WARNING in JEMesh - load(): cannot apply tweaker included in the JSON model because JEELIZVTO is not ready.")}else{if(typeof(JEELIZVTO)!=="undefined"){console.log("INFO in JEMesh - load(): tweaker = ",U.tweaker);JEELIZVTO.set_tweaker(U.tweaker)}}}f.splice(0,f.length);f.push({n:0,offset:0});t.min.set(Infinity,Infinity,Infinity);t.max.set(-Infinity,-Infinity,-Infinity);let dataUVs=U.uvs;if(dataUVs){dataUVs=dataUVs.filter(function(W){return W})}_isUVs=(dataUVs&&dataUVs.length>0&&dataUVs[0].length>0);if(typeof(QuantizaterDecoder_decodeUintArray)!=="undefined"&&typeof(U.faces)==="string"){U.faces=QuantizaterDecoder_decodeUintArray(U.faces)}if(typeof(QuantizaterDecoder_decodeFloatArray)!=="undefined"){if(typeof(U.vertices)==="string"){U.vertices=QuantizaterDecoder_decodeFloatArray(U.vertices)}if(dataUVs&&dataUVs.length){dataUVs.forEach(function(W,X){if(typeof(W)==="string"){dataUVs[X]=QuantizaterDecoder_decodeFloatArray(W)}})}}let nIndicesPerVertex=1;const J=U.metadata["faces"];nIndicesPerVertex+=(_isUVs)?1:0;console.log("INFO in JEMesh - load(): expected number of indices per vertex: ",nIndicesPerVertex);let ratio=(U.faces.length-J)/(U.metadata["faces"]*nIndicesPerVertex);if(ratio<3){console.log("ERROR in JEMesh - load(): critical error. nFaces = ",U.faces.length,"nMatIndices =",J,"nIndicesPerVertex =",nIndicesPerVertex);;return false}if((ratio===6||ratio===8)&&!_isUVs){_isUVs=true;++nIndicesPerVertex;ratio/=2}if(ratio!==3&&ratio!==4){console.log("ERROR in JEMesh - load(): an OBJ should have either only triangle, either only quads. Not both. abort. nFaces = ",U.faces.length,"nMatIndices =",J,"nIndicesPerVertex =",nIndicesPerVertex);return false}if(ratio===4){console.log("INFO in JEMesh - load(): convert quads to tris");const P=2*3*nIndicesPerVertex+2;const L=4*nIndicesPerVertex+1;const K=new Array(U.metadata["faces"]*P);for(let i=0;i<U.metadata["faces"];++i){for(let j=0;j<nIndicesPerVertex;++j){K[i*P+j*4]=U.faces[i*L+j*5];K[i*P+j*4+1]=U.faces[i*L+j*5+1];K[i*P+j*4+2]=U.faces[i*L+j*5+2];if(j===0){K[i*P+3]=U.faces[i*L+4]}K[i*P+j*4+nIndicesPerVertex*3+1]=U.faces[i*L+j*5];K[i*P+j*4+nIndicesPerVertex*3+1+1]=U.faces[i*L+j*5+2];K[i*P+j*4+nIndicesPerVertex*3+2+1]=U.faces[i*L+j*5+3];if(j===0){K[i*P+nIndicesPerVertex*3+3+1]=U.faces[i*L+4]}}}U.faces=K;U.metadata["faces"]*=2}console.log("INFO in JEMesh - load(): make arrays of THREE vertices and faces");_threeVertices=new Array(U.metadata["vertices"]);for(let i=0;i<U.metadata["vertices"];++i){const I=U.vertices[3*i],H=U.vertices[3*i+1],F=U.vertices[3*i+2];_threeVertices[i]=new JETHREE.Vector3(I,H,F);t.expandByPoint(_threeVertices[i])}_threeFaces=new Array(U.metadata["faces"]);const D=3*nIndicesPerVertex+1;for(let i=0;i<U.metadata["faces"];++i){_threeFaces[i]=new JETHREE.Face3(U.faces[D*i],U.faces[D*i+1],U.faces[D*i+2]);_threeFaces[i].materialIndex=U.faces[D*i+3]}_isVisible=(_threeVertices.length>3);if(that){that.visible=_isVisible}console.log("INFO in JEMesh - load(): compute normals");JElib_geometry.compute_faceNormals(_threeVertices,_threeFaces);_threeNormals=JElib_geometry.compute_vertexNormals(_threeVertices,_threeFaces,true);if(_isUVs){const M=new Array(_threeVertices.length);const T=["a","b","c"];for(let i=0;i<U.metadata["faces"];++i){for(let j=0;j<3;++j){const R=U.faces[i*7+j];const O=U.faces[i*7+1+j+3];if(typeof(M[R])==="undefined"){M[R]=[[R,O]];continue}else{if(M[R][0][1]===O){continue}else{let replacePi=-1;for(let k=1;k<M[R].length;++k){if(M[R][k][1]===O){replacePi=M[R][k][0];break}}let newPi=-1;if(replacePi===-1){newPi=_threeVertices.length;_threeVertices.push(_threeVertices[R].clone());_threeNormals.push(_threeNormals[R].clone());M[R].push([newPi,O]);M[newPi]=[[newPi,O]]}else{newPi=replacePi}U.faces[i*7+j]=newPi;_threeFaces[i][T[j]]=newPi}}}}_threeUvs=new Array(_threeVertices.length);for(let i=0;i<_threeVertices.length;++i){const Q=M[i][0][1];_threeUvs[i]=new JETHREE.Vector2(dataUVs[0][2*Q],dataUVs[0][2*Q+1])}}const E=t.center();if(g.autoCenter){_threeVertices.forEach(function(W){W.x-=E.x;W.z-=E.z;W.y-=t.min.y});t.min.x-=E.x;t.max.x-=E.x;t.min.z-=E.z;t.max.z-=E.z;t.max.y-=t.min.y;t.min.y=0}if(g.autoScale){const B=Math.max(t.max.x-t.min.x,t.max.y-t.min.y,t.max.z-t.min.z);const V=JESETTINGS.autoScaleMaxDim/B;_threeVertices.forEach(function(W){W.multiplyScalar(V)});t.min.multiplyScalar(V);t.max.multiplyScalar(V)}const N=(_isUVs)?8:6;const G=new Float32Array(_threeVertices.length*N);for(let i=0;i<_threeVertices.length;++i){G[N*i]=_threeVertices[i].x;G[N*i+1]=_threeVertices[i].y;G[N*i+2]=_threeVertices[i].z;G[N*i+3]=_threeNormals[i].x;G[N*i+4]=_threeNormals[i].y;G[N*i+5]=_threeNormals[i].z;if(_isUVs){G[N*i+6]=_threeUvs[i].x;G[N*i+7]=_threeUvs[i].y}}_threeFaces.sort(function(X,W){return X.materialIndex-W.materialIndex});const S=(_threeFaces.length*3<65536)?Uint16Array:Uint32Array;const C=new S(_threeFaces.length*3);let parti=0;_threeFaces.forEach(function(W,X){if(W.materialIndex===parti){f[parti].n+=3}else{f.push({n:3,offset:X*3});++parti}C[3*X]=W.a;C[3*X+1]=W.b;C[3*X+2]=W.c});if(_vbo){_vbo.remove()}_vbo=JEVBO.instance({vertices:G,indices:C});console.log("INFO in JEMesh - load(): the mesh is loaded in the VRAM. There are",f.length,"parts.");_vboTangents=false;_isVboTangents=false;if(_isNormalTexture){that.compute_tangents()}_isLoaded=true;that.do_onload();if(g.callback){g.callback(that);g.callback=null}}function d(B){_vbo.draw_part(B.n,B.offset)}function n(B,C){if(!_materials[C]){return}JEShaders.set(_materials[C].get_shaderNameNormalsNNGLNoDrawBuffers());_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition();JEShaders.set_attribPointerNormals()}else{JEShaders.set_attribPointerPositionNoUVs();JEShaders.set_attribPointerNormalsNoUVs()}if(_materials[C].is_normalTexture()){JEShaders.set_attribPointerUvs();_vboTangents.bind_vertices(false);JEShaders.set_attribPointerTangents();JECamera.draw_positionNormals()}_materials[C].draw_alpha();_materials[C].draw_normals();_vbo.draw_part(B.n,B.offset)}function q(B,C){if(!_materials[C]){return}JEShaders.set(_materials[C].get_shaderNameNormalsNoNNGLNoDrawBuffers());_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition();JEShaders.set_attribPointerNormals()}else{JEShaders.set_attribPointerPositionNoUVs();JEShaders.set_attribPointerNormalsNoUVs()}if(_materials[C].is_normalTexture()){JEShaders.set_attribPointerUvs();_vboTangents.bind_vertices(false);JEShaders.set_attribPointerTangents();JECamera.draw_positionNormals()}that.draw_matrixIfMoved();_materials[C].draw_normals();_vbo.draw_part(B.n,B.offset)}function z(B,C){if(!_isMaterials||!_materials[C]){return}_materials[C].draw_alpha2();_vbo.draw_part(B.n,B.offset)}function b(B,C){if(!_isMaterials||!_materials[C]){return}_materials[C].draw_diffuseNoDrawBuffers(_isUVs);_vbo.draw_part(B.n,B.offset)}function c(B,C){if(!_materials[C]){return}JEShaders.set(_materials[C].get_shaderNameMatParamsNNGLNoDrawBuffers());_materials[C].draw_params();_vbo.draw_part(B.n,B.offset)}function u(B,C){if(!_materials[C]){return}JEShaders.set(_materials[C].get_shaderNameMatParamsNoNNGLNoDrawBuffers());that.draw_matrixIfMoved();_materials[C].draw_params();_vbo.draw_part(B.n,B.offset)}function x(B,C){if(!_materials[C]){return}const D=_materials[C].get_shaderNameNNGLDrawBuffers();JEShaders.set(D);if(_materials[C].is_normalTexture()){_vboTangents.bind_vertices(false);JEShaders.set_attribPointerTangents();JECamera.draw_positionNormals()}_vbo.bind(false);_materials[C].draw_drawBuffers(_isUVs);_vbo.draw_part(B.n,B.offset)}function v(B,C){if(!_materials[C]){return}const D=_materials[C].get_shaderNameNoNNGLDrawBuffers();JEShaders.set(D);if(_materials[C].is_normalTexture()){_vboTangents.bind_vertices(false);JEShaders.set_attribPointerTangents();JECamera.draw_positionNormals();_vbo.bind(false)}if(!a[D]){that.draw_matrixIfMoved();_vbo.bind(false);a[D]=true}_materials[C].draw_drawBuffers(_isUVs);_vbo.draw_part(B.n,B.offset)}let that={visible:_isVisible,count_parts:function(){return f.length},compute_tangents:function(){if(_isVboTangents){return}if(!_isUVs){return}if(!_threeUvs){;throw new Error("ERROR in compute_tangents: UVs are not set")}console.log("INFO in JEMesh - compute_tangents()");_threeFaces=_threeFaces.filter(function(B){return(B!==null)});_tangents=JElib_geometry.compute_tangents(_threeVertices,_threeNormals,_threeUvs,_threeFaces);_vboTangents=JEVBO.instance({vertices:_tangents,indices:false});_tangents=null;_threeVertices=null;_threeFaces=null;_threeNormals=null;_threeUvs=null;_isVboTangents=true},draw_matrixIfMoved:function(){JECamera.draw();that.draw_matrix()},draw_matrix:function(){JEShaders.set_uniformDynamicMatrix4fv("uun_Mmatrix",r.elements)},draw_shadow:function(){if(!_isVisible){return}that.draw_matrix();_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}_vbo.draw()},draw_positions:function(B){if(!_isVisible){return}if(!B){that.draw_matrixIfMoved()}_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}_vbo.draw()},draw_shadowGlasses:function(){if(!_isVisible){return}_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}f.forEach(z)},draw_deformGlasses:function(){if(!_isVisible){return}_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}p.forEach(d)},draw_matParams:function(B){if(!_isMaterials||!_isVisible){return}_vbo.bind(false);if(_isUVs){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}if(B){f.forEach(c)}else{f.forEach(u)}},draw_diffuse:function(B){if(!_isVisible){return}if(!B){that.draw_matrixIfMoved()}_vbo.bind(false);if(!B){JEShaders.set_attribPointerPosition();JEShaders.set_attribPointerUvs()}if(_isMaterials){f.forEach(b)}},draw_normals:function(B){if(!_isMaterials||!_isVisible){return}if(B){f.forEach(n)}else{f.forEach(q)}},draw_drawBuffersNoNNGL:function(){if(!_isMaterials||!_isVisible){return}f.forEach(v)},draw_drawBuffersNNGL:function(){if(!_isMaterials||!_isVisible){return}f.forEach(x)},get_modelURL:function(){return _modelURL},get_materialsURLs:function(){return _materialsURLs},update_material:function(B,D){const C=_materials[B];C.update(D);that.update_transparentParts()},set_materials:function(C,E){_materialsURLs=C;console.log("BEGIN in JEMesh - set_materials(): materialsURLs =",C);_isMaterials=false;const B=C.length;let nMaterialsLoaded=0;const D=function(I,F,H){if(!I){console.log("ERROR in JEMesh - set_materials(): invalid material for URL =",H);;return}I.callback=function(){if(!that){return}if(++nMaterialsLoaded===B){console.log("INFO in JEMesh - set_materials(): all materials are loaded");_isMaterials=true;if(_isNormalTexture){that.call_onload(that.compute_tangents,5)}that.do_onload();if(E){that.call_onload(function(){E(that)},10)}}};const G=JEMaterial.instance(I);if(_materials[F]){_materials[F].free_memory()}_materials[F]=G;_isNormalTexture=_isNormalTexture||G.is_normalTexture()};_materials=new Array(B);_isNormalTexture=false;C.forEach(function(H,F){if(typeof(H)==="string"){const G=(H.indexOf(".json")===-1)?H+".json":H;JElib_ajax.get_json(G,function(I){I.name=H;D(I,F,H)})}else{D(H,F,false)}});that.call_onload(function(){that.update_transparentParts();JEScene.update_model(that);JEScene.switch_play(true);console.log("INFO in JEMesh: there are",p.length,"transparent parts")},4);console.log("END in JEMesh - set_materials()")},update_transparentParts:function(){p.splice(0,p.length);f.forEach(function(C,B){if(!_materials[B]){return}if(_materials[B].is_transparent()){p.push(C)}})},call_onload:function(C,B){if(_isLoaded&&_isMaterials){C(that)}else{o.push({func:C,order:(B)?B:0})}},do_onload:function(){if(!_isLoaded||!_isMaterials){return}o.sort(function(C,B){return(C.order-B.order<0)?1:-1});o.forEach(function(B){B.func(that)});o.splice(0,o.length)},remove:function(){that.free_memory();that=null},free_memory:function(){_isLoaded=false;_isVisible=false;if(_vbo){_vbo.remove()}_materials.forEach(function(B){B.free_memory()});if(_isVboTangents){_vboTangents.remove()}},get_sizeX:function(){return t.size().x},get_sizeY:function(){return t.size().y},get_sizeZ:function(){return t.size().z},get_centerX:function(){return t.center().x},get_centerY:function(){return t.center().y},get_centerZ:function(){return t.center().z},get_minY:function(){return t.min.y},replace:function(B,D,C){if(B===_modelURL){if(D&&that){that.do_onload();D(that)}return false}_modelURL=B;JEScene.switch_play(false);JElib_ajax.get_json(B,function(E){l(E);if(D){D(that)}},C);return true},debug:function(){return{mMatrix:r}}};if(g.materials){that.set_materials(g.materials,g.callbackMaterials)}_modelURL=g.url;JElib_ajax.get_json(g.url,l);return that},resetRender_noNNGL:function(){a.shp_gbuffers=false;a.shp_gbufferscolor=false;a.shp_gbuffersNormalMap=false;a.shp_gbuffersParamsMap=false;a.shp_gbuffersNormalParamsMap=false}}})();var JEWorkerMain=(function(){let _worker=null;const e={setParams:2,setCameraMatrix:3,log:4,setCameraPivotZ:5,ready:6};let _isInitialized=false,_isLoop=false;let _params=null;const d=new Float32Array(16);const a=new Float32Array(3);const b={data:0};const c={init:function(){console.log("INFO in WorkerMain: init()");if(JESETTINGS.enableWorkers){_worker=new Worker("js/worker.php")}else{_worker={postMessage:function(f){b.data=f;JEWorkerThread.on_message(b)},terminate:function(){console.log("INFO in WorkerMain: FakeWorker terminated")}}}_worker.onmessage=function(f){switch(f.data[0]){case e.setCameraMatrix:for(let i=0;i<16;++i){d[i]=f.data[i+1]}for(let i=0;i<3;++i){a[i]=f.data[i+17]}JECamera.get_current().set_movMatrixElements(d,a);break;case e.log:console.log("INFO in WorkerMain - message from the worker : ",f.data[1]);break;case e.ready:console.log("INFO in WorkerMain: worker is ready !");c.set_cameraPivotZ();_isInitialized=true;JEInteractor.update_params(false);if(JESETTINGS.aoEnable){JEAO.enable();JEAO.set_noGhostingMode()}break}};_worker.onerror=function(f,l,g){alert("An error happens in the workers at line n"+g+" : "+f)};_params=new Float32Array(6);_params[0]=e.setParams;if(!JESETTINGS.enableWorkers){JEWorkerThread.set_fakeWorker(_worker)}},start_animatePhysics:function(){if(JESETTINGS.disablePhysics){return}console.log("INFO in WorkerMain - start_animatePhysic()");_isLoop=true},stop_animatePhysics:function(){console.log("INFO in WorkerMain - stop_animatePhysic()");_isLoop=false},send_params:function(g,f){if(!f&&(!_isInitialized||!_isLoop)){return}_params[1]=g[0];_params[2]=g[1];_params[3]=g[2];_params[4]=g[3];_params[5]=g[4];_worker.postMessage(_params)},set_cameraPivotZ:function(){_worker.postMessage([e.setCameraPivotZ,JESETTINGS.cameraPivotZ])},free_memory:function(){if(!JESETTINGS.enableWorkers){return}_worker.terminate()}};return c})();var JEWorkerThread=(function(){const e={setParams:2,setCameraMatrix:3,log:4,setCameraPivotZ:5,ready:6};let _timer=false;const q={theta:0,phi:0,cameraDistance:0,pivot:[0,0]};const a=new JETHREE.Matrix4();const g=new JETHREE.Quaternion();const l=new JETHREE.Quaternion();const p=new JETHREE.Vector3();const n=new JETHREE.Vector3();const c=new JETHREE.Euler();let _cameraPivotZ=0;const f=new Float32Array(1+16+3);f[0]=e.setCameraMatrix;let _fakeWorker=false;const b={data:false};const r=function(){p.set(q.pivot[0],q.pivot[1],-q.cameraDistance);c.set(q.phi,q.theta,0,"XYZ");g.setFromEuler(c);p.y-=_cameraPivotZ;a.makeRotationFromQuaternion(g);a.setPosition(p);l.copy(g).inverse();n.copy(p).applyQuaternion(l)};const d=function(){for(let i=1;i<17;++i){f[i]=a.elements[i-1]}f[17]=n.x;f[18]=n.y;f[19]=n.z;o.post_message(f)};const o={init:function(){if(typeof(JESETTINGS)==="undefined"){self.JESETTINGS={enableWorkers:true}}if(JESETTINGS.enableWorkers){o.post_message([e.ready])}},on_message:function(t){switch(t.data[0]){case e.setParams:o.set_params(t.data);break;case e.setCameraPivotZ:_cameraPivotZ=t.data[1];break}},post_message:function(t){if(JESETTINGS.enableWorkers){postMessage(t)}else{b.data=t;_fakeWorker.onmessage(b)}},set_params:function(t){q.theta=t[1];q.phi=t[2];q.cameraDistance=t[3];q.pivot[0]=t[4];q.pivot[1]=t[5];r();d()},set_fakeWorker:function(t){_fakeWorker=t;o.post_message([e.ready])}};return o})();JEWorkerThread.init();var JEMaterial=(function(){let __isNNGL=false;let __diffuseTexture=null;let __auxiliarySampler=1;const a={diffuseTexture:null,normalTexture:null,paramsTexture:null,colorTextureUsage:0,metalness:0.5,roughness:0.5,fresnelMin:0,fresnelMax:1,fresnelPow:5,alpha:1,diffuseColor:[255,255,255],paramsMapMask:[0,0,0,0],callback:null,name:"undefined name"};function b(e){const f=e.split(":").shift();if(f==="data"||f==="blob"){return e}const d=((typeof(SETTINGS)!=="undefined"&&SETTINGS.basePath)?SETTINGS:JESETTINGS).basePath+JESETTINGS.materialTextureBasePath;return d+e}function c(e,d){return Math.min(d+e+d*e,1)}return{init:function(){__diffuseTexture=JETexture.instance({width:1,height:1,isMipmap:false,nChannels:4,array:new Uint8Array([255,255,255,255]),isSrgb:false})},enable_NNGL:function(){__isNNGL=true;__auxiliarySampler=2},instance:function(p){const f=[1,0,0,0];const d=[0,0,0,0];let _spec=Object.assign({},a,p);let _diffuseColor=null,_diffuseShaderNameNoDrawBuffers=null;const q={diffuse:null,normal:null,params:null};const n={diffuse:false,normal:false,params:false};let _uParams=null;let _shaderNameNoNNGL=null,_shaderNameNNGL=null;let _shaderNameNormalsNNGLNoDrawBuffers=null,_shaderNameNormalsNoNNGLNoDrawBuffers=null;let _shaderNameMatParamsNNGLNoDrawBuffers=null,_shaderNameMatParamsNoNNGLNoDrawBuffers=null;function l(){if(typeof(_spec.alpha)==="number"){f[0]=_spec.alpha;f[1]=0,f[2]=0,f[3]=0}else{f[0]=_spec.alpha[0];f[1]=_spec.alpha[1]-_spec.alpha[0];f[2]=_spec.alpha[2];f[3]=_spec.alpha[3]}const t=(_spec.fresnelPow>=1)?_spec.fresnelMin:_spec.fresnelMax;d[0]=c(f[0],t),d[1]=c(f[1],t),d[2]=f[2],d[3]=f[3];_uParams={paramA:_spec.fresnelMax,mains:[_spec.fresnelMin,_spec.roughness,_spec.fresnelPow/15,_spec.metalness],mask:_spec.paramsMapMask}}function o(u){let _nToLoad=1,_nLoaded=0;function t(){if(++_nLoaded===_nToLoad){if(u){console.log("INFO in JEMaterial - Material loaded for",_spec.name);u()}}}n.normal=(_spec.normalTexture&&JEContext.can_normalMap())?true:false;if(n.normal&&!q.normal){++_nToLoad;q.normal=JETexture.instance({url:b(_spec.normalTexture),isLinear:true,isMipmap:true,isAnisotropicFiltering:JEContext.is_insaneMode(),isPot:true,nChannels:3,callback:t})}n.diffuse=(_spec.diffuseTexture&&_spec.diffuseTexture!=="")?true:false;if(n.diffuse&&!q.diffuse){++_nToLoad;q.diffuse=JETexture.instance({url:b(_spec.diffuseTexture),isMipmap:true,isLinear:true,isPot:true,isAnisotropicFiltering:true,isSrgb:false,isMirrorY:false,isMirrorX:false,nChannels:4,callback:t});_diffuseShaderNameNoDrawBuffers="shp_gbufferDiffuseNNGLtexture"}else{if(!q.diffuse){_diffuseShaderNameNoDrawBuffers="shp_gbufferDiffuseNNGLcolor";q.diffuse=__diffuseTexture}}_diffuseColor=[_spec.diffuseColor[0]/255,_spec.diffuseColor[1]/255,_spec.diffuseColor[2]/255];n.params=(_spec.paramsTexture)?true:false;if(n.params&&!n.diffuse){console.log("ERROR in JEMaterial - instance(): a material has a params map, ",_spec.paramsTexture," but no diffuse map.")}if(n.params&&!q.params){if(_spec.paramsTexture===_spec.diffuseTexture){q.params=q.diffuse}else{++_nToLoad;q.params=JETexture.instance({url:b(_spec.paramsTexture),isMipmap:true,isLinear:true,isPot:true,isAnisotropicFiltering:true,isSrgb:false,isMirrorY:false,isMirrorX:false,nChannels:4,callback:t})}}t()}function r(){if(!n.normal&&!n.params&&!n.diffuse){_shaderNameNoNNGL="shp_gbufferscolor";_shaderNameNNGL="shp_gbuffersNNGLcolor"}else{if(!n.normal&&!n.params){_shaderNameNoNNGL="shp_gbuffers";_shaderNameNNGL="shp_gbuffersNNGLtexture"}else{if(n.normal&&!n.params){_shaderNameNoNNGL="shp_gbuffersNormalMap";_shaderNameNNGL="shp_gbuffersNNGLtextureNormalMap"}else{if(!n.normal&&n.params){_shaderNameNoNNGL="shp_gbuffersParamsMap";_shaderNameNNGL="shp_gbuffersNNGLtextureParamsMap"}else{_shaderNameNoNNGL="shp_gbuffersNormalParamsMap";_shaderNameNNGL="shp_gbuffersNNGLtextureNormalParamsMap"}}}}_shaderNameNormalsNNGLNoDrawBuffers=(n.normal)?"shp_gbufferNormalsNNGLNormalMap":"shp_gbufferNormalsNNGL";_shaderNameNormalsNoNNGLNoDrawBuffers=(n.normal)?"shp_gbufferNormalsNormalMap":"shp_gbufferNormals";_shaderNameMatParamsNNGLNoDrawBuffers=(n.params)?"shp_gbufferMatParamsParamsMapNNGL":"shp_gbufferMatParamsNNGL";_shaderNameMatParamsNoNNGLNoDrawBuffers=(n.params)?"shp_gbufferMatParamsParamsMap":"shp_gbufferMatParams"}function e(u){l();const t=(_spec.callback)?_spec.callback.bind(null,u):null;o(t);r()}const g={update:function(t){Object.assign(_spec,t);e()},is_normalTexture:function(){return n.normal},is_transparent:function(){return(f[0]<0.99)},get_shaderNameNormalsNoNNGLNoDrawBuffers:function(){return _shaderNameNormalsNoNNGLNoDrawBuffers},get_shaderNameNormalsNNGLNoDrawBuffers:function(){return _shaderNameNormalsNNGLNoDrawBuffers},get_shaderNameMatParamsNoNNGLNoDrawBuffers:function(){return _shaderNameMatParamsNoNNGLNoDrawBuffers},get_shaderNameMatParamsNNGLNoDrawBuffers:function(){return _shaderNameMatParamsNNGLNoDrawBuffers},get_shaderNameNoNNGLDrawBuffers:function(){return _shaderNameNoNNGL},get_shaderNameNNGLDrawBuffers:function(){return _shaderNameNNGL},draw_normals:function(){if(n.normal){q.normal.bind_toSampler(0)}},draw_diffuseNoDrawBuffers:function(t){if(__isNNGL){JEShaders.set(_diffuseShaderNameNoDrawBuffers)}if(t){JEShaders.set_attribPointerPosition()}else{JEShaders.set_attribPointerPositionNoUVs()}if(n.diffuse){JEShaders.set_attribPointerUvs()}g.draw_diffuse()},draw_diffuse:function(){if(n.diffuse){JEShaders.set_uniformDynamic1f("uun_colorTextureUsage",_spec.colorTextureUsage);q.diffuse.bind_toSampler(0)}JEShaders.set_uniformDynamic3fv("uun_diffuseColor",_diffuseColor)},draw_params:function(){if(n.params){q.params.bind_toSampler(0);JEShaders.set_uniformDynamic4fv("uun_paramsMapMask",_uParams.mask);JEShaders.set_attribPointerUvs()}JEShaders.set_uniformDynamic4fv("uun_matParams",_uParams.mains);JEShaders.set_uniformDynamic1f("uun_matParamA",_uParams.paramA)},draw_drawBuffers:function(t){if(n.params&&!n.normal){q.params.bind_toSampler(__auxiliarySampler)}else{if(n.normal){if(!n.diffuse){__diffuseTexture.bind_toSampler(0)}q.normal.bind_toSampler(__auxiliarySampler);if(n.params){q.params.bind_toSampler(__auxiliarySampler+1)}}}if(n.params){JEShaders.set_uniformDynamic4fv("uun_paramsMapMask",_uParams.mask)}if(n.diffuse||n.normal){JEShaders.set_attribPointerDrawBuffers()}else{if(t){JEShaders.set_attribPointerDrawBuffersNoUvs()}else{JEShaders.set_attribPointerDrawBuffersNoUvs2()}}g.draw_diffuse();JEShaders.set_uniformDynamic4fv("uun_alpha",f);JEShaders.set_uniformDynamic4fv("uun_matParams",_uParams.mains);JEShaders.set_uniformDynamic1f("uun_matParamA",_uParams.paramA)},draw_alpha:function(){JEShaders.set_uniformDynamic4fv("uun_alpha",f)},draw_alpha2:function(){JEShaders.set_uniformDynamic4fv("uun_alpha",d)},free_memory:function(){if(n.diffuse){q.diffuse.remove()}if(n.normal){q.normal.remove()}if(n.params&&_spec.paramsTexture!==_spec.diffuseTexture){q.params.remove()}}};e(g);return g}}})();var JEAO=(function(){let _overSamplingFactor=0,_opacityMin=0,_opacityMax=0,_lightAttMax=0,_aoMaxWaked=0,_aoMax=0;const d=JESETTINGS.aoStepMin;const b=JESETTINGS.aoStepMax;const a=JESETTINGS.aoStepPow;let _width=0,_height=0,_texture=null,_fbo=null,_opacity=0,_lightAtt=0,_nPasses=0;let _width0=0,_height0=0,_texturePostProcessed=null;let _k=0,_kPeriod=0,_kt=0,_t=Date.now();let _timerGhosting=null;let _isInitialized=false;let _isResized=false;let _isNoGhosting=false;let _GbuffersOverSamplingFactor=1;let _isEnabled=false;const c={init:function(){console.log("INFO in AO: init() ");_overSamplingFactor=JESETTINGS.aoOverSampling[JEContext.get_level()];_opacityMin=JESETTINGS.aoOpacityMin[JEContext.get_level()];_opacityMax=JESETTINGS.aoOpacityMax[JEContext.get_level()];_kPeriod=JESETTINGS.aoPeriod[JEContext.get_level()];_lightAttMax=JESETTINGS.aoLightAttMax[JEContext.get_level()];_aoMaxWaked=JESETTINGS.aoMaxWaked[JEContext.get_level()];_nPasses=JESETTINGS.aoNPasses[JEContext.get_level()];_width0=JEContext.get_width();_height0=JEContext.get_height();_width=Math.round(_width0*_overSamplingFactor);_height=Math.round(_height0*_overSamplingFactor);_fbo=JEFBO.instance({width:_width,height:_height,isDepth:false});_texture=JETexture.instance({width:_width,height:_height,isPot:false,isLinear:true});_texturePostProcessed=JETexture.instance({width:_width,height:_height,isPot:false,isLinear:true,nChannels:1});_isInitialized=true},resize:function(f,e,g){_GbuffersOverSamplingFactor=g;_width0=f;_height0=e;_width=Math.round(f*_overSamplingFactor);_height=Math.round(e*_overSamplingFactor);_fbo.resize(_width,_height);_isResized=true},draw:function(){const f=Date.now()-_t;const l=Math.exp(-f/_kPeriod);if(_isNoGhosting){_k=_kt+(1-l)*(1-_kt)}else{_k=_kt*l}_opacity=_opacityMin+_k*(_opacityMax-_opacityMin);_lightAtt=_lightAttMax+(1-_k)*(1-_lightAttMax);_aoMax=_aoMaxWaked+(1-_k)*(1-_aoMaxWaked);JETexture.unbind(5);if(_isResized&&_isInitialized){JETexture.unbind(6);_texturePostProcessed.resize(_width,_height);JEShaders.set("shp_copy");JEShaders.set_uniformDynamic1i("uun_source",6);_fbo.bind(false,true);_texturePostProcessed.set_rtt();_fbo.clear_color();_texture.bind_toSampler(6);JEVBO.draw_quad(true,true);_texture.resize(_width,_height);_texture.set_rtt();_texturePostProcessed.bind_toSampler(6);JEVBO.draw_quad(false,false);JEShaders.set_uniformDynamic1i("uun_source",0);_isResized=false;return}GL.enable(GL.BLEND);GL.blendFunc(GL.CONSTANT_ALPHA,GL.ONE_MINUS_SRC_ALPHA);const o=_opacity/_nPasses;GL.blendColor(o,o,o,o);GL.colorMask(true,false,false,true);JEShaders.set("shp_AO");JECamera.draw_ao();JEShaders.set_uniformDynamic1f("uun_opacity",_opacity);if(_kPeriod){JEShaders.set_uniformDynamic1f("uun_lightAtt",_lightAtt);JEShaders.set_uniformDynamic1f("uun_aoMax",_aoMax)}const g=_GbuffersOverSamplingFactor*(d+Math.pow(Math.random(),a)*(b-d));JEShaders.set_uniformDynamic2f("uun_dxy",g/_width0,g/_height0);_fbo.bind_only();_fbo.set_vp();_texture.set_rtt();const n=2*Math.PI*Math.random();let isBindQuad=true;for(let i=0;i<_nPasses;++i){if(i===1){GL.blendFunc(GL.SRC_ALPHA,GL.ONE);JEShaders.set_uniformDynamic1f("uun_opacity",o)}JEShaders.set_uniformDynamic1f("uun_theta",n+(i/_nPasses)*(Math.PI/2));JEShaders.set_uniformDynamic2f("uun_uvTilt",(Math.random()-0.5)/_width0,(Math.random()-0.5)/_height0);JEVBO.draw_quad(isBindQuad,isBindQuad);isBindQuad=false}GL.disable(GL.BLEND);JEShaders.set("shp_AOPostProcessing");JEShaders.set_uniformDynamic2f("uun_dxy",1/_width,1/_height);_texturePostProcessed.set_rtt();_texture.bind_toSampler(7);JEVBO.draw_quad(false,false);GL.colorMask(true,true,true,true)},bind_toSampler:function(e){_texturePostProcessed.bind_toSampler(e)},enable:function(){_isEnabled=true},prevent_ghosting:function(){console.log("AO: prevent_ghosting()");if(_isNoGhosting||!_isEnabled){return false}if(_timerGhosting){clearTimeout(_timerGhosting)}c.set_noGhostingMode();_timerGhosting=setTimeout(c.unset_noGhostingMode,400)},set_noGhostingMode:function(){if(_timerGhosting){clearTimeout(_timerGhosting);_timerGhosting=false}if(_isNoGhosting||!_isEnabled){return}console.log("AO: set_noGhostingMode()");window.JESSMP.disable();_isNoGhosting=true;_t=Date.now();_kt=_k},unset_noGhostingMode:function(){if(!_isNoGhosting||!_isEnabled){return}if(_timerGhosting){clearTimeout(_timerGhosting);_timerGhosting=null}console.log("AO: unset_noGhostingMode()");window.JESSMP.enable();_isNoGhosting=false;_t=Date.now();_kt=_k},free_memory:function(){_texture.remove();_texturePostProcessed.remove();_fbo.remove()}};c.prevent_ghosting();return c})();var JEShadow=(function(){return{instance:function(f){let sizeFactor=JESETTINGS.shadowSizeFactor[JEContext.get_level()];let _width=f.width*sizeFactor;let _height=f.height*sizeFactor;let _isLoaded=false;const q=JEFBO.instance({width:_width,height:_height,isDepth:true});const D=JETexture.instance({width:_width,height:_height,isLinear:true,nChannels:3});const p=JETexture.instance({width:_width,height:_height,nChannels:3});const x=JETexture.instance({width:_width,height:_height,isFloat:SharedContext.can_floatRTT(),isHalfFloat:true,nChannels:1});const o=JElib_matrix.get_projectionOrtho(f.sceneWidth,f.sceneHeight,0,f.sceneDepth);const a=new JETHREE.Vector3(f.center[0],f.center[1],f.center[2]);const g=new JETHREE.Vector3(f.normal[0],f.normal[1],f.normal[2]).normalize();const C=new JETHREE.Quaternion().setFromUnitVectors(g,new JETHREE.Vector3(0,0,-1));const B=C.clone().inverse();const A=a.clone().applyQuaternion(B);const b=new JETHREE.Matrix4().makeRotationFromQuaternion(C).setPosition(A);const t=b.elements;let threeVMatrixInv=new JETHREE.Matrix4().getInverse(b);let _VInvMatrix=threeVMatrixInv.elements;const n=f.sceneWidth/2,d=f.sceneHeight/2;const c=new JETHREE.Vector4(-n,d,0,1).applyMatrix4(threeVMatrixInv);const e=new JETHREE.Vector4(n,d,0,1).applyMatrix4(threeVMatrixInv);const v=new JETHREE.Vector4(-n,-d,0,1).applyMatrix4(threeVMatrixInv);const u=new JETHREE.Vector4(n,-d,0,1).applyMatrix4(threeVMatrixInv);const l=JEVBO.instance({vertices:[c.x,c.y,c.z,0,0,e.x,e.y,e.z,1,0,u.x,u.y,u.z,1,1,v.x,v.y,v.z,0,1],indices:[0,1,2,0,2,3]});const r=function(){console.log("INFO in JEShadow - instance: build()");q.set_rtt();x.set_rtt();q.set_vp();GL.clearColor(1,1,1,1);q.clear();JEShaders.set("shp_shadowDepth");JEShaders.set_uniformDynamicMatrix4fv("uun_Vmatrix",t);JEShaders.set_uniformDynamicMatrix4fv("uun_Pmatrix",o);f.meshes.forEach(function(E){E.draw_shadow()});JEShaders.set("shp_shadow");D.set_rtt();GL.clearColor(0,0,0,0);q.clear();x.bind_toSampler(0);JELight.bind_irradianceTextureToSampler(1);JETexture.bind_random(2);JEShaders.set_uniformDynamicMatrix4fv("uun_Pmatrix",o);JEShaders.set_uniformDynamicMatrix4fv("uun_VInvMatrix",_VInvMatrix);JEShaders.set_uniformDynamic2f("uun_wh",f.sceneWidth,f.sceneHeight);JEVBO.draw_quad(true,true);p.set_rtt();JEShaders.set("shp_shadowBlur");JEShaders.set_uniformDynamic2f("uun_dxy",1/_width,0);D.bind_toSampler(0);JEVBO.draw_quad(false,false);D.set_rtt();JEShaders.set_uniformDynamic2f("uun_dxy",0,1/_height);p.bind_toSampler(0);JEVBO.draw_quad(false,false);GL.flush();JETexture.unbind(0);JETexture.unbind(1);q.remove();p.remove();x.remove();_isLoaded=true};let nLoaded=0;const z=function(){if(++nLoaded===f.meshes.length+1){console.log("INFO in JEShadow - check_isLoaded(): ",f.meshes.length," are loaded");setTimeout(r,0)}};f.meshes.forEach(function(E){E.call_onload(z)});JELight.call_onload(z);let that={bind_toSampler:function(E){D.bind_toSampler(E)},debug:function(){D.debug()},draw:function(){if(!_isLoaded){return}JEShaders.set("shp_shadowDraw");JECamera.draw();that.bind_toSampler(7);l.bind(false);JEShaders.set_attribPointersPositionUvs();l.draw()},remove:function(){that.free_memory();that=null},free_memory:function(){l.remove();D.remove()}};return that}}})();var JEFakeMipmap=(function(){return{instance:function(c){const a=c.texture.get_width();const b=(c.isRGBE)?true:false;const d=(b)?"shp_fakeMipmapRGBE":"shp_fakeMipmap";const f=JETexture.instance({isFloat:c.texture.is_float()&&SharedContext.can_floatRTT()&&!b,isHalfFloat:c.texture.is_halfFloat()&&!b,isLinear:true,isMipmap:false,isPot:false,width:a,height:a,nChannels:(b)?4:3});const e=JETexture.instance({isFloat:c.texture.is_float()&&SharedContext.can_floatRTT(),isHalfFloat:c.texture.is_halfFloat(),isPot:true,width:1,height:a/2,nChannels:3});e.set_rtt();JEShaders.set("shp_avgLineColor");c.texture.bind_toSampler(0);JEVBO.draw_quad(true,true);const g=Math.round(Math.log(a)/Math.log(2));f.refresh_fakeMipmap=function(){f.set_rtt();JEShaders.set(d);JEShaders.set_uniformDynamic1f("uun_gamma",JESETTINGS.postProcessingGamma);c.texture.bind_toSampler(0);e.bind_toSampler(1);let y=0;for(let i=0;i<=g;++i){const n=Math.pow(2,g-i);const l=n/2;GL.viewport(0,y,a,l);JEShaders.set_uniformDynamic2f("uun_uvFactor",a/n,1);JEShaders.set_uniformDynamic1f("uun_edge",Math.min(6/l,0.6));y+=n/2;JEVBO.draw_quad((i===0),(i===0))}};f.remove_texture=f.remove;f.remove=function(){f.remove_texture();e.remove()};return f}}})();